{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac1e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import random\n",
    "import sys,os\n",
    "import itertools\n",
    "import numbers\n",
    "from collections import Counter\n",
    "from warnings import warn\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a5a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cf7fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(1337)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "#python_random.seed(1337)\n",
    "random.seed(1337)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.random.set_seed(1337)\n",
    "#older version of tensorflow\n",
    "#tf.set_random_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf00f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9a06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 8\n",
    "# Maximum number of threads to use for OpenMP parallel regions.\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"12\"\n",
    "# Without setting below 2 environment variables, it didn't work for me. Thanks to @cjw85 \n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"8\"\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"8\"\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(\n",
    "    num_threads\n",
    ")\n",
    "tf.config.threading.set_intra_op_parallelism_threads(\n",
    "    num_threads\n",
    ")\n",
    "tf.config.set_soft_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acc5c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.regularizers import (\n",
    "    l2, \n",
    "    l1, \n",
    "    l1_l2\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import (\n",
    "    activations, \n",
    "    initializers, \n",
    "    regularizers, \n",
    "    constraints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98af4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ba35c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, \n",
    "    EarlyStopping\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d6afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest,\n",
    "    chi2\n",
    ")\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84eec855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention_layer import Attention, attention_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b27604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\tprint('building model')\n",
    "\n",
    "\tseq_input_shape = (1000,4)\n",
    "\tnb_filter = 256\n",
    "\tfilter_length = 9\n",
    "\tattentionhidden = 256\n",
    "\n",
    "\tseq_input = Input(shape = seq_input_shape, name = 'seq_input')\n",
    "\tconvul1   = Convolution1D(filters = nb_filter,\n",
    "                        \t  kernel_size = filter_length,\n",
    "                        \t  padding = 'valid',\n",
    "                        \t  activation = 'relu',\n",
    "                        \t  kernel_constraint = max_norm(3)\n",
    "\t\t\t\t\t\t\t  #subsample_length = 1\n",
    "\t\t\t\t\t\t\t  )\n",
    "\n",
    "\tpool_ma1 = MaxPooling1D(pool_size = 3)\n",
    "\tdropout1 = Dropout(0.5977908689086315)\n",
    "\tdropout2 = Dropout(0.50131233477637737)\n",
    "\tdecoder  = Attention(hidden = attentionhidden, activation = 'linear')\n",
    "\tdense1   = Dense(1)\n",
    "\tdense2   = Dense(1)\n",
    "\n",
    "\toutput_1 = pool_ma1(convul1(seq_input))\n",
    "\toutput_2 = dropout1(output_1)\n",
    "\tatt_decoder  = decoder(output_2)\n",
    "\toutput_3 = attention_flatten(output_2.shape[2])(att_decoder)\n",
    "\n",
    "\toutput_4 =  dense1(dropout2(Flatten()(output_2)))\n",
    "\tall_outp =  concatenate([output_3, output_4])\n",
    "\toutput_5 =  dense2(all_outp)\n",
    "\toutput_f =  Activation('sigmoid')(output_5)\n",
    "\n",
    "\tmodel = Model(inputs = seq_input, outputs = output_f)\n",
    "\tmodel.compile(loss = 'binary_crossentropy', optimizer = 'nadam', metrics = ['accuracy'])\n",
    "\n",
    "\tprint (model.summary())\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "246210bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing():\n",
    "    x_visdb = np.load('data/x_VISDB_fulldata.npy')\n",
    "    y_visdb = np.load('data/y_VISDB_fulldata.npy')\n",
    "\n",
    "    ###split 9:1\n",
    "    trainx, valx, trainy, valy = train_test_split(x_visdb, y_visdb, test_size = 0.1, stratify=y_visdb , random_state=42\n",
    "                                                    )\n",
    "\n",
    "    ##test 1:1\n",
    "    neg_val = np.where(valy == 0)\n",
    "    pos_val = np.where(valy == 1)\n",
    "    xval_positive = valx[pos_val]\n",
    "    yval_positive = valy[pos_val]\n",
    "    xval_negative = valx[neg_val]\n",
    "    yval_negative = valy[neg_val]\n",
    "\n",
    "    permutation = np.random.permutation(xval_negative.shape[0])\n",
    "    xval_negative_1 = xval_negative[permutation[:xval_positive.shape[0]], :, :]\n",
    "    yval_negative_1 = yval_negative[permutation[:xval_positive.shape[0]]]\n",
    "\n",
    "    xval_1 = np.concatenate((xval_positive, xval_negative_1), axis=0)\n",
    "    yval_1 = np.concatenate((yval_positive, yval_negative_1), axis=0)\n",
    "    xval_2, yval_2 = shuffle(xval_1, yval_1\n",
    "                            )\n",
    "\n",
    "    trainx2, trainy2 = shuffle(trainx, trainy\n",
    "                            )\n",
    "    \n",
    "    return trainx2, trainy2, xval_2, yval_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65a11e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fff25ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainx, trainy, cv):\n",
    "    kfold = cv\n",
    "    for i, (train,test) in enumerate(kfold.split(trainx, trainy)):\n",
    "        xtrain = trainx[train]\n",
    "        ytrain = trainy[train]\n",
    "        testx = trainx[test]\n",
    "        testy = trainy[test]\n",
    "\n",
    "        neg_val = np.where(testy == 0)\n",
    "        pos_val = np.where(testy == 1)\n",
    "        xval_positive = testx[pos_val]\n",
    "        yval_positive = testy[pos_val]\n",
    "        xval_negative = testx[neg_val]\n",
    "        yval_negative = testy[neg_val]\n",
    "\n",
    "        x_p = xtrain[np.where(ytrain==1)]\n",
    "        x_n = xtrain[np.where(ytrain!=1)]\n",
    "\n",
    "        permutation = np.random.permutation(xval_negative.shape[0])\n",
    "        xval_negative_1 = xval_negative[permutation[:xval_positive.shape[0]], :, :]\n",
    "        yval_negative_1 = yval_negative[permutation[:xval_positive.shape[0]]]\n",
    "\n",
    "        xval_1 = np.concatenate((xval_positive, xval_negative_1), axis=0)\n",
    "        yval_1 = np.concatenate((yval_positive, yval_negative_1), axis=0)\n",
    "        xval_2, yval_2 = shuffle(xval_1, yval_1 #, random_state=42\n",
    "                                )\n",
    "\n",
    "        slength=int(x_p.shape[0]) #positive data length\n",
    "\n",
    "        folder = ('model/fullrun3/CV_%s/' %i) #set CV iteration folder\n",
    "        if not os.path.isdir(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "        for u in range(10):\n",
    "            callback_list = [\n",
    "                EarlyStopping(monitor = 'val_accuracy', patience = 10),\n",
    "                ModelCheckpoint(filepath = (folder+'model_%s.h5' %u), monitor = 'val_accuracy', mode = 'max', save_best_only= True, save_weights_only = True, verbose = 1),\n",
    "                MyCustomCallback()\n",
    "            ]\n",
    "\n",
    "            if u == 0:\n",
    "                model = build_model()\n",
    "            if u == 9:\n",
    "                x1_n1 = x_n[(slength*u):]\n",
    "            else:                            \n",
    "                x1_n1 = x_n[(slength*u):(slength*u+slength)]\n",
    "\n",
    "\n",
    "            train_x1 = np.concatenate((x_p, x1_n1), axis=0)\n",
    "            train_yf =  np.concatenate((np.ones((len(x_p),), dtype=np.int),np.zeros((len(x1_n1),), dtype=np.int)), axis=0)\n",
    "\n",
    "            model.fit(train_x1, train_yf, \n",
    "                        validation_data = (xval_2, yval_2),\n",
    "                        epochs = 100, batch_size = 512, shuffle = True,\n",
    "                        callbacks = callback_list,\n",
    "                        verbose = 1)\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fff25ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(valx, valy):\n",
    "        \n",
    "        font1 = {'family' : 'Times New Roman',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "        figsize=6.2, 6.2\n",
    "\n",
    "        folder = 'model/Final_model.h5'\n",
    "        #if not os.path.isdir(folder):\n",
    "        #        os.makedirs(folder)             \n",
    "\n",
    "        model = build_model()\n",
    "        model.load_weights(folder)\n",
    "        y_pred = model.predict(valx, verbose = 1)\n",
    "        \n",
    "        del model\n",
    "\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(valy, y_pred)\n",
    "        auroc = roc_auc_score(valy, y_pred)\n",
    "        pr, rc, _ = precision_recall_curve(valy, y_pred)\n",
    "        aupr = average_precision_score(valy, y_pred)\n",
    "\n",
    "        figure1, ax1 = plt.subplots(figsize=figsize)\n",
    "        ax1.tick_params(labelsize=18)\n",
    "        labels = ax1.get_xticklabels() + ax1.get_yticklabels()\n",
    "        [label.set_fontname('Times New Roman') for label in labels]  \n",
    "        ax1.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Luck', alpha=.8)\n",
    "\n",
    "        ax1.plot(fpr, tpr, color='b',\n",
    "                label=r'Independent Test ROC (AUC = %0.2f)' % (auroc),\n",
    "                lw=1, alpha=.8)\n",
    "        ax1.set_xlim([-0.05, 1.05])\n",
    "        ax1.set_ylim([-0.05, 1.05])\n",
    "        ax1.set_xlabel('False Positive Rate', font1)\n",
    "        ax1.set_ylabel('True Positive Rate', font1)\n",
    "        title1 = 'Cross Validated ROC Curve'\n",
    "        ax1.set_title(title1, font1)\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "        ########PR_figure\n",
    "        figure2, ax2 = plt.subplots(figsize=figsize)\n",
    "        ax2.tick_params(labelsize=18)\n",
    "        labels = ax2.get_xticklabels() + ax2.get_yticklabels()\n",
    "        [label.set_fontname('Times New Roman') for label in labels] \n",
    "\n",
    "        ax2.plot(rc, pr, color='b',\n",
    "                label=r'Independent Test PR (AUC = %0.2f)' % aupr,\n",
    "                lw=1, alpha=.8)\n",
    "        ax2.set_xlim([-0.05, 1.05])\n",
    "        ax2.set_ylim([-0.05, 1.05])\n",
    "        ax2.set_xlabel('Recall', font1)\n",
    "        ax2.set_ylabel('Precision', font1)\n",
    "        title2 = 'Cross Validated PR Curve'\n",
    "        ax2.set_title(title2, font1)\n",
    "        ax2.legend(loc=\"lower left\")\n",
    "\n",
    "        figure1.savefig('figures/DeepHTLV_ROC_independentTest.jpg', dpi=300, bbox_inches = 'tight')\n",
    "        figure2.savefig('figures/DeepHTLV_PRC_independentTest.jpg', dpi = 300, bbox_inches = 'tight')\n",
    "        #figure3.savefig('figures/DeepHTLV_fullscript_ROC_CV10mean.jpg', dpi = 300, bbox_inches = 'tight')\n",
    "        #figure4.savefig('figures/DeepHTLV_fullscript_PR_CV10mean.jpg', dpi = 300, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fff25ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_curves(trainx, trainy, cv):\n",
    "        all_probas = np.array([])\n",
    "        all_labels = np.array([])\n",
    "\n",
    "        font1 = {'family' : 'Times New Roman',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "        figsize=6.2, 6.2\n",
    "        \n",
    "        kfold = cv\n",
    "        for i, (train,test) in enumerate(kfold.split(trainx, trainy)):\n",
    "                i1 = i + 1\n",
    "                xtrain = trainx[train]\n",
    "                ytrain = trainy[train]\n",
    "                testx = trainx[test]\n",
    "                testy = trainy[test]\n",
    "\n",
    "                neg_val = np.where(testy == 0)\n",
    "                pos_val = np.where(testy == 1)\n",
    "                xval_positive = testx[pos_val]\n",
    "                yval_positive = testy[pos_val]\n",
    "                xval_negative = testx[neg_val]\n",
    "                yval_negative = testy[neg_val]\n",
    "\n",
    "                #x_p = xtrain[np.where(ytrain==1)]\n",
    "                #x_n = xtrain[np.where(ytrain!=1)]\n",
    "\n",
    "                permutation = np.random.permutation(xval_negative.shape[0])\n",
    "                xval_negative_1 = xval_negative[permutation[:xval_positive.shape[0]], :, :]\n",
    "                yval_negative_1 = yval_negative[permutation[:xval_positive.shape[0]]]\n",
    "\n",
    "                xval_1 = np.concatenate((xval_positive, xval_negative_1), axis=0)\n",
    "                yval_1 = np.concatenate((yval_positive, yval_negative_1), axis=0)\n",
    "                xval_2, yval_2 = shuffle(xval_1, yval_1 #, random_state=42\n",
    "                                        )\n",
    "\n",
    "                folder = ('model/fullrun3/CV_%s/' %i) #set CV iteration folder\n",
    "                if not os.path.isdir(folder):\n",
    "                        os.makedirs(folder)\n",
    "\n",
    "                for u in range(10):\n",
    "                        model = build_model()\n",
    "                        model.load_weights(folder+'model_%s.h5' %u)\n",
    "                        y_pred = model.predict(xval_2, verbose = 1)\n",
    "                        \n",
    "                        if u == 0:\n",
    "                                probas = np.array(y_pred)\n",
    "                        else:\n",
    "                                probas = np.column_stack((probas, y_pred))\n",
    "                        del model\n",
    "                        gc.collect()\n",
    "                        tf.keras.backend.clear_session()\n",
    "\n",
    "                avg_probas = np.array(probas).mean(axis = 1)\n",
    "\n",
    "                auroc = roc_auc_score(yval_2, avg_probas)\n",
    "                fpr, tpr, threshold = roc_curve(yval_2, avg_probas)\n",
    "                aupr = average_precision_score(yval_2, avg_probas)\n",
    "                pr, rc, threshold = precision_recall_curve(yval_2, avg_probas)\n",
    "\n",
    "                if i == 0:\n",
    "                        figure1, ax1 = plt.subplots(figsize=figsize)\n",
    "                        ax1.tick_params(labelsize=18)\n",
    "                        labels = ax1.get_xticklabels() + ax1.get_yticklabels()\n",
    "                        [label.set_fontname('Times New Roman') for label in labels]  \n",
    "                        ax1.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "                        label='Luck', alpha=.8)\n",
    "\n",
    "                        ax1.plot(fpr, tpr, #color='cyan',\n",
    "                                label=r'ROC '+str(i1)+'(AUC = %0.2f)' % (auroc),\n",
    "                                lw=1, alpha=.5)\n",
    "                        ax1.set_xlim([-0.05, 1.05])\n",
    "                        ax1.set_ylim([-0.05, 1.05])\n",
    "                        ax1.set_xlabel('False Positive Rate', font1)\n",
    "                        ax1.set_ylabel('True Positive Rate', font1)\n",
    "                        title1 = 'Cross Validated ROC Curve'\n",
    "                        ax1.set_title(title1, font1)\n",
    "                        ax1.legend(loc=\"lower right\")\n",
    "\n",
    "                        ########PR_figure\n",
    "                        figure2, ax2 = plt.subplots(figsize=figsize)\n",
    "                        ax2.tick_params(labelsize=18)\n",
    "                        labels = ax2.get_xticklabels() + ax2.get_yticklabels()\n",
    "                        [label.set_fontname('Times New Roman') for label in labels] \n",
    "\n",
    "                        ax2.plot(rc, pr,# color='cyan',\n",
    "                                label=r'PR '+str(i1)+ '(AUC = %0.2f)' % aupr,\n",
    "                                lw=1, alpha=.5)\n",
    "\n",
    "                        ax2.set_xlim([-0.05, 1.05])\n",
    "                        ax2.set_ylim([-0.05, 1.05])\n",
    "                        ax2.set_xlabel('Recall', font1)\n",
    "                        ax2.set_ylabel('Precision', font1)\n",
    "                        title2 = 'Cross Validated PR Curve'\n",
    "                        ax2.set_title(title2, font1)\n",
    "                        ax2.legend(loc=\"lower left\")\n",
    "                else:\n",
    "                        ax1.plot(fpr, tpr,\n",
    "                                label=r'ROC '+str(i1)+ '(AUC = %0.2f)' % (auroc),\n",
    "                                lw=1, alpha=.5)\n",
    "                        ax1.legend(loc=\"lower right\")\n",
    "\n",
    "                        ax2.plot(rc, pr,\n",
    "                                label=r'PR '+str(i1)+ '(AUC = %0.2f)' % aupr,\n",
    "                                lw=1, alpha=.5)\n",
    "                        ax2.legend(loc='lower left')\n",
    "\n",
    "                        print('auroc = ', auroc)\n",
    "                        print('aupr = ', aupr)\n",
    "\n",
    "                        gc.collect()\n",
    "                        tf.keras.backend.clear_session()\n",
    "\n",
    "        all_probas = np.append(all_probas, avg_probas)\n",
    "        all_labels = np.append(all_labels, yval_2)\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(all_labels, all_probas)\n",
    "        auroc = roc_auc_score(all_labels, all_probas)\n",
    "        pr, rc, _ = precision_recall_curve(all_labels, all_probas)\n",
    "        aupr = average_precision_score(all_labels, all_probas)\n",
    "\n",
    "        #figure3, ax3 = plt.subplots(figsize=figsize)\n",
    "        #ax3.tick_params(labelsize=18)\n",
    "        #labels = ax1.get_xticklabels() + ax1.get_yticklabels()\n",
    "        #[label.set_fontname('Times New Roman') for label in labels]\n",
    "        #ax1.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        #label='Luck', alpha=.8)\n",
    "\n",
    "        ax1.plot(fpr, tpr, color='b',\n",
    "                label=r'Mean ROC (AUC = %0.2f)' % (auroc),\n",
    "                lw=2, alpha=.8)\n",
    "        #ax3.set_xlim([-0.05, 1.05])\n",
    "        #ax3.set_ylim([-0.05, 1.05])\n",
    "        #ax3.set_xlabel('False Positive Rate', font1)\n",
    "        #ax3.set_ylabel('True Positive Rate', font1)\n",
    "        #title3 = 'Mean Cross Validated ROC Curve'\n",
    "        #ax3.set_title(title3, font1)\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "\n",
    "        #figure4, ax4 = plt.subplots(figsize=figsize)\n",
    "        #ax4.tick_params(labelsize=18)\n",
    "        #labels = ax4.get_xticklabels() + ax4.get_yticklabels()\n",
    "        #[label.set_fontname('Times New Roman') for label in labels] \n",
    "        ax2.plot(rc, pr, color='b',\n",
    "                label=r'Mean PR (AUC = %0.2f)' % aupr,\n",
    "                lw=2, alpha=.8)\n",
    "\n",
    "        #ax4.set_xlim([-0.05, 1.05])\n",
    "        #ax4.set_ylim([-0.05, 1.05])\n",
    "        #ax4.set_xlabel('Recall', font1)\n",
    "        #ax4.set_ylabel('Precision', font1)\n",
    "        #title4 = 'Mean Cross Validated PR Curve'\n",
    "        #ax4.set_title(title4, font1)\n",
    "        ax2.legend(loc=\"lower left\")\n",
    "\n",
    "        figure1.savefig('figures/DeepHTLV_ROC_CVfold10_revisions.jpg', dpi=300, bbox_inches = 'tight')\n",
    "        figure2.savefig('figures/DeepHTLV_PR_CVfold10_revisions.jpg', dpi = 300, bbox_inches = 'tight')\n",
    "        #figure3.savefig('figures/DeepHTLV_fullscript_ROC_CV10mean.jpg', dpi = 300, bbox_inches = 'tight')\n",
    "        #figure4.savefig('figures/DeepHTLV_fullscript_PR_CV10mean.jpg', dpi = 300, bbox_inches = 'tight')\n",
    "\n",
    "\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad8068ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1337)\n",
    "trainx, trainy, valx, valy = data_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d0cb864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 13s 80ms/step - loss: 0.6797 - accuracy: 0.5666 - val_loss: 0.6476 - val_accuracy: 0.5814\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58139, saving model to model/fullrun3/CV_0\\model_0.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.6367 - accuracy: 0.5948 - val_loss: 0.6471 - val_accuracy: 0.5394\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.58139\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.6194 - accuracy: 0.6269 - val_loss: 0.6084 - val_accuracy: 0.6487\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.58139 to 0.64866, saving model to model/fullrun3/CV_0\\model_0.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.6008 - accuracy: 0.6518 - val_loss: 0.6124 - val_accuracy: 0.6257\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64866\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5909 - accuracy: 0.6646 - val_loss: 0.6014 - val_accuracy: 0.6476\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.64866\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5761 - accuracy: 0.6788 - val_loss: 0.5853 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.64866 to 0.66783, saving model to model/fullrun3/CV_0\\model_0.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5715 - accuracy: 0.6834 - val_loss: 0.5813 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66783 to 0.67497, saving model to model/fullrun3/CV_0\\model_0.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5599 - accuracy: 0.6948 - val_loss: 0.5879 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67497\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5548 - accuracy: 0.6997 - val_loss: 0.5797 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67497\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5468 - accuracy: 0.7077 - val_loss: 0.5866 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67497\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5440 - accuracy: 0.7122 - val_loss: 0.5790 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67497\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5378 - accuracy: 0.7166 - val_loss: 0.5804 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67497\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5348 - accuracy: 0.7194 - val_loss: 0.5790 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.67497 to 0.67689, saving model to model/fullrun3/CV_0\\model_0.h5\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5270 - accuracy: 0.7257 - val_loss: 0.5806 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67689\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5272 - accuracy: 0.7266 - val_loss: 0.5863 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67689\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5253 - accuracy: 0.7256 - val_loss: 0.5809 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67689\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5207 - accuracy: 0.7284 - val_loss: 0.5838 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67689\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5167 - accuracy: 0.7320 - val_loss: 0.5814 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67689\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5139 - accuracy: 0.7366 - val_loss: 0.5830 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67689\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5143 - accuracy: 0.7342 - val_loss: 0.5826 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67689\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5106 - accuracy: 0.7406 - val_loss: 0.5836 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67689\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5073 - accuracy: 0.7400 - val_loss: 0.5829 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67689\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5054 - accuracy: 0.7421 - val_loss: 0.5830 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67689\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5634 - accuracy: 0.6984 - val_loss: 0.5783 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67672, saving model to model/fullrun3/CV_0\\model_1.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5505 - accuracy: 0.7037 - val_loss: 0.5813 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67672\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5439 - accuracy: 0.7130 - val_loss: 0.5770 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67672\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5335 - accuracy: 0.7205 - val_loss: 0.5757 - val_accuracy: 0.6804\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67672 to 0.68038, saving model to model/fullrun3/CV_0\\model_1.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5308 - accuracy: 0.7238 - val_loss: 0.5753 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68038\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5240 - accuracy: 0.7271 - val_loss: 0.5821 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68038\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5223 - accuracy: 0.7293 - val_loss: 0.5758 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68038\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5174 - accuracy: 0.7359 - val_loss: 0.5751 - val_accuracy: 0.6809\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.68038 to 0.68090, saving model to model/fullrun3/CV_0\\model_1.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5146 - accuracy: 0.7352 - val_loss: 0.5772 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68090\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5116 - accuracy: 0.7386 - val_loss: 0.5759 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68090\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5078 - accuracy: 0.7419 - val_loss: 0.5768 - val_accuracy: 0.6793\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68090\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5035 - accuracy: 0.7452 - val_loss: 0.5773 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68090\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5020 - accuracy: 0.7446 - val_loss: 0.5785 - val_accuracy: 0.6814\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.68090 to 0.68142, saving model to model/fullrun3/CV_0\\model_1.h5\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4976 - accuracy: 0.7512 - val_loss: 0.5781 - val_accuracy: 0.6790\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68142\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4990 - accuracy: 0.7469 - val_loss: 0.5796 - val_accuracy: 0.6802\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68142\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4946 - accuracy: 0.7527 - val_loss: 0.5844 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68142\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4977 - accuracy: 0.7469 - val_loss: 0.5808 - val_accuracy: 0.6812\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68142\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4892 - accuracy: 0.7566 - val_loss: 0.5831 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68142\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4884 - accuracy: 0.7559 - val_loss: 0.5834 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68142\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4884 - accuracy: 0.7531 - val_loss: 0.5828 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68142\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4869 - accuracy: 0.7565 - val_loss: 0.5844 - val_accuracy: 0.6760\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68142\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4836 - accuracy: 0.7595 - val_loss: 0.5853 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.68142\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4815 - accuracy: 0.7621 - val_loss: 0.5857 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.68142\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5483 - accuracy: 0.7133 - val_loss: 0.5785 - val_accuracy: 0.6776\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67759, saving model to model/fullrun3/CV_0\\model_2.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5380 - accuracy: 0.7177 - val_loss: 0.5809 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67759\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5314 - accuracy: 0.7227 - val_loss: 0.5787 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67759\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5230 - accuracy: 0.7292 - val_loss: 0.5794 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67759\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5181 - accuracy: 0.7358 - val_loss: 0.5771 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67759\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5149 - accuracy: 0.7341 - val_loss: 0.5854 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67759\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5142 - accuracy: 0.7361 - val_loss: 0.5753 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67759\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5069 - accuracy: 0.7436 - val_loss: 0.5746 - val_accuracy: 0.6795\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.67759 to 0.67951, saving model to model/fullrun3/CV_0\\model_2.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5045 - accuracy: 0.7446 - val_loss: 0.5793 - val_accuracy: 0.6778\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67951\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5010 - accuracy: 0.7458 - val_loss: 0.5750 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.67951 to 0.68003, saving model to model/fullrun3/CV_0\\model_2.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4984 - accuracy: 0.7502 - val_loss: 0.5779 - val_accuracy: 0.6814\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.68003 to 0.68142, saving model to model/fullrun3/CV_0\\model_2.h5\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4948 - accuracy: 0.7526 - val_loss: 0.5785 - val_accuracy: 0.6795\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68142\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4937 - accuracy: 0.7522 - val_loss: 0.5787 - val_accuracy: 0.6795\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68142\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4889 - accuracy: 0.7556 - val_loss: 0.5807 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68142\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4893 - accuracy: 0.7537 - val_loss: 0.5822 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68142\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4876 - accuracy: 0.7566 - val_loss: 0.5813 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68142\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4855 - accuracy: 0.7591 - val_loss: 0.5787 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68142\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4825 - accuracy: 0.7601 - val_loss: 0.5804 - val_accuracy: 0.6772\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68142\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4788 - accuracy: 0.7616 - val_loss: 0.5817 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68142\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4798 - accuracy: 0.7614 - val_loss: 0.5843 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68142\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4768 - accuracy: 0.7642 - val_loss: 0.5792 - val_accuracy: 0.6797\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68142\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5382 - accuracy: 0.7192 - val_loss: 0.5761 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67829, saving model to model/fullrun3/CV_0\\model_3.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5296 - accuracy: 0.7262 - val_loss: 0.5773 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67829\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5247 - accuracy: 0.7286 - val_loss: 0.5795 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67829\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5162 - accuracy: 0.7369 - val_loss: 0.5765 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67829\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5126 - accuracy: 0.7402 - val_loss: 0.5771 - val_accuracy: 0.6806\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67829 to 0.68055, saving model to model/fullrun3/CV_0\\model_3.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5115 - accuracy: 0.7403 - val_loss: 0.5864 - val_accuracy: 0.6657\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68055\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5054 - accuracy: 0.7441 - val_loss: 0.5774 - val_accuracy: 0.6776\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68055\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5013 - accuracy: 0.7464 - val_loss: 0.5748 - val_accuracy: 0.6823\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.68055 to 0.68229, saving model to model/fullrun3/CV_0\\model_3.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4978 - accuracy: 0.7489 - val_loss: 0.5814 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68229\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4949 - accuracy: 0.7521 - val_loss: 0.5792 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68229\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4899 - accuracy: 0.7552 - val_loss: 0.5824 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68229\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4866 - accuracy: 0.7561 - val_loss: 0.5821 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68229\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4878 - accuracy: 0.7556 - val_loss: 0.5813 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68229\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4848 - accuracy: 0.7595 - val_loss: 0.5819 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68229\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4815 - accuracy: 0.7624 - val_loss: 0.5829 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68229\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4812 - accuracy: 0.7599 - val_loss: 0.5835 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68229\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4792 - accuracy: 0.7642 - val_loss: 0.5820 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68229\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4773 - accuracy: 0.7640 - val_loss: 0.5835 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68229\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5288 - accuracy: 0.7268 - val_loss: 0.5806 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66609, saving model to model/fullrun3/CV_0\\model_4.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5224 - accuracy: 0.7307 - val_loss: 0.5811 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66609\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5157 - accuracy: 0.7367 - val_loss: 0.5830 - val_accuracy: 0.6657\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66609\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5060 - accuracy: 0.7449 - val_loss: 0.5851 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66609\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5023 - accuracy: 0.7472 - val_loss: 0.5813 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.66609 to 0.66783, saving model to model/fullrun3/CV_0\\model_4.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5000 - accuracy: 0.7488 - val_loss: 0.5887 - val_accuracy: 0.6616\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66783\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4984 - accuracy: 0.7505 - val_loss: 0.5806 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66783 to 0.66800, saving model to model/fullrun3/CV_0\\model_4.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4922 - accuracy: 0.7521 - val_loss: 0.5804 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.66800 to 0.67097, saving model to model/fullrun3/CV_0\\model_4.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4912 - accuracy: 0.7553 - val_loss: 0.5870 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67097\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4877 - accuracy: 0.7578 - val_loss: 0.5834 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67097\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4822 - accuracy: 0.7591 - val_loss: 0.5869 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67097\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4832 - accuracy: 0.7576 - val_loss: 0.5871 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67097\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4812 - accuracy: 0.7613 - val_loss: 0.5820 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67097\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4781 - accuracy: 0.7634 - val_loss: 0.5911 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67097\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4761 - accuracy: 0.7660 - val_loss: 0.5893 - val_accuracy: 0.6616\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67097\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4747 - accuracy: 0.7648 - val_loss: 0.5919 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67097\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4750 - accuracy: 0.7676 - val_loss: 0.5864 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67097\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4706 - accuracy: 0.7696 - val_loss: 0.5880 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67097\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5233 - accuracy: 0.7303 - val_loss: 0.5826 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66312, saving model to model/fullrun3/CV_0\\model_5.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5191 - accuracy: 0.7339 - val_loss: 0.5870 - val_accuracy: 0.6532\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66312\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5100 - accuracy: 0.7400 - val_loss: 0.5859 - val_accuracy: 0.6602\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66312\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5045 - accuracy: 0.7464 - val_loss: 0.5881 - val_accuracy: 0.6562\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66312\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5010 - accuracy: 0.7495 - val_loss: 0.5843 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.66312 to 0.66382, saving model to model/fullrun3/CV_0\\model_5.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4981 - accuracy: 0.7499 - val_loss: 0.5884 - val_accuracy: 0.6603\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66382\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4945 - accuracy: 0.7531 - val_loss: 0.5848 - val_accuracy: 0.6609\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66382\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4896 - accuracy: 0.7563 - val_loss: 0.5859 - val_accuracy: 0.6584\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66382\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4885 - accuracy: 0.7572 - val_loss: 0.5883 - val_accuracy: 0.6563\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66382\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4847 - accuracy: 0.7593 - val_loss: 0.5864 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66382\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4808 - accuracy: 0.7604 - val_loss: 0.5877 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66382\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4779 - accuracy: 0.7653 - val_loss: 0.5872 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66382\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4763 - accuracy: 0.7648 - val_loss: 0.5895 - val_accuracy: 0.6610\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66382\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4751 - accuracy: 0.7651 - val_loss: 0.5888 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.66382 to 0.66521, saving model to model/fullrun3/CV_0\\model_5.h5\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4734 - accuracy: 0.7672 - val_loss: 0.5962 - val_accuracy: 0.6609\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66521\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4701 - accuracy: 0.7690 - val_loss: 0.5906 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66521\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4711 - accuracy: 0.7701 - val_loss: 0.5869 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.66521 to 0.66748, saving model to model/fullrun3/CV_0\\model_5.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4661 - accuracy: 0.7730 - val_loss: 0.5897 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66748\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4878 - accuracy: 0.7560 - val_loss: 0.5831 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.66748 to 0.66940, saving model to model/fullrun3/CV_0\\model_5.h5\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4855 - accuracy: 0.7576 - val_loss: 0.5872 - val_accuracy: 0.6616\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66940\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4849 - accuracy: 0.7600 - val_loss: 0.5864 - val_accuracy: 0.6657\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66940\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4868 - accuracy: 0.7583 - val_loss: 0.5834 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.66940 to 0.67079, saving model to model/fullrun3/CV_0\\model_5.h5\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4842 - accuracy: 0.7573 - val_loss: 0.5869 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67079\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4870 - accuracy: 0.7561 - val_loss: 0.5851 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67079\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4872 - accuracy: 0.7578 - val_loss: 0.5823 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.67079 to 0.67184, saving model to model/fullrun3/CV_0\\model_5.h5\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4833 - accuracy: 0.7605 - val_loss: 0.5854 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67184\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4834 - accuracy: 0.7597 - val_loss: 0.5850 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.67184\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4802 - accuracy: 0.7632 - val_loss: 0.5866 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.67184\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4809 - accuracy: 0.7607 - val_loss: 0.5838 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67184\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4830 - accuracy: 0.7606 - val_loss: 0.5885 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67184\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4783 - accuracy: 0.7609 - val_loss: 0.5840 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.67184\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4763 - accuracy: 0.7654 - val_loss: 0.5844 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.67184 to 0.67358, saving model to model/fullrun3/CV_0\\model_5.h5\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4774 - accuracy: 0.7634 - val_loss: 0.5852 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.67358\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4765 - accuracy: 0.7640 - val_loss: 0.5845 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.67358\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4751 - accuracy: 0.7657 - val_loss: 0.5872 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.67358\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4725 - accuracy: 0.7680 - val_loss: 0.5842 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.67358 to 0.67445, saving model to model/fullrun3/CV_0\\model_5.h5\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4691 - accuracy: 0.7695 - val_loss: 0.5864 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.67445\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4725 - accuracy: 0.7643 - val_loss: 0.5857 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.67445\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4711 - accuracy: 0.7679 - val_loss: 0.5860 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.67445 to 0.67515, saving model to model/fullrun3/CV_0\\model_5.h5\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4683 - accuracy: 0.7678 - val_loss: 0.5856 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.67515\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4669 - accuracy: 0.7719 - val_loss: 0.5870 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.67515\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4701 - accuracy: 0.7676 - val_loss: 0.5859 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.67515\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4691 - accuracy: 0.7687 - val_loss: 0.5883 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.67515\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4663 - accuracy: 0.7722 - val_loss: 0.5868 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.67515\n",
      "Epoch 45/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4662 - accuracy: 0.7696 - val_loss: 0.5881 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.67515\n",
      "Epoch 46/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4619 - accuracy: 0.7741 - val_loss: 0.5866 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.67515\n",
      "Epoch 47/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4681 - accuracy: 0.7701 - val_loss: 0.5881 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.67515\n",
      "Epoch 48/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4634 - accuracy: 0.7743 - val_loss: 0.5890 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.67515\n",
      "Epoch 49/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4617 - accuracy: 0.7740 - val_loss: 0.5877 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.67515\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5380 - accuracy: 0.7168 - val_loss: 0.5846 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66975, saving model to model/fullrun3/CV_0\\model_6.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5319 - accuracy: 0.7243 - val_loss: 0.5836 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66975 to 0.67009, saving model to model/fullrun3/CV_0\\model_6.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5260 - accuracy: 0.7316 - val_loss: 0.5838 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67009\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5180 - accuracy: 0.7340 - val_loss: 0.5848 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67009\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5143 - accuracy: 0.7392 - val_loss: 0.5832 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67009 to 0.67062, saving model to model/fullrun3/CV_0\\model_6.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5137 - accuracy: 0.7381 - val_loss: 0.5859 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67062\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5111 - accuracy: 0.7397 - val_loss: 0.5851 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67062\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5024 - accuracy: 0.7449 - val_loss: 0.5819 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67062\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5028 - accuracy: 0.7446 - val_loss: 0.5818 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.67062 to 0.67114, saving model to model/fullrun3/CV_0\\model_6.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5002 - accuracy: 0.7477 - val_loss: 0.5822 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67114\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4937 - accuracy: 0.7516 - val_loss: 0.5849 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67114\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4901 - accuracy: 0.7538 - val_loss: 0.5865 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67114\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4893 - accuracy: 0.7557 - val_loss: 0.5853 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.67114 to 0.67184, saving model to model/fullrun3/CV_0\\model_6.h5\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4859 - accuracy: 0.7583 - val_loss: 0.5836 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67184\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4846 - accuracy: 0.7591 - val_loss: 0.5859 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67184\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4834 - accuracy: 0.7600 - val_loss: 0.5885 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67184\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4779 - accuracy: 0.7639 - val_loss: 0.5804 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.67184 to 0.67567, saving model to model/fullrun3/CV_0\\model_6.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4791 - accuracy: 0.7634 - val_loss: 0.5821 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67567\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4846 - accuracy: 0.7577 - val_loss: 0.5822 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67567\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4795 - accuracy: 0.7625 - val_loss: 0.5854 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67567\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4793 - accuracy: 0.7613 - val_loss: 0.5840 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67567\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4790 - accuracy: 0.7620 - val_loss: 0.5819 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67567\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4746 - accuracy: 0.7657 - val_loss: 0.5845 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67567\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4793 - accuracy: 0.7613 - val_loss: 0.5864 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67567\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4796 - accuracy: 0.7618 - val_loss: 0.5792 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.67567 to 0.67672, saving model to model/fullrun3/CV_0\\model_6.h5\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4794 - accuracy: 0.7644 - val_loss: 0.5823 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67672\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4766 - accuracy: 0.7655 - val_loss: 0.5821 - val_accuracy: 0.6788\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.67672 to 0.67881, saving model to model/fullrun3/CV_0\\model_6.h5\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4742 - accuracy: 0.7670 - val_loss: 0.5852 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.67881\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4747 - accuracy: 0.7647 - val_loss: 0.5838 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67881\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4721 - accuracy: 0.7655 - val_loss: 0.5847 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67881\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4715 - accuracy: 0.7672 - val_loss: 0.5821 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.67881\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4698 - accuracy: 0.7695 - val_loss: 0.5843 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.67881\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4721 - accuracy: 0.7678 - val_loss: 0.5842 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.67881\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4686 - accuracy: 0.7690 - val_loss: 0.5837 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.67881\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4637 - accuracy: 0.7731 - val_loss: 0.5853 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.67881\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4672 - accuracy: 0.7705 - val_loss: 0.5836 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.67881\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4634 - accuracy: 0.7727 - val_loss: 0.5842 - val_accuracy: 0.6764\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.67881\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5297 - accuracy: 0.7259 - val_loss: 0.5807 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67428, saving model to model/fullrun3/CV_0\\model_7.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5239 - accuracy: 0.7277 - val_loss: 0.5820 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67428\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5187 - accuracy: 0.7363 - val_loss: 0.5838 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67428\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5135 - accuracy: 0.7382 - val_loss: 0.5801 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67428\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5121 - accuracy: 0.7399 - val_loss: 0.5796 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67428\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5072 - accuracy: 0.7425 - val_loss: 0.5824 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67428\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5057 - accuracy: 0.7430 - val_loss: 0.5786 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.67428 to 0.67497, saving model to model/fullrun3/CV_0\\model_7.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4986 - accuracy: 0.7487 - val_loss: 0.5827 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67497\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4974 - accuracy: 0.7483 - val_loss: 0.5781 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67497\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4926 - accuracy: 0.7514 - val_loss: 0.5788 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.67497 to 0.67550, saving model to model/fullrun3/CV_0\\model_7.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4933 - accuracy: 0.7537 - val_loss: 0.5867 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67550\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4901 - accuracy: 0.7550 - val_loss: 0.5859 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67550\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4871 - accuracy: 0.7592 - val_loss: 0.5846 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67550\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4802 - accuracy: 0.7621 - val_loss: 0.5811 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67550\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4825 - accuracy: 0.7598 - val_loss: 0.5840 - val_accuracy: 0.6682\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67550\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4810 - accuracy: 0.7614 - val_loss: 0.5829 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67550\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4764 - accuracy: 0.7641 - val_loss: 0.5777 - val_accuracy: 0.6797\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.67550 to 0.67968, saving model to model/fullrun3/CV_0\\model_7.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4797 - accuracy: 0.7650 - val_loss: 0.5778 - val_accuracy: 0.6806\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.67968 to 0.68055, saving model to model/fullrun3/CV_0\\model_7.h5\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4780 - accuracy: 0.7621 - val_loss: 0.5814 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68055\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4736 - accuracy: 0.7670 - val_loss: 0.5869 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68055\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4759 - accuracy: 0.7650 - val_loss: 0.5794 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68055\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4758 - accuracy: 0.7646 - val_loss: 0.5768 - val_accuracy: 0.6830\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.68055 to 0.68299, saving model to model/fullrun3/CV_0\\model_7.h5\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4729 - accuracy: 0.7667 - val_loss: 0.5826 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.68299\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4738 - accuracy: 0.7643 - val_loss: 0.5825 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.68299\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4706 - accuracy: 0.7703 - val_loss: 0.5774 - val_accuracy: 0.6837\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.68299 to 0.68369, saving model to model/fullrun3/CV_0\\model_7.h5\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4740 - accuracy: 0.7668 - val_loss: 0.5794 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.68369\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4719 - accuracy: 0.7697 - val_loss: 0.5771 - val_accuracy: 0.6828\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.68369\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4694 - accuracy: 0.7675 - val_loss: 0.5788 - val_accuracy: 0.6806\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.68369\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4659 - accuracy: 0.7699 - val_loss: 0.5803 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.68369\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4668 - accuracy: 0.7713 - val_loss: 0.5833 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.68369\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4670 - accuracy: 0.7706 - val_loss: 0.5796 - val_accuracy: 0.6818\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.68369\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4644 - accuracy: 0.7730 - val_loss: 0.5826 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.68369\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4644 - accuracy: 0.7734 - val_loss: 0.5828 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.68369\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4605 - accuracy: 0.7755 - val_loss: 0.5818 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.68369\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4640 - accuracy: 0.7719 - val_loss: 0.5806 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.68369\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5278 - accuracy: 0.7279 - val_loss: 0.5805 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67253, saving model to model/fullrun3/CV_0\\model_8.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5242 - accuracy: 0.7304 - val_loss: 0.5781 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.67253 to 0.67428, saving model to model/fullrun3/CV_0\\model_8.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5190 - accuracy: 0.7351 - val_loss: 0.5831 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67428\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5130 - accuracy: 0.7382 - val_loss: 0.5811 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67428\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5096 - accuracy: 0.7419 - val_loss: 0.5835 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67428\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5075 - accuracy: 0.7414 - val_loss: 0.5839 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67428\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5043 - accuracy: 0.7445 - val_loss: 0.5803 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67428\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4970 - accuracy: 0.7498 - val_loss: 0.5826 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67428\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4968 - accuracy: 0.7493 - val_loss: 0.5804 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.67428 to 0.67585, saving model to model/fullrun3/CV_0\\model_8.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4913 - accuracy: 0.7556 - val_loss: 0.5811 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67585\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4879 - accuracy: 0.7574 - val_loss: 0.5860 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67585\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4883 - accuracy: 0.7574 - val_loss: 0.5851 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67585\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4859 - accuracy: 0.7569 - val_loss: 0.5839 - val_accuracy: 0.6760\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.67585 to 0.67602, saving model to model/fullrun3/CV_0\\model_8.h5\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4829 - accuracy: 0.7615 - val_loss: 0.5851 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67602\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4838 - accuracy: 0.7597 - val_loss: 0.5859 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67602\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4789 - accuracy: 0.7649 - val_loss: 0.5890 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67602\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4772 - accuracy: 0.7645 - val_loss: 0.5840 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.67602 to 0.67811, saving model to model/fullrun3/CV_0\\model_8.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4773 - accuracy: 0.7640 - val_loss: 0.5827 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.67811 to 0.67863, saving model to model/fullrun3/CV_0\\model_8.h5\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4763 - accuracy: 0.7647 - val_loss: 0.5833 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67863\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4693 - accuracy: 0.7685 - val_loss: 0.5869 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67863\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4706 - accuracy: 0.7699 - val_loss: 0.5856 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67863\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4710 - accuracy: 0.7669 - val_loss: 0.5816 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67863\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4695 - accuracy: 0.7713 - val_loss: 0.5880 - val_accuracy: 0.6772\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67863\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4734 - accuracy: 0.7674 - val_loss: 0.5861 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67863\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4710 - accuracy: 0.7664 - val_loss: 0.5821 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67863\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4729 - accuracy: 0.7672 - val_loss: 0.5840 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67863\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4669 - accuracy: 0.7731 - val_loss: 0.5835 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.67863\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4666 - accuracy: 0.7731 - val_loss: 0.5867 - val_accuracy: 0.6790\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.67863 to 0.67898, saving model to model/fullrun3/CV_0\\model_8.h5\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4631 - accuracy: 0.7733 - val_loss: 0.5875 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67898\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4657 - accuracy: 0.7710 - val_loss: 0.5889 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67898\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4658 - accuracy: 0.7715 - val_loss: 0.5860 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.67898\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4609 - accuracy: 0.7751 - val_loss: 0.5868 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.67898\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4631 - accuracy: 0.7729 - val_loss: 0.5892 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.67898\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4612 - accuracy: 0.7740 - val_loss: 0.5876 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.67898\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4557 - accuracy: 0.7780 - val_loss: 0.5889 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.67898\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4662 - accuracy: 0.7722 - val_loss: 0.5851 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.67898\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4640 - accuracy: 0.7738 - val_loss: 0.5833 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.67898\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4683 - accuracy: 0.7703 - val_loss: 0.5844 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.67898\n",
      "Epoch 1/100\n",
      "  6/101 [>.............................] - ETA: 6s - loss: 0.5484 - accuracy: 0.7201WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0374s vs `on_train_batch_end` time: 0.0550s). Check your callbacks.\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.5413 - accuracy: 0.7171 - val_loss: 0.5831 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67131, saving model to model/fullrun3/CV_0\\model_9.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5340 - accuracy: 0.7202 - val_loss: 0.5809 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.67131 to 0.67410, saving model to model/fullrun3/CV_0\\model_9.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5312 - accuracy: 0.7232 - val_loss: 0.5833 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67410\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5292 - accuracy: 0.7254 - val_loss: 0.5793 - val_accuracy: 0.6772\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67410 to 0.67724, saving model to model/fullrun3/CV_0\\model_9.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5231 - accuracy: 0.7307 - val_loss: 0.5781 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67724\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5203 - accuracy: 0.7311 - val_loss: 0.5812 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67724\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5152 - accuracy: 0.7376 - val_loss: 0.5793 - val_accuracy: 0.6776\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.67724 to 0.67759, saving model to model/fullrun3/CV_0\\model_9.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5133 - accuracy: 0.7382 - val_loss: 0.5803 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67759\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5146 - accuracy: 0.7377 - val_loss: 0.5854 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67759\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5087 - accuracy: 0.7394 - val_loss: 0.5771 - val_accuracy: 0.6833\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.67759 to 0.68334, saving model to model/fullrun3/CV_0\\model_9.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5049 - accuracy: 0.7438 - val_loss: 0.5800 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68334\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5024 - accuracy: 0.7463 - val_loss: 0.5797 - val_accuracy: 0.6765\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68334\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5024 - accuracy: 0.7453 - val_loss: 0.5772 - val_accuracy: 0.6819\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68334\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5011 - accuracy: 0.7473 - val_loss: 0.5823 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68334\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4959 - accuracy: 0.7480 - val_loss: 0.5796 - val_accuracy: 0.6765\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68334\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4950 - accuracy: 0.7519 - val_loss: 0.5801 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68334\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4946 - accuracy: 0.7490 - val_loss: 0.5808 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68334\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4935 - accuracy: 0.7513 - val_loss: 0.5775 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68334\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4887 - accuracy: 0.7563 - val_loss: 0.5801 - val_accuracy: 0.6778\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68334\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4874 - accuracy: 0.7578 - val_loss: 0.5790 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68334\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 9s 80ms/step - loss: 0.6837 - accuracy: 0.5657 - val_loss: 0.6632 - val_accuracy: 0.5756\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57564, saving model to model/fullrun3/CV_1\\model_0.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.6414 - accuracy: 0.5843 - val_loss: 0.6410 - val_accuracy: 0.5507\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.57564\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.6191 - accuracy: 0.6272 - val_loss: 0.6157 - val_accuracy: 0.6244\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.57564 to 0.62443, saving model to model/fullrun3/CV_1\\model_0.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.6010 - accuracy: 0.6522 - val_loss: 0.6028 - val_accuracy: 0.6405\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.62443 to 0.64047, saving model to model/fullrun3/CV_1\\model_0.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5890 - accuracy: 0.6678 - val_loss: 0.5919 - val_accuracy: 0.6596\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.64047 to 0.65964, saving model to model/fullrun3/CV_1\\model_0.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5792 - accuracy: 0.6781 - val_loss: 0.5864 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.65964 to 0.66835, saving model to model/fullrun3/CV_1\\model_0.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5705 - accuracy: 0.6855 - val_loss: 0.5822 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66835 to 0.67062, saving model to model/fullrun3/CV_1\\model_0.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5610 - accuracy: 0.6964 - val_loss: 0.5836 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67062\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5545 - accuracy: 0.7007 - val_loss: 0.5783 - val_accuracy: 0.6812\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.67062 to 0.68125, saving model to model/fullrun3/CV_1\\model_0.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5495 - accuracy: 0.7056 - val_loss: 0.5849 - val_accuracy: 0.6656\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68125\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5443 - accuracy: 0.7095 - val_loss: 0.5762 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68125\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5384 - accuracy: 0.7139 - val_loss: 0.5753 - val_accuracy: 0.6835\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.68125 to 0.68351, saving model to model/fullrun3/CV_1\\model_0.h5\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5367 - accuracy: 0.7153 - val_loss: 0.5778 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68351\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5320 - accuracy: 0.7213 - val_loss: 0.5774 - val_accuracy: 0.6797\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68351\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5281 - accuracy: 0.7242 - val_loss: 0.5803 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68351\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5223 - accuracy: 0.7296 - val_loss: 0.5758 - val_accuracy: 0.6790\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68351\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5196 - accuracy: 0.7313 - val_loss: 0.5758 - val_accuracy: 0.6792\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68351\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5178 - accuracy: 0.7309 - val_loss: 0.5752 - val_accuracy: 0.6793\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68351\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5167 - accuracy: 0.7339 - val_loss: 0.5794 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68351\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5114 - accuracy: 0.7382 - val_loss: 0.5758 - val_accuracy: 0.6828\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68351\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5068 - accuracy: 0.7417 - val_loss: 0.5779 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68351\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5072 - accuracy: 0.7413 - val_loss: 0.5771 - val_accuracy: 0.6772\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.68351\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5605 - accuracy: 0.6981 - val_loss: 0.5738 - val_accuracy: 0.6804\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68038, saving model to model/fullrun3/CV_1\\model_1.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5466 - accuracy: 0.7107 - val_loss: 0.5825 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68038\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5379 - accuracy: 0.7158 - val_loss: 0.5718 - val_accuracy: 0.6856\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.68038 to 0.68560, saving model to model/fullrun3/CV_1\\model_1.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5337 - accuracy: 0.7227 - val_loss: 0.5698 - val_accuracy: 0.6860\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.68560 to 0.68595, saving model to model/fullrun3/CV_1\\model_1.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5273 - accuracy: 0.7244 - val_loss: 0.5747 - val_accuracy: 0.6799\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68595\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5230 - accuracy: 0.7297 - val_loss: 0.5749 - val_accuracy: 0.6835\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68595\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5221 - accuracy: 0.7291 - val_loss: 0.5729 - val_accuracy: 0.6868\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.68595 to 0.68682, saving model to model/fullrun3/CV_1\\model_1.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5159 - accuracy: 0.7345 - val_loss: 0.5738 - val_accuracy: 0.6846\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.68682\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5110 - accuracy: 0.7404 - val_loss: 0.5811 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68682\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5100 - accuracy: 0.7403 - val_loss: 0.5748 - val_accuracy: 0.6839\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68682\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5085 - accuracy: 0.7380 - val_loss: 0.5750 - val_accuracy: 0.6854\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68682\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5038 - accuracy: 0.7462 - val_loss: 0.5765 - val_accuracy: 0.6814\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68682\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5037 - accuracy: 0.7456 - val_loss: 0.5755 - val_accuracy: 0.6807\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68682\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5000 - accuracy: 0.7473 - val_loss: 0.5795 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68682\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4981 - accuracy: 0.7485 - val_loss: 0.5771 - val_accuracy: 0.6802\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68682\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4964 - accuracy: 0.7493 - val_loss: 0.5834 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68682\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4932 - accuracy: 0.7508 - val_loss: 0.5781 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68682\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5415 - accuracy: 0.7153 - val_loss: 0.5762 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67829, saving model to model/fullrun3/CV_1\\model_2.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5323 - accuracy: 0.7246 - val_loss: 0.5805 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67829\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5257 - accuracy: 0.7286 - val_loss: 0.5776 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67829\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5179 - accuracy: 0.7342 - val_loss: 0.5742 - val_accuracy: 0.6802\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67829 to 0.68020, saving model to model/fullrun3/CV_1\\model_2.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5132 - accuracy: 0.7379 - val_loss: 0.5765 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68020\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5097 - accuracy: 0.7408 - val_loss: 0.5799 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68020\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5068 - accuracy: 0.7435 - val_loss: 0.5773 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68020\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5014 - accuracy: 0.7476 - val_loss: 0.5742 - val_accuracy: 0.6806\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.68020 to 0.68055, saving model to model/fullrun3/CV_1\\model_2.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5005 - accuracy: 0.7475 - val_loss: 0.5811 - val_accuracy: 0.6764\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68055\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4970 - accuracy: 0.7497 - val_loss: 0.5766 - val_accuracy: 0.6835\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.68055 to 0.68351, saving model to model/fullrun3/CV_1\\model_2.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4947 - accuracy: 0.7518 - val_loss: 0.5773 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68351\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4947 - accuracy: 0.7522 - val_loss: 0.5785 - val_accuracy: 0.6837\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.68351 to 0.68369, saving model to model/fullrun3/CV_1\\model_2.h5\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4907 - accuracy: 0.7542 - val_loss: 0.5764 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68369\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4884 - accuracy: 0.7552 - val_loss: 0.5805 - val_accuracy: 0.6806\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68369\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4861 - accuracy: 0.7569 - val_loss: 0.5774 - val_accuracy: 0.6818\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68369\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4849 - accuracy: 0.7583 - val_loss: 0.5825 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68369\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4839 - accuracy: 0.7603 - val_loss: 0.5785 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68369\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4964 - accuracy: 0.7495 - val_loss: 0.5780 - val_accuracy: 0.6778\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68369\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4942 - accuracy: 0.7505 - val_loss: 0.5809 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68369\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4953 - accuracy: 0.7480 - val_loss: 0.5828 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68369\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4893 - accuracy: 0.7537 - val_loss: 0.5847 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68369\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4911 - accuracy: 0.7529 - val_loss: 0.5779 - val_accuracy: 0.6778\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.68369\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5369 - accuracy: 0.7202 - val_loss: 0.5766 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67445, saving model to model/fullrun3/CV_1\\model_3.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5283 - accuracy: 0.7257 - val_loss: 0.5800 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67445\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5231 - accuracy: 0.7301 - val_loss: 0.5794 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67445 to 0.67619, saving model to model/fullrun3/CV_1\\model_3.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5141 - accuracy: 0.7388 - val_loss: 0.5762 - val_accuracy: 0.6830\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67619 to 0.68299, saving model to model/fullrun3/CV_1\\model_3.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5111 - accuracy: 0.7417 - val_loss: 0.5762 - val_accuracy: 0.6812\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68299\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5089 - accuracy: 0.7415 - val_loss: 0.5804 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68299\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5043 - accuracy: 0.7469 - val_loss: 0.5752 - val_accuracy: 0.6842\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.68299 to 0.68421, saving model to model/fullrun3/CV_1\\model_3.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5004 - accuracy: 0.7487 - val_loss: 0.5742 - val_accuracy: 0.6856\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.68421 to 0.68560, saving model to model/fullrun3/CV_1\\model_3.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4987 - accuracy: 0.7492 - val_loss: 0.5764 - val_accuracy: 0.6844\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68560\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4953 - accuracy: 0.7519 - val_loss: 0.5786 - val_accuracy: 0.6839\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68560\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4948 - accuracy: 0.7540 - val_loss: 0.5779 - val_accuracy: 0.6840\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68560\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4912 - accuracy: 0.7545 - val_loss: 0.5824 - val_accuracy: 0.6837\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68560\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4890 - accuracy: 0.7559 - val_loss: 0.5799 - val_accuracy: 0.6832\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68560\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4842 - accuracy: 0.7588 - val_loss: 0.5782 - val_accuracy: 0.6856\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68560\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4828 - accuracy: 0.7604 - val_loss: 0.5800 - val_accuracy: 0.6844\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68560\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4807 - accuracy: 0.7625 - val_loss: 0.5803 - val_accuracy: 0.6837\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68560\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4815 - accuracy: 0.7615 - val_loss: 0.5757 - val_accuracy: 0.6854\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68560\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4878 - accuracy: 0.7590 - val_loss: 0.5767 - val_accuracy: 0.6830\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68560\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5316 - accuracy: 0.7235 - val_loss: 0.5757 - val_accuracy: 0.6842\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68421, saving model to model/fullrun3/CV_1\\model_4.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5208 - accuracy: 0.7339 - val_loss: 0.5826 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68421\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5151 - accuracy: 0.7364 - val_loss: 0.5811 - val_accuracy: 0.6821\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.68421\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5098 - accuracy: 0.7430 - val_loss: 0.5747 - val_accuracy: 0.6863\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.68421 to 0.68630, saving model to model/fullrun3/CV_1\\model_4.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5057 - accuracy: 0.7433 - val_loss: 0.5774 - val_accuracy: 0.6858\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68630\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4990 - accuracy: 0.7494 - val_loss: 0.5797 - val_accuracy: 0.6793\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68630\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4971 - accuracy: 0.7496 - val_loss: 0.5838 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68630\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4959 - accuracy: 0.7517 - val_loss: 0.5805 - val_accuracy: 0.6814\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.68630\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4910 - accuracy: 0.7556 - val_loss: 0.5860 - val_accuracy: 0.6788\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68630\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4882 - accuracy: 0.7564 - val_loss: 0.5799 - val_accuracy: 0.6809\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68630\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4875 - accuracy: 0.7579 - val_loss: 0.5779 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68630\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4854 - accuracy: 0.7580 - val_loss: 0.5849 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68630\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4818 - accuracy: 0.7586 - val_loss: 0.5811 - val_accuracy: 0.6785\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68630\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4786 - accuracy: 0.7623 - val_loss: 0.5810 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68630\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5227 - accuracy: 0.7312 - val_loss: 0.5778 - val_accuracy: 0.6797\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67968, saving model to model/fullrun3/CV_1\\model_5.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5123 - accuracy: 0.7390 - val_loss: 0.5788 - val_accuracy: 0.6792\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67968\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5067 - accuracy: 0.7434 - val_loss: 0.5838 - val_accuracy: 0.6764\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67968\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5003 - accuracy: 0.7485 - val_loss: 0.5753 - val_accuracy: 0.6851\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67968 to 0.68508, saving model to model/fullrun3/CV_1\\model_5.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4951 - accuracy: 0.7519 - val_loss: 0.5756 - val_accuracy: 0.6865\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.68508 to 0.68648, saving model to model/fullrun3/CV_1\\model_5.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4922 - accuracy: 0.7559 - val_loss: 0.5778 - val_accuracy: 0.6797\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68648\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4882 - accuracy: 0.7582 - val_loss: 0.5814 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68648\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4854 - accuracy: 0.7592 - val_loss: 0.5797 - val_accuracy: 0.6806\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.68648\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4830 - accuracy: 0.7631 - val_loss: 0.5922 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68648\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4798 - accuracy: 0.7636 - val_loss: 0.5827 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68648\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4779 - accuracy: 0.7655 - val_loss: 0.5779 - val_accuracy: 0.6833\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68648\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4779 - accuracy: 0.7636 - val_loss: 0.5841 - val_accuracy: 0.6776\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68648\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4749 - accuracy: 0.7668 - val_loss: 0.5833 - val_accuracy: 0.6793\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68648\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4710 - accuracy: 0.7705 - val_loss: 0.5818 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68648\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4872 - accuracy: 0.7587 - val_loss: 0.5771 - val_accuracy: 0.6851\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68648\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5162 - accuracy: 0.7361 - val_loss: 0.5769 - val_accuracy: 0.6856\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68560, saving model to model/fullrun3/CV_1\\model_6.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5098 - accuracy: 0.7406 - val_loss: 0.5793 - val_accuracy: 0.6778\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68560\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5029 - accuracy: 0.7484 - val_loss: 0.5819 - val_accuracy: 0.6760\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.68560\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4969 - accuracy: 0.7502 - val_loss: 0.5766 - val_accuracy: 0.6847\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.68560\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4908 - accuracy: 0.7580 - val_loss: 0.5780 - val_accuracy: 0.6816\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68560\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4903 - accuracy: 0.7561 - val_loss: 0.5790 - val_accuracy: 0.6830\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68560\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4869 - accuracy: 0.7595 - val_loss: 0.5832 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68560\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4817 - accuracy: 0.7628 - val_loss: 0.5837 - val_accuracy: 0.6809\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.68560\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4804 - accuracy: 0.7629 - val_loss: 0.5841 - val_accuracy: 0.6828\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68560\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4769 - accuracy: 0.7661 - val_loss: 0.5793 - val_accuracy: 0.6860\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.68560 to 0.68595, saving model to model/fullrun3/CV_1\\model_6.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4767 - accuracy: 0.7647 - val_loss: 0.5810 - val_accuracy: 0.6832\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68595\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4754 - accuracy: 0.7642 - val_loss: 0.5899 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68595\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4701 - accuracy: 0.7706 - val_loss: 0.5848 - val_accuracy: 0.6837\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68595\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4691 - accuracy: 0.7701 - val_loss: 0.5816 - val_accuracy: 0.6802\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68595\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4770 - accuracy: 0.7650 - val_loss: 0.5845 - val_accuracy: 0.6785\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68595\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4873 - accuracy: 0.7564 - val_loss: 0.5775 - val_accuracy: 0.6823\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68595\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4889 - accuracy: 0.7564 - val_loss: 0.5733 - val_accuracy: 0.6884\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.68595 to 0.68839, saving model to model/fullrun3/CV_1\\model_6.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4858 - accuracy: 0.7570 - val_loss: 0.5755 - val_accuracy: 0.6849\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68839\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4937 - accuracy: 0.7524 - val_loss: 0.5752 - val_accuracy: 0.6832\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68839\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4927 - accuracy: 0.7526 - val_loss: 0.5781 - val_accuracy: 0.6826\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68839\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4873 - accuracy: 0.7577 - val_loss: 0.5806 - val_accuracy: 0.6793\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68839\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4899 - accuracy: 0.7538 - val_loss: 0.5721 - val_accuracy: 0.6851\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.68839\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4894 - accuracy: 0.7537 - val_loss: 0.5778 - val_accuracy: 0.6832\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.68839\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4910 - accuracy: 0.7532 - val_loss: 0.5789 - val_accuracy: 0.6865\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.68839\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4859 - accuracy: 0.7584 - val_loss: 0.5755 - val_accuracy: 0.6853\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.68839\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4841 - accuracy: 0.7605 - val_loss: 0.5765 - val_accuracy: 0.6877\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.68839\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4835 - accuracy: 0.7588 - val_loss: 0.5767 - val_accuracy: 0.6840\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.68839\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5212 - accuracy: 0.7325 - val_loss: 0.5789 - val_accuracy: 0.6776\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67759, saving model to model/fullrun3/CV_1\\model_7.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5154 - accuracy: 0.7380 - val_loss: 0.5815 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67759\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5078 - accuracy: 0.7439 - val_loss: 0.5835 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67759\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5035 - accuracy: 0.7480 - val_loss: 0.5804 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67759\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4981 - accuracy: 0.7488 - val_loss: 0.5794 - val_accuracy: 0.6764\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67759\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4973 - accuracy: 0.7496 - val_loss: 0.5806 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67759\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4921 - accuracy: 0.7532 - val_loss: 0.5792 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.67759 to 0.67829, saving model to model/fullrun3/CV_1\\model_7.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4895 - accuracy: 0.7583 - val_loss: 0.5825 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67829\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4866 - accuracy: 0.7621 - val_loss: 0.5856 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67829\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4829 - accuracy: 0.7638 - val_loss: 0.5813 - val_accuracy: 0.6806\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.67829 to 0.68055, saving model to model/fullrun3/CV_1\\model_7.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4819 - accuracy: 0.7638 - val_loss: 0.5816 - val_accuracy: 0.6760\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68055\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4789 - accuracy: 0.7644 - val_loss: 0.5850 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68055\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4752 - accuracy: 0.7665 - val_loss: 0.5866 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68055\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4766 - accuracy: 0.7652 - val_loss: 0.5817 - val_accuracy: 0.6785\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68055\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4782 - accuracy: 0.7634 - val_loss: 0.5820 - val_accuracy: 0.6771\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68055\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4812 - accuracy: 0.7620 - val_loss: 0.5804 - val_accuracy: 0.6785\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68055\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4823 - accuracy: 0.7632 - val_loss: 0.5766 - val_accuracy: 0.6821\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.68055 to 0.68212, saving model to model/fullrun3/CV_1\\model_7.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4819 - accuracy: 0.7605 - val_loss: 0.5760 - val_accuracy: 0.6840\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.68212 to 0.68404, saving model to model/fullrun3/CV_1\\model_7.h5\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4855 - accuracy: 0.7586 - val_loss: 0.5795 - val_accuracy: 0.6799\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68404\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4803 - accuracy: 0.7608 - val_loss: 0.5804 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68404\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4783 - accuracy: 0.7639 - val_loss: 0.5844 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68404\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4800 - accuracy: 0.7611 - val_loss: 0.5790 - val_accuracy: 0.6785\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.68404\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4805 - accuracy: 0.7628 - val_loss: 0.5836 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.68404\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4793 - accuracy: 0.7646 - val_loss: 0.5818 - val_accuracy: 0.6764\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.68404\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4782 - accuracy: 0.7645 - val_loss: 0.5769 - val_accuracy: 0.6802\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.68404\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4745 - accuracy: 0.7673 - val_loss: 0.5777 - val_accuracy: 0.6818\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.68404\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4751 - accuracy: 0.7658 - val_loss: 0.5794 - val_accuracy: 0.6818\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.68404\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4864 - accuracy: 0.7570 - val_loss: 0.5792 - val_accuracy: 0.6797\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.68404\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5228 - accuracy: 0.7316 - val_loss: 0.5795 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67567, saving model to model/fullrun3/CV_1\\model_8.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5185 - accuracy: 0.7358 - val_loss: 0.5785 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.67567 to 0.67811, saving model to model/fullrun3/CV_1\\model_8.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5086 - accuracy: 0.7434 - val_loss: 0.5859 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67811\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5088 - accuracy: 0.7416 - val_loss: 0.5799 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67811\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5004 - accuracy: 0.7506 - val_loss: 0.5807 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67811\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5009 - accuracy: 0.7470 - val_loss: 0.5839 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67811\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4990 - accuracy: 0.7482 - val_loss: 0.5832 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67811\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4912 - accuracy: 0.7582 - val_loss: 0.5829 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67811\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4873 - accuracy: 0.7573 - val_loss: 0.5873 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67811\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4869 - accuracy: 0.7613 - val_loss: 0.5848 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67811\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4851 - accuracy: 0.7590 - val_loss: 0.5866 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67811\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4814 - accuracy: 0.7634 - val_loss: 0.5871 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67811\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5381 - accuracy: 0.7191 - val_loss: 0.5787 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67515, saving model to model/fullrun3/CV_1\\model_9.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5346 - accuracy: 0.7198 - val_loss: 0.5800 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67515\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5311 - accuracy: 0.7237 - val_loss: 0.5752 - val_accuracy: 0.6840\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67515 to 0.68404, saving model to model/fullrun3/CV_1\\model_9.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5249 - accuracy: 0.7298 - val_loss: 0.5781 - val_accuracy: 0.6790\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.68404\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5224 - accuracy: 0.7307 - val_loss: 0.5732 - val_accuracy: 0.6812\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68404\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5198 - accuracy: 0.7304 - val_loss: 0.5758 - val_accuracy: 0.6788\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68404\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5155 - accuracy: 0.7360 - val_loss: 0.5747 - val_accuracy: 0.6819\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68404\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5112 - accuracy: 0.7396 - val_loss: 0.5807 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.68404\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5114 - accuracy: 0.7391 - val_loss: 0.5818 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68404\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5091 - accuracy: 0.7408 - val_loss: 0.5755 - val_accuracy: 0.6802\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68404\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5077 - accuracy: 0.7445 - val_loss: 0.5767 - val_accuracy: 0.6804\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68404\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5072 - accuracy: 0.7424 - val_loss: 0.5823 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68404\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4987 - accuracy: 0.7477 - val_loss: 0.5774 - val_accuracy: 0.6814\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68404\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 9s 80ms/step - loss: 0.6732 - accuracy: 0.5700 - val_loss: 0.6441 - val_accuracy: 0.5884\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58836, saving model to model/fullrun3/CV_2\\model_0.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.6321 - accuracy: 0.6003 - val_loss: 0.6333 - val_accuracy: 0.5906\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.58836 to 0.59062, saving model to model/fullrun3/CV_2\\model_0.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.6167 - accuracy: 0.6302 - val_loss: 0.6104 - val_accuracy: 0.6596\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.59062 to 0.65964, saving model to model/fullrun3/CV_2\\model_0.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5983 - accuracy: 0.6559 - val_loss: 0.6060 - val_accuracy: 0.6474\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65964\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5868 - accuracy: 0.6694 - val_loss: 0.5939 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.65964 to 0.66835, saving model to model/fullrun3/CV_2\\model_0.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5756 - accuracy: 0.6786 - val_loss: 0.5883 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66835\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5668 - accuracy: 0.6901 - val_loss: 0.5830 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66835 to 0.67341, saving model to model/fullrun3/CV_2\\model_0.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5566 - accuracy: 0.6976 - val_loss: 0.5986 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67341\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5531 - accuracy: 0.7051 - val_loss: 0.5799 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.67341 to 0.67619, saving model to model/fullrun3/CV_2\\model_0.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5458 - accuracy: 0.7077 - val_loss: 0.5816 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67619\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5423 - accuracy: 0.7132 - val_loss: 0.5802 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67619\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5366 - accuracy: 0.7150 - val_loss: 0.5809 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67619\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5324 - accuracy: 0.7199 - val_loss: 0.5805 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67619\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5289 - accuracy: 0.7221 - val_loss: 0.5805 - val_accuracy: 0.6776\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.67619 to 0.67759, saving model to model/fullrun3/CV_2\\model_0.h5\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5243 - accuracy: 0.7266 - val_loss: 0.5819 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67759\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5218 - accuracy: 0.7292 - val_loss: 0.5809 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67759\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5181 - accuracy: 0.7322 - val_loss: 0.5837 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67759\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5132 - accuracy: 0.7368 - val_loss: 0.5820 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67759\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5152 - accuracy: 0.7346 - val_loss: 0.5829 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67759\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5121 - accuracy: 0.7373 - val_loss: 0.5818 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67759\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5102 - accuracy: 0.7400 - val_loss: 0.5843 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67759\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5076 - accuracy: 0.7388 - val_loss: 0.5842 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67759\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5035 - accuracy: 0.7430 - val_loss: 0.5833 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67759\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5033 - accuracy: 0.7430 - val_loss: 0.5844 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67759\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5628 - accuracy: 0.6970 - val_loss: 0.5823 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67393, saving model to model/fullrun3/CV_2\\model_1.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5492 - accuracy: 0.7072 - val_loss: 0.5877 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67393\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5430 - accuracy: 0.7136 - val_loss: 0.5818 - val_accuracy: 0.6814\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67393 to 0.68142, saving model to model/fullrun3/CV_2\\model_1.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5343 - accuracy: 0.7193 - val_loss: 0.5770 - val_accuracy: 0.6793\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.68142\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5284 - accuracy: 0.7251 - val_loss: 0.5786 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68142\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5253 - accuracy: 0.7269 - val_loss: 0.5824 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68142\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5203 - accuracy: 0.7313 - val_loss: 0.5760 - val_accuracy: 0.6832\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.68142 to 0.68316, saving model to model/fullrun3/CV_2\\model_1.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5157 - accuracy: 0.7349 - val_loss: 0.5762 - val_accuracy: 0.6812\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.68316\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5139 - accuracy: 0.7369 - val_loss: 0.5819 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68316\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5109 - accuracy: 0.7388 - val_loss: 0.5778 - val_accuracy: 0.6792\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68316\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5092 - accuracy: 0.7417 - val_loss: 0.5791 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68316\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5029 - accuracy: 0.7462 - val_loss: 0.5792 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68316\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5019 - accuracy: 0.7441 - val_loss: 0.5802 - val_accuracy: 0.6802\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68316\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4970 - accuracy: 0.7479 - val_loss: 0.5812 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68316\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4972 - accuracy: 0.7492 - val_loss: 0.5804 - val_accuracy: 0.6764\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68316\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4931 - accuracy: 0.7529 - val_loss: 0.5811 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68316\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4914 - accuracy: 0.7535 - val_loss: 0.5824 - val_accuracy: 0.6778\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68316\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5439 - accuracy: 0.7122 - val_loss: 0.5792 - val_accuracy: 0.6764\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67637, saving model to model/fullrun3/CV_2\\model_2.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5319 - accuracy: 0.7213 - val_loss: 0.5859 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.67637 to 0.67672, saving model to model/fullrun3/CV_2\\model_2.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5271 - accuracy: 0.7272 - val_loss: 0.5801 - val_accuracy: 0.6804\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67672 to 0.68038, saving model to model/fullrun3/CV_2\\model_2.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5220 - accuracy: 0.7305 - val_loss: 0.5808 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.68038\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5159 - accuracy: 0.7354 - val_loss: 0.5808 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68038\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5107 - accuracy: 0.7404 - val_loss: 0.5837 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68038\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5086 - accuracy: 0.7414 - val_loss: 0.5772 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68038\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5029 - accuracy: 0.7424 - val_loss: 0.5755 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.68038\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4982 - accuracy: 0.7488 - val_loss: 0.5840 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68038\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4994 - accuracy: 0.7467 - val_loss: 0.5781 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68038\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4924 - accuracy: 0.7529 - val_loss: 0.5788 - val_accuracy: 0.6771\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68038\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4930 - accuracy: 0.7538 - val_loss: 0.5813 - val_accuracy: 0.6788\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68038\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4925 - accuracy: 0.7536 - val_loss: 0.5793 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68038\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5286 - accuracy: 0.7262 - val_loss: 0.5766 - val_accuracy: 0.6804\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68038, saving model to model/fullrun3/CV_2\\model_3.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5207 - accuracy: 0.7337 - val_loss: 0.5884 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68038\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5147 - accuracy: 0.7399 - val_loss: 0.5787 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.68038\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5088 - accuracy: 0.7419 - val_loss: 0.5787 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.68038\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5049 - accuracy: 0.7431 - val_loss: 0.5886 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68038\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5013 - accuracy: 0.7476 - val_loss: 0.5867 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68038\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4974 - accuracy: 0.7496 - val_loss: 0.5822 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68038\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4918 - accuracy: 0.7556 - val_loss: 0.5807 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.68038\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4919 - accuracy: 0.7564 - val_loss: 0.5883 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68038\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4875 - accuracy: 0.7576 - val_loss: 0.5821 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68038\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4839 - accuracy: 0.7603 - val_loss: 0.5837 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68038\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5182 - accuracy: 0.7345 - val_loss: 0.5838 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67149, saving model to model/fullrun3/CV_2\\model_4.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5126 - accuracy: 0.7412 - val_loss: 0.5921 - val_accuracy: 0.6656\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67149\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5075 - accuracy: 0.7446 - val_loss: 0.5857 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67149\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4990 - accuracy: 0.7492 - val_loss: 0.5880 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67149\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4963 - accuracy: 0.7517 - val_loss: 0.5865 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67149 to 0.67341, saving model to model/fullrun3/CV_2\\model_4.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4919 - accuracy: 0.7531 - val_loss: 0.5865 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.67341 to 0.67567, saving model to model/fullrun3/CV_2\\model_4.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4869 - accuracy: 0.7582 - val_loss: 0.5852 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67567\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4846 - accuracy: 0.7610 - val_loss: 0.5813 - val_accuracy: 0.6772\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.67567 to 0.67724, saving model to model/fullrun3/CV_2\\model_4.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4822 - accuracy: 0.7623 - val_loss: 0.5940 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67724\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4800 - accuracy: 0.7635 - val_loss: 0.5828 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67724\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4784 - accuracy: 0.7652 - val_loss: 0.5863 - val_accuracy: 0.6765\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67724\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4935 - accuracy: 0.7521 - val_loss: 0.5826 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67724\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4893 - accuracy: 0.7552 - val_loss: 0.5854 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67724\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4985 - accuracy: 0.7488 - val_loss: 0.5839 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67724\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4953 - accuracy: 0.7500 - val_loss: 0.5800 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.67724 to 0.67863, saving model to model/fullrun3/CV_2\\model_4.h5\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4942 - accuracy: 0.7511 - val_loss: 0.5798 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67863\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4913 - accuracy: 0.7546 - val_loss: 0.5810 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67863\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4972 - accuracy: 0.7480 - val_loss: 0.5815 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67863\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4948 - accuracy: 0.7501 - val_loss: 0.5831 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67863\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4911 - accuracy: 0.7520 - val_loss: 0.5870 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67863\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4917 - accuracy: 0.7530 - val_loss: 0.5859 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67863\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4909 - accuracy: 0.7531 - val_loss: 0.5814 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67863\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4863 - accuracy: 0.7562 - val_loss: 0.5861 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67863\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4846 - accuracy: 0.7581 - val_loss: 0.5834 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67863\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4860 - accuracy: 0.7544 - val_loss: 0.5818 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67863\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5260 - accuracy: 0.7289 - val_loss: 0.5847 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67410, saving model to model/fullrun3/CV_2\\model_5.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5220 - accuracy: 0.7319 - val_loss: 0.5883 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67410\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5140 - accuracy: 0.7400 - val_loss: 0.5854 - val_accuracy: 0.6764\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67410 to 0.67637, saving model to model/fullrun3/CV_2\\model_5.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5084 - accuracy: 0.7421 - val_loss: 0.5850 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67637\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5023 - accuracy: 0.7463 - val_loss: 0.5859 - val_accuracy: 0.6760\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67637\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4989 - accuracy: 0.7495 - val_loss: 0.5890 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67637\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4946 - accuracy: 0.7535 - val_loss: 0.5873 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67637\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4919 - accuracy: 0.7546 - val_loss: 0.5853 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67637\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4872 - accuracy: 0.7571 - val_loss: 0.5935 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67637\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4857 - accuracy: 0.7595 - val_loss: 0.5847 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.67637 to 0.67794, saving model to model/fullrun3/CV_2\\model_5.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4814 - accuracy: 0.7635 - val_loss: 0.5843 - val_accuracy: 0.6802\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.67794 to 0.68020, saving model to model/fullrun3/CV_2\\model_5.h5\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4917 - accuracy: 0.7536 - val_loss: 0.5853 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68020\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4866 - accuracy: 0.7573 - val_loss: 0.5855 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68020\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4888 - accuracy: 0.7567 - val_loss: 0.5871 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68020\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4873 - accuracy: 0.7564 - val_loss: 0.5844 - val_accuracy: 0.6771\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68020\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4844 - accuracy: 0.7590 - val_loss: 0.5854 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68020\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4828 - accuracy: 0.7610 - val_loss: 0.5859 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68020\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4853 - accuracy: 0.7569 - val_loss: 0.5846 - val_accuracy: 0.6772\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68020\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4833 - accuracy: 0.7565 - val_loss: 0.5839 - val_accuracy: 0.6772\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68020\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4787 - accuracy: 0.7625 - val_loss: 0.5971 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68020\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4811 - accuracy: 0.7621 - val_loss: 0.5871 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68020\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5205 - accuracy: 0.7327 - val_loss: 0.5839 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67515, saving model to model/fullrun3/CV_2\\model_6.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5152 - accuracy: 0.7366 - val_loss: 0.5886 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67515\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5093 - accuracy: 0.7427 - val_loss: 0.5855 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67515\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5071 - accuracy: 0.7431 - val_loss: 0.5846 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67515\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5010 - accuracy: 0.7472 - val_loss: 0.5865 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67515\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4958 - accuracy: 0.7510 - val_loss: 0.5859 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67515\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4950 - accuracy: 0.7523 - val_loss: 0.5862 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67515\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4891 - accuracy: 0.7580 - val_loss: 0.5836 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.67515 to 0.67794, saving model to model/fullrun3/CV_2\\model_6.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4840 - accuracy: 0.7613 - val_loss: 0.5914 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67794\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4839 - accuracy: 0.7595 - val_loss: 0.5832 - val_accuracy: 0.6776\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67794\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4800 - accuracy: 0.7624 - val_loss: 0.5906 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67794\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4835 - accuracy: 0.7598 - val_loss: 0.5828 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.67794 to 0.67863, saving model to model/fullrun3/CV_2\\model_6.h5\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4833 - accuracy: 0.7605 - val_loss: 0.5884 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67863\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4821 - accuracy: 0.7629 - val_loss: 0.5867 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67863\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4817 - accuracy: 0.7604 - val_loss: 0.5862 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67863\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4806 - accuracy: 0.7626 - val_loss: 0.5862 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67863\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4761 - accuracy: 0.7638 - val_loss: 0.5850 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67863\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4798 - accuracy: 0.7635 - val_loss: 0.5827 - val_accuracy: 0.6776\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67863\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4777 - accuracy: 0.7638 - val_loss: 0.5841 - val_accuracy: 0.6807\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.67863 to 0.68072, saving model to model/fullrun3/CV_2\\model_6.h5\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4723 - accuracy: 0.7677 - val_loss: 0.5897 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68072\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4726 - accuracy: 0.7678 - val_loss: 0.5943 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68072\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4822 - accuracy: 0.7594 - val_loss: 0.5848 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.68072\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4778 - accuracy: 0.7635 - val_loss: 0.5885 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.68072\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4801 - accuracy: 0.7618 - val_loss: 0.5844 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.68072\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4767 - accuracy: 0.7629 - val_loss: 0.5835 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.68072\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4833 - accuracy: 0.7594 - val_loss: 0.5833 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.68072\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4847 - accuracy: 0.7577 - val_loss: 0.5811 - val_accuracy: 0.6799\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.68072\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4845 - accuracy: 0.7588 - val_loss: 0.5831 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.68072\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4811 - accuracy: 0.7619 - val_loss: 0.5849 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.68072\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5221 - accuracy: 0.7315 - val_loss: 0.5847 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67184, saving model to model/fullrun3/CV_2\\model_7.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5183 - accuracy: 0.7344 - val_loss: 0.5893 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67184\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5136 - accuracy: 0.7395 - val_loss: 0.5862 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67184\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5074 - accuracy: 0.7426 - val_loss: 0.5899 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67184\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5034 - accuracy: 0.7449 - val_loss: 0.5892 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67184\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4995 - accuracy: 0.7481 - val_loss: 0.5908 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67184\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4997 - accuracy: 0.7488 - val_loss: 0.5875 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67184\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4912 - accuracy: 0.7554 - val_loss: 0.5920 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67184\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4910 - accuracy: 0.7550 - val_loss: 0.5957 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67184\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4871 - accuracy: 0.7578 - val_loss: 0.5876 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.67184 to 0.67463, saving model to model/fullrun3/CV_2\\model_7.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4843 - accuracy: 0.7617 - val_loss: 0.5912 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67463\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4855 - accuracy: 0.7596 - val_loss: 0.5901 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67463\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4826 - accuracy: 0.7604 - val_loss: 0.5929 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67463\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4803 - accuracy: 0.7614 - val_loss: 0.5928 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67463\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4806 - accuracy: 0.7632 - val_loss: 0.5902 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67463\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4789 - accuracy: 0.7649 - val_loss: 0.5912 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67463\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4731 - accuracy: 0.7654 - val_loss: 0.5891 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.67463 to 0.67585, saving model to model/fullrun3/CV_2\\model_7.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4798 - accuracy: 0.7626 - val_loss: 0.5863 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67585\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4758 - accuracy: 0.7638 - val_loss: 0.5925 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67585\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4734 - accuracy: 0.7676 - val_loss: 0.5931 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67585\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4724 - accuracy: 0.7668 - val_loss: 0.5927 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67585\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4771 - accuracy: 0.7631 - val_loss: 0.5878 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67585\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4720 - accuracy: 0.7666 - val_loss: 0.5950 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67585\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4712 - accuracy: 0.7691 - val_loss: 0.5936 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67585\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4684 - accuracy: 0.7702 - val_loss: 0.5892 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67585\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4767 - accuracy: 0.7644 - val_loss: 0.5891 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67585\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4726 - accuracy: 0.7662 - val_loss: 0.5915 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.67585\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5207 - accuracy: 0.7326 - val_loss: 0.5936 - val_accuracy: 0.6617\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66173, saving model to model/fullrun3/CV_2\\model_8.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5193 - accuracy: 0.7346 - val_loss: 0.5939 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66173\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5113 - accuracy: 0.7400 - val_loss: 0.5935 - val_accuracy: 0.6616\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66173\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5062 - accuracy: 0.7443 - val_loss: 0.5918 - val_accuracy: 0.6649\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.66173 to 0.66487, saving model to model/fullrun3/CV_2\\model_8.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5048 - accuracy: 0.7453 - val_loss: 0.5957 - val_accuracy: 0.6582\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66487\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4991 - accuracy: 0.7488 - val_loss: 0.5939 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66487\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4978 - accuracy: 0.7509 - val_loss: 0.5904 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66487\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4931 - accuracy: 0.7540 - val_loss: 0.5912 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.66487 to 0.66643, saving model to model/fullrun3/CV_2\\model_8.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4901 - accuracy: 0.7578 - val_loss: 0.5931 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66643\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4864 - accuracy: 0.7585 - val_loss: 0.5884 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.66643 to 0.66957, saving model to model/fullrun3/CV_2\\model_8.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4851 - accuracy: 0.7607 - val_loss: 0.5918 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66957\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4861 - accuracy: 0.7591 - val_loss: 0.5950 - val_accuracy: 0.6635\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66957\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4804 - accuracy: 0.7629 - val_loss: 0.5896 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.66957 to 0.67097, saving model to model/fullrun3/CV_2\\model_8.h5\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4791 - accuracy: 0.7638 - val_loss: 0.5956 - val_accuracy: 0.6657\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67097\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4806 - accuracy: 0.7618 - val_loss: 0.5957 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67097\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4781 - accuracy: 0.7633 - val_loss: 0.5922 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67097\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4739 - accuracy: 0.7676 - val_loss: 0.5918 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67097\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4774 - accuracy: 0.7635 - val_loss: 0.5900 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.67097 to 0.67358, saving model to model/fullrun3/CV_2\\model_8.h5\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4751 - accuracy: 0.7667 - val_loss: 0.5905 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67358\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4701 - accuracy: 0.7703 - val_loss: 0.5987 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67358\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4705 - accuracy: 0.7684 - val_loss: 0.5914 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67358\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4741 - accuracy: 0.7666 - val_loss: 0.5869 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.67358 to 0.67393, saving model to model/fullrun3/CV_2\\model_8.h5\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4680 - accuracy: 0.7715 - val_loss: 0.5947 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67393\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4692 - accuracy: 0.7702 - val_loss: 0.5913 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67393\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4688 - accuracy: 0.7715 - val_loss: 0.5900 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67393\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4705 - accuracy: 0.7690 - val_loss: 0.5910 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67393\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4709 - accuracy: 0.7689 - val_loss: 0.5861 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.67393 to 0.67532, saving model to model/fullrun3/CV_2\\model_8.h5\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4789 - accuracy: 0.7632 - val_loss: 0.5883 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.67532\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4733 - accuracy: 0.7664 - val_loss: 0.5872 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67532\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4755 - accuracy: 0.7653 - val_loss: 0.5910 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67532\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4781 - accuracy: 0.7654 - val_loss: 0.5882 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.67532\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4790 - accuracy: 0.7636 - val_loss: 0.5864 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.67532\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4776 - accuracy: 0.7639 - val_loss: 0.5888 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.67532\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4743 - accuracy: 0.7683 - val_loss: 0.5887 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.67532\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4746 - accuracy: 0.7650 - val_loss: 0.5885 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.67532\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4720 - accuracy: 0.7666 - val_loss: 0.5868 - val_accuracy: 0.6760\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.67532 to 0.67602, saving model to model/fullrun3/CV_2\\model_8.h5\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4714 - accuracy: 0.7687 - val_loss: 0.5874 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.67602\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4682 - accuracy: 0.7707 - val_loss: 0.5902 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.67602\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4692 - accuracy: 0.7689 - val_loss: 0.5892 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.67602\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4686 - accuracy: 0.7700 - val_loss: 0.5894 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.67602\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4679 - accuracy: 0.7691 - val_loss: 0.5893 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.67602\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4656 - accuracy: 0.7728 - val_loss: 0.5908 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.67602\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4682 - accuracy: 0.7699 - val_loss: 0.5899 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.67602\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4654 - accuracy: 0.7701 - val_loss: 0.5889 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.67602\n",
      "Epoch 45/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4674 - accuracy: 0.7705 - val_loss: 0.5906 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.67602\n",
      "Epoch 46/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4682 - accuracy: 0.7674 - val_loss: 0.5908 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.67602\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.5424 - accuracy: 0.7130 - val_loss: 0.5893 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66800, saving model to model/fullrun3/CV_2\\model_9.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5390 - accuracy: 0.7173 - val_loss: 0.5911 - val_accuracy: 0.6642\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66800\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5352 - accuracy: 0.7208 - val_loss: 0.5874 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66800\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5310 - accuracy: 0.7237 - val_loss: 0.5900 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66800\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5264 - accuracy: 0.7265 - val_loss: 0.5885 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66800\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5195 - accuracy: 0.7313 - val_loss: 0.5864 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.66800 to 0.67027, saving model to model/fullrun3/CV_2\\model_9.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5192 - accuracy: 0.7331 - val_loss: 0.5938 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67027\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5177 - accuracy: 0.7345 - val_loss: 0.5925 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67027\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5152 - accuracy: 0.7353 - val_loss: 0.5871 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.67027 to 0.67079, saving model to model/fullrun3/CV_2\\model_9.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5115 - accuracy: 0.7402 - val_loss: 0.5891 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67079\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5057 - accuracy: 0.7415 - val_loss: 0.5825 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.67079 to 0.67689, saving model to model/fullrun3/CV_2\\model_9.h5\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5075 - accuracy: 0.7413 - val_loss: 0.5844 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67689\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5022 - accuracy: 0.7472 - val_loss: 0.5946 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67689\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5030 - accuracy: 0.7460 - val_loss: 0.5853 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67689\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4995 - accuracy: 0.7477 - val_loss: 0.5918 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67689\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4960 - accuracy: 0.7517 - val_loss: 0.5867 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67689\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4945 - accuracy: 0.7519 - val_loss: 0.5872 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67689\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4945 - accuracy: 0.7528 - val_loss: 0.5884 - val_accuracy: 0.6682\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67689\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4917 - accuracy: 0.7546 - val_loss: 0.5868 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67689\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4888 - accuracy: 0.7557 - val_loss: 0.5904 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67689\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4878 - accuracy: 0.7572 - val_loss: 0.5873 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67689\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 9s 79ms/step - loss: 0.6804 - accuracy: 0.5657 - val_loss: 0.6558 - val_accuracy: 0.5741\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57407, saving model to model/fullrun3/CV_3\\model_0.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.6379 - accuracy: 0.5893 - val_loss: 0.6691 - val_accuracy: 0.5120\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.57407\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.6197 - accuracy: 0.6230 - val_loss: 0.6101 - val_accuracy: 0.6501\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.57407 to 0.65005, saving model to model/fullrun3/CV_3\\model_0.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.6012 - accuracy: 0.6508 - val_loss: 0.6070 - val_accuracy: 0.6372\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65005\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5888 - accuracy: 0.6653 - val_loss: 0.5916 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.65005 to 0.66539, saving model to model/fullrun3/CV_3\\model_0.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5803 - accuracy: 0.6757 - val_loss: 0.5906 - val_accuracy: 0.6624\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66539\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5713 - accuracy: 0.6843 - val_loss: 0.5890 - val_accuracy: 0.6633\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66539\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5608 - accuracy: 0.6967 - val_loss: 0.5833 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.66539 to 0.67288, saving model to model/fullrun3/CV_3\\model_0.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5559 - accuracy: 0.6984 - val_loss: 0.5805 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.67288 to 0.67811, saving model to model/fullrun3/CV_3\\model_0.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5496 - accuracy: 0.7065 - val_loss: 0.5836 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67811\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5465 - accuracy: 0.7085 - val_loss: 0.5783 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67811\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5386 - accuracy: 0.7172 - val_loss: 0.5783 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67811\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5356 - accuracy: 0.7183 - val_loss: 0.5779 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67811\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5302 - accuracy: 0.7211 - val_loss: 0.5804 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67811\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5280 - accuracy: 0.7258 - val_loss: 0.5861 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67811\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5219 - accuracy: 0.7288 - val_loss: 0.5804 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67811\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5212 - accuracy: 0.7288 - val_loss: 0.5808 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67811\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5199 - accuracy: 0.7311 - val_loss: 0.5804 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67811\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5148 - accuracy: 0.7353 - val_loss: 0.5818 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67811\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5609 - accuracy: 0.6987 - val_loss: 0.5782 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67497, saving model to model/fullrun3/CV_3\\model_1.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5454 - accuracy: 0.7095 - val_loss: 0.5816 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67497\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5412 - accuracy: 0.7153 - val_loss: 0.5790 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67497\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5323 - accuracy: 0.7210 - val_loss: 0.5753 - val_accuracy: 0.6792\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67497 to 0.67916, saving model to model/fullrun3/CV_3\\model_1.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5294 - accuracy: 0.7223 - val_loss: 0.5783 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67916\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5237 - accuracy: 0.7296 - val_loss: 0.5809 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67916\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5217 - accuracy: 0.7310 - val_loss: 0.5755 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67916\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5173 - accuracy: 0.7342 - val_loss: 0.5762 - val_accuracy: 0.6776\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67916\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5139 - accuracy: 0.7348 - val_loss: 0.5811 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67916\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5117 - accuracy: 0.7375 - val_loss: 0.5766 - val_accuracy: 0.6771\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67916\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5089 - accuracy: 0.7404 - val_loss: 0.5777 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67916\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5036 - accuracy: 0.7447 - val_loss: 0.5772 - val_accuracy: 0.6799\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.67916 to 0.67985, saving model to model/fullrun3/CV_3\\model_1.h5\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5027 - accuracy: 0.7459 - val_loss: 0.5773 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67985\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4995 - accuracy: 0.7486 - val_loss: 0.5788 - val_accuracy: 0.6818\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.67985 to 0.68177, saving model to model/fullrun3/CV_3\\model_1.h5\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5003 - accuracy: 0.7455 - val_loss: 0.5799 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68177\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4932 - accuracy: 0.7507 - val_loss: 0.5834 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68177\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4940 - accuracy: 0.7516 - val_loss: 0.5811 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68177\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4926 - accuracy: 0.7532 - val_loss: 0.5817 - val_accuracy: 0.6765\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68177\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4886 - accuracy: 0.7548 - val_loss: 0.5814 - val_accuracy: 0.6795\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68177\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5025 - accuracy: 0.7445 - val_loss: 0.5805 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68177\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4985 - accuracy: 0.7487 - val_loss: 0.5840 - val_accuracy: 0.6760\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68177\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4966 - accuracy: 0.7490 - val_loss: 0.5812 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.68177\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4944 - accuracy: 0.7478 - val_loss: 0.5817 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.68177\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4940 - accuracy: 0.7505 - val_loss: 0.5804 - val_accuracy: 0.6790\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.68177\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5482 - accuracy: 0.7094 - val_loss: 0.5775 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67585, saving model to model/fullrun3/CV_3\\model_2.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5380 - accuracy: 0.7153 - val_loss: 0.5803 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67585\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5300 - accuracy: 0.7249 - val_loss: 0.5804 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67585\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5261 - accuracy: 0.7269 - val_loss: 0.5757 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67585 to 0.67863, saving model to model/fullrun3/CV_3\\model_2.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5190 - accuracy: 0.7347 - val_loss: 0.5781 - val_accuracy: 0.6778\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67863\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5182 - accuracy: 0.7345 - val_loss: 0.5793 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67863\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5145 - accuracy: 0.7381 - val_loss: 0.5751 - val_accuracy: 0.6812\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.67863 to 0.68125, saving model to model/fullrun3/CV_3\\model_2.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5085 - accuracy: 0.7410 - val_loss: 0.5745 - val_accuracy: 0.6823\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.68125 to 0.68229, saving model to model/fullrun3/CV_3\\model_2.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5062 - accuracy: 0.7430 - val_loss: 0.5782 - val_accuracy: 0.6804\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68229\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5033 - accuracy: 0.7450 - val_loss: 0.5758 - val_accuracy: 0.6818\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68229\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4989 - accuracy: 0.7487 - val_loss: 0.5768 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68229\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4972 - accuracy: 0.7500 - val_loss: 0.5802 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68229\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4928 - accuracy: 0.7530 - val_loss: 0.5773 - val_accuracy: 0.6776\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68229\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4936 - accuracy: 0.7503 - val_loss: 0.5802 - val_accuracy: 0.6776\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68229\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4947 - accuracy: 0.7516 - val_loss: 0.5806 - val_accuracy: 0.6793\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68229\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4871 - accuracy: 0.7571 - val_loss: 0.5827 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68229\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4829 - accuracy: 0.7600 - val_loss: 0.5823 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68229\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4842 - accuracy: 0.7593 - val_loss: 0.5807 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68229\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5375 - accuracy: 0.7170 - val_loss: 0.5790 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66922, saving model to model/fullrun3/CV_3\\model_3.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5269 - accuracy: 0.7256 - val_loss: 0.5817 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66922 to 0.67114, saving model to model/fullrun3/CV_3\\model_3.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5225 - accuracy: 0.7313 - val_loss: 0.5838 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67114 to 0.67201, saving model to model/fullrun3/CV_3\\model_3.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5171 - accuracy: 0.7339 - val_loss: 0.5773 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67201 to 0.67410, saving model to model/fullrun3/CV_3\\model_3.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5132 - accuracy: 0.7373 - val_loss: 0.5788 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67410 to 0.67480, saving model to model/fullrun3/CV_3\\model_3.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5081 - accuracy: 0.7412 - val_loss: 0.5795 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67480\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5085 - accuracy: 0.7426 - val_loss: 0.5765 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67480\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5034 - accuracy: 0.7457 - val_loss: 0.5768 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.67480 to 0.67811, saving model to model/fullrun3/CV_3\\model_3.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4986 - accuracy: 0.7503 - val_loss: 0.5900 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67811\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4938 - accuracy: 0.7491 - val_loss: 0.5812 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67811\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4947 - accuracy: 0.7539 - val_loss: 0.5803 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67811\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4907 - accuracy: 0.7549 - val_loss: 0.5806 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67811\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4859 - accuracy: 0.7586 - val_loss: 0.5794 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67811\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4862 - accuracy: 0.7585 - val_loss: 0.5816 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67811\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4882 - accuracy: 0.7571 - val_loss: 0.5840 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67811\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4800 - accuracy: 0.7618 - val_loss: 0.5816 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67811\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4778 - accuracy: 0.7645 - val_loss: 0.5827 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67811\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4794 - accuracy: 0.7623 - val_loss: 0.5797 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67811\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5302 - accuracy: 0.7255 - val_loss: 0.5792 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67184, saving model to model/fullrun3/CV_3\\model_4.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5202 - accuracy: 0.7358 - val_loss: 0.5814 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67184\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5142 - accuracy: 0.7395 - val_loss: 0.5814 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67184 to 0.67271, saving model to model/fullrun3/CV_3\\model_4.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5095 - accuracy: 0.7415 - val_loss: 0.5775 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67271 to 0.67393, saving model to model/fullrun3/CV_3\\model_4.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5091 - accuracy: 0.7424 - val_loss: 0.5816 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67393\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5042 - accuracy: 0.7430 - val_loss: 0.5775 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.67393 to 0.67532, saving model to model/fullrun3/CV_3\\model_4.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5019 - accuracy: 0.7487 - val_loss: 0.5743 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67532\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4976 - accuracy: 0.7502 - val_loss: 0.5768 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.67532 to 0.67811, saving model to model/fullrun3/CV_3\\model_4.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4930 - accuracy: 0.7531 - val_loss: 0.5823 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67811\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4892 - accuracy: 0.7552 - val_loss: 0.5775 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.67811 to 0.67863, saving model to model/fullrun3/CV_3\\model_4.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4850 - accuracy: 0.7590 - val_loss: 0.5763 - val_accuracy: 0.6778\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67863\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4855 - accuracy: 0.7578 - val_loss: 0.5830 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67863\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4812 - accuracy: 0.7627 - val_loss: 0.5804 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67863\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4785 - accuracy: 0.7635 - val_loss: 0.5824 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67863\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4812 - accuracy: 0.7602 - val_loss: 0.5796 - val_accuracy: 0.6772\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67863\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4756 - accuracy: 0.7646 - val_loss: 0.5824 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67863\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4735 - accuracy: 0.7658 - val_loss: 0.5809 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67863\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4708 - accuracy: 0.7671 - val_loss: 0.5796 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67863\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4908 - accuracy: 0.7538 - val_loss: 0.5790 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67863\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4921 - accuracy: 0.7525 - val_loss: 0.5775 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67863\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.5248 - accuracy: 0.7296 - val_loss: 0.5765 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67619, saving model to model/fullrun3/CV_3\\model_5.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5188 - accuracy: 0.7355 - val_loss: 0.5841 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67619\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5138 - accuracy: 0.7376 - val_loss: 0.5785 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67619\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5070 - accuracy: 0.7438 - val_loss: 0.5779 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67619\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5052 - accuracy: 0.7445 - val_loss: 0.5799 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67619\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4991 - accuracy: 0.7492 - val_loss: 0.5848 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67619\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4980 - accuracy: 0.7502 - val_loss: 0.5805 - val_accuracy: 0.6785\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.67619 to 0.67846, saving model to model/fullrun3/CV_3\\model_5.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4978 - accuracy: 0.7499 - val_loss: 0.5807 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67846\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4907 - accuracy: 0.7556 - val_loss: 0.5854 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67846\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4886 - accuracy: 0.7557 - val_loss: 0.5793 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.67846 to 0.67863, saving model to model/fullrun3/CV_3\\model_5.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4833 - accuracy: 0.7609 - val_loss: 0.5779 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67863\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4830 - accuracy: 0.7626 - val_loss: 0.5876 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67863\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4787 - accuracy: 0.7626 - val_loss: 0.5823 - val_accuracy: 0.6772\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67863\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4801 - accuracy: 0.7619 - val_loss: 0.5798 - val_accuracy: 0.6788\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.67863 to 0.67881, saving model to model/fullrun3/CV_3\\model_5.h5\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4774 - accuracy: 0.7659 - val_loss: 0.5807 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67881\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4725 - accuracy: 0.7664 - val_loss: 0.5791 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67881\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4712 - accuracy: 0.7692 - val_loss: 0.5785 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67881\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4679 - accuracy: 0.7707 - val_loss: 0.5800 - val_accuracy: 0.6806\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.67881 to 0.68055, saving model to model/fullrun3/CV_3\\model_5.h5\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4802 - accuracy: 0.7636 - val_loss: 0.5803 - val_accuracy: 0.6778\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68055\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4789 - accuracy: 0.7633 - val_loss: 0.5789 - val_accuracy: 0.6792\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68055\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4916 - accuracy: 0.7530 - val_loss: 0.5775 - val_accuracy: 0.6792\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68055\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4920 - accuracy: 0.7527 - val_loss: 0.5731 - val_accuracy: 0.6795\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.68055\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4876 - accuracy: 0.7568 - val_loss: 0.5753 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.68055\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4873 - accuracy: 0.7548 - val_loss: 0.5733 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.68055 to 0.68247, saving model to model/fullrun3/CV_3\\model_5.h5\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4887 - accuracy: 0.7560 - val_loss: 0.5725 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.68247\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4842 - accuracy: 0.7589 - val_loss: 0.5726 - val_accuracy: 0.6811\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.68247\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4791 - accuracy: 0.7603 - val_loss: 0.5719 - val_accuracy: 0.6816\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.68247\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4845 - accuracy: 0.7590 - val_loss: 0.5747 - val_accuracy: 0.6835\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.68247 to 0.68351, saving model to model/fullrun3/CV_3\\model_5.h5\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4810 - accuracy: 0.7609 - val_loss: 0.5746 - val_accuracy: 0.6819\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.68351\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4830 - accuracy: 0.7600 - val_loss: 0.5779 - val_accuracy: 0.6811\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.68351\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4789 - accuracy: 0.7628 - val_loss: 0.5741 - val_accuracy: 0.6802\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.68351\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4747 - accuracy: 0.7664 - val_loss: 0.5753 - val_accuracy: 0.6821\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.68351\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4756 - accuracy: 0.7615 - val_loss: 0.5769 - val_accuracy: 0.6772\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.68351\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4754 - accuracy: 0.7651 - val_loss: 0.5762 - val_accuracy: 0.6821\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.68351\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4780 - accuracy: 0.7628 - val_loss: 0.5782 - val_accuracy: 0.6823\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.68351\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4740 - accuracy: 0.7659 - val_loss: 0.5748 - val_accuracy: 0.6795\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.68351\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.4708 - accuracy: 0.7670 - val_loss: 0.5762 - val_accuracy: 0.6788\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.68351\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4742 - accuracy: 0.7664 - val_loss: 0.5753 - val_accuracy: 0.6811\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.68351\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.5340 - accuracy: 0.7218 - val_loss: 0.5774 - val_accuracy: 0.6790\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67898, saving model to model/fullrun3/CV_3\\model_6.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5239 - accuracy: 0.7312 - val_loss: 0.5775 - val_accuracy: 0.6788\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67898\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5200 - accuracy: 0.7315 - val_loss: 0.5790 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67898\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5148 - accuracy: 0.7385 - val_loss: 0.5760 - val_accuracy: 0.6793\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67898 to 0.67933, saving model to model/fullrun3/CV_3\\model_6.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5110 - accuracy: 0.7391 - val_loss: 0.5801 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67933\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5054 - accuracy: 0.7432 - val_loss: 0.5816 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67933\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5045 - accuracy: 0.7443 - val_loss: 0.5749 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67933\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5027 - accuracy: 0.7464 - val_loss: 0.5741 - val_accuracy: 0.6814\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.67933 to 0.68142, saving model to model/fullrun3/CV_3\\model_6.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4974 - accuracy: 0.7511 - val_loss: 0.5778 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68142\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4961 - accuracy: 0.7512 - val_loss: 0.5739 - val_accuracy: 0.6837\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.68142 to 0.68369, saving model to model/fullrun3/CV_3\\model_6.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4929 - accuracy: 0.7546 - val_loss: 0.5716 - val_accuracy: 0.6865\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.68369 to 0.68648, saving model to model/fullrun3/CV_3\\model_6.h5\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4881 - accuracy: 0.7566 - val_loss: 0.5792 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68648\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.4841 - accuracy: 0.7581 - val_loss: 0.5781 - val_accuracy: 0.6790\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68648\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4831 - accuracy: 0.7614 - val_loss: 0.5806 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68648\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4831 - accuracy: 0.7601 - val_loss: 0.5795 - val_accuracy: 0.6797\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68648\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4808 - accuracy: 0.7623 - val_loss: 0.5773 - val_accuracy: 0.6804\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68648\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4758 - accuracy: 0.7644 - val_loss: 0.5727 - val_accuracy: 0.6880\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.68648 to 0.68804, saving model to model/fullrun3/CV_3\\model_6.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4761 - accuracy: 0.7654 - val_loss: 0.5742 - val_accuracy: 0.6863\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68804\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4805 - accuracy: 0.7618 - val_loss: 0.5790 - val_accuracy: 0.6776\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68804\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4788 - accuracy: 0.7630 - val_loss: 0.5794 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68804\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4811 - accuracy: 0.7617 - val_loss: 0.5799 - val_accuracy: 0.6793\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68804\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4797 - accuracy: 0.7625 - val_loss: 0.5757 - val_accuracy: 0.6818\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.68804\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4791 - accuracy: 0.7603 - val_loss: 0.5776 - val_accuracy: 0.6818\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.68804\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4783 - accuracy: 0.7602 - val_loss: 0.5781 - val_accuracy: 0.6799\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.68804\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4792 - accuracy: 0.7623 - val_loss: 0.5752 - val_accuracy: 0.6847\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.68804\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4776 - accuracy: 0.7642 - val_loss: 0.5757 - val_accuracy: 0.6853\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.68804\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4718 - accuracy: 0.7661 - val_loss: 0.5751 - val_accuracy: 0.6833\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.68804\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5280 - accuracy: 0.7263 - val_loss: 0.5796 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67410, saving model to model/fullrun3/CV_3\\model_7.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5179 - accuracy: 0.7353 - val_loss: 0.5791 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.67410 to 0.67497, saving model to model/fullrun3/CV_3\\model_7.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5124 - accuracy: 0.7396 - val_loss: 0.5789 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67497\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5080 - accuracy: 0.7438 - val_loss: 0.5776 - val_accuracy: 0.6760\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67497 to 0.67602, saving model to model/fullrun3/CV_3\\model_7.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5059 - accuracy: 0.7454 - val_loss: 0.5789 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67602\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5007 - accuracy: 0.7486 - val_loss: 0.5814 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67602\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4985 - accuracy: 0.7509 - val_loss: 0.5777 - val_accuracy: 0.6785\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.67602 to 0.67846, saving model to model/fullrun3/CV_3\\model_7.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4959 - accuracy: 0.7551 - val_loss: 0.5836 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67846\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4942 - accuracy: 0.7535 - val_loss: 0.5824 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67846\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4908 - accuracy: 0.7536 - val_loss: 0.5774 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67846\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4869 - accuracy: 0.7586 - val_loss: 0.5808 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67846\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4825 - accuracy: 0.7602 - val_loss: 0.5831 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67846\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4792 - accuracy: 0.7619 - val_loss: 0.5783 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67846\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.4804 - accuracy: 0.7643 - val_loss: 0.5864 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67846\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4783 - accuracy: 0.7658 - val_loss: 0.5851 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67846\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4779 - accuracy: 0.7640 - val_loss: 0.5817 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67846\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4686 - accuracy: 0.7695 - val_loss: 0.5821 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67846\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5176 - accuracy: 0.7370 - val_loss: 0.5830 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67166, saving model to model/fullrun3/CV_3\\model_8.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5091 - accuracy: 0.7427 - val_loss: 0.5781 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.67166 to 0.67288, saving model to model/fullrun3/CV_3\\model_8.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5027 - accuracy: 0.7468 - val_loss: 0.5842 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67288\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5009 - accuracy: 0.7510 - val_loss: 0.5795 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67288 to 0.67375, saving model to model/fullrun3/CV_3\\model_8.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4984 - accuracy: 0.7500 - val_loss: 0.5855 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67375\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4905 - accuracy: 0.7564 - val_loss: 0.5836 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67375\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4897 - accuracy: 0.7553 - val_loss: 0.5839 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67375\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4851 - accuracy: 0.7591 - val_loss: 0.5890 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67375\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4855 - accuracy: 0.7627 - val_loss: 0.5905 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67375\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4817 - accuracy: 0.7608 - val_loss: 0.5799 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67375\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4761 - accuracy: 0.7649 - val_loss: 0.5834 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67375\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4779 - accuracy: 0.7663 - val_loss: 0.5909 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67375\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4733 - accuracy: 0.7682 - val_loss: 0.5876 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67375\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4753 - accuracy: 0.7675 - val_loss: 0.5896 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67375\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.5373 - accuracy: 0.7207 - val_loss: 0.5766 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67515, saving model to model/fullrun3/CV_3\\model_9.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5319 - accuracy: 0.7224 - val_loss: 0.5765 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67515\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5292 - accuracy: 0.7241 - val_loss: 0.5737 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67515 to 0.67863, saving model to model/fullrun3/CV_3\\model_9.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5253 - accuracy: 0.7288 - val_loss: 0.5788 - val_accuracy: 0.6776\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67863\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5230 - accuracy: 0.7304 - val_loss: 0.5742 - val_accuracy: 0.6785\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67863\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5212 - accuracy: 0.7315 - val_loss: 0.5714 - val_accuracy: 0.6835\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.67863 to 0.68351, saving model to model/fullrun3/CV_3\\model_9.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5156 - accuracy: 0.7352 - val_loss: 0.5762 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68351\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5119 - accuracy: 0.7382 - val_loss: 0.5776 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.68351\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5093 - accuracy: 0.7395 - val_loss: 0.5708 - val_accuracy: 0.6844\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.68351 to 0.68438, saving model to model/fullrun3/CV_3\\model_9.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5086 - accuracy: 0.7387 - val_loss: 0.5761 - val_accuracy: 0.6823\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68438\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.5042 - accuracy: 0.7432 - val_loss: 0.5692 - val_accuracy: 0.6846\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.68438 to 0.68456, saving model to model/fullrun3/CV_3\\model_9.h5\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5033 - accuracy: 0.7489 - val_loss: 0.5684 - val_accuracy: 0.6839\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68456\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4998 - accuracy: 0.7484 - val_loss: 0.5751 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68456\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4978 - accuracy: 0.7477 - val_loss: 0.5714 - val_accuracy: 0.6835\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.68456\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4984 - accuracy: 0.7490 - val_loss: 0.5730 - val_accuracy: 0.6828\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.68456\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4947 - accuracy: 0.7527 - val_loss: 0.5713 - val_accuracy: 0.6849\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.68456 to 0.68491, saving model to model/fullrun3/CV_3\\model_9.h5\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4937 - accuracy: 0.7505 - val_loss: 0.5736 - val_accuracy: 0.6809\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68491\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4907 - accuracy: 0.7534 - val_loss: 0.5721 - val_accuracy: 0.6839\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68491\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4885 - accuracy: 0.7559 - val_loss: 0.5712 - val_accuracy: 0.6846\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68491\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4889 - accuracy: 0.7567 - val_loss: 0.5721 - val_accuracy: 0.6853\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.68491 to 0.68526, saving model to model/fullrun3/CV_3\\model_9.h5\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4848 - accuracy: 0.7578 - val_loss: 0.5746 - val_accuracy: 0.6807\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68526\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4817 - accuracy: 0.7611 - val_loss: 0.5745 - val_accuracy: 0.6833\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.68526\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4847 - accuracy: 0.7567 - val_loss: 0.5763 - val_accuracy: 0.6799\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.68526\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4826 - accuracy: 0.7581 - val_loss: 0.5739 - val_accuracy: 0.6839\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.68526\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4816 - accuracy: 0.7619 - val_loss: 0.5751 - val_accuracy: 0.6823\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.68526\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4811 - accuracy: 0.7606 - val_loss: 0.5827 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.68526\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4772 - accuracy: 0.7630 - val_loss: 0.5741 - val_accuracy: 0.6844\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.68526\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4766 - accuracy: 0.7637 - val_loss: 0.5794 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.68526\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4758 - accuracy: 0.7639 - val_loss: 0.5850 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.68526\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4767 - accuracy: 0.7652 - val_loss: 0.5776 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.68526\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 9s 82ms/step - loss: 0.6724 - accuracy: 0.5677 - val_loss: 0.6428 - val_accuracy: 0.5817\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58174, saving model to model/fullrun3/CV_4\\model_0.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.6328 - accuracy: 0.5971 - val_loss: 0.6241 - val_accuracy: 0.6237\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.58174 to 0.62374, saving model to model/fullrun3/CV_4\\model_0.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.6172 - accuracy: 0.6289 - val_loss: 0.6133 - val_accuracy: 0.6398\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.62374 to 0.63977, saving model to model/fullrun3/CV_4\\model_0.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.5991 - accuracy: 0.6541 - val_loss: 0.6075 - val_accuracy: 0.6422\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.63977 to 0.64221, saving model to model/fullrun3/CV_4\\model_0.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5871 - accuracy: 0.6678 - val_loss: 0.5963 - val_accuracy: 0.6532\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.64221 to 0.65319, saving model to model/fullrun3/CV_4\\model_0.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5769 - accuracy: 0.6782 - val_loss: 0.5920 - val_accuracy: 0.6530\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.65319\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5669 - accuracy: 0.6871 - val_loss: 0.5877 - val_accuracy: 0.6643\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.65319 to 0.66434, saving model to model/fullrun3/CV_4\\model_0.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5592 - accuracy: 0.6969 - val_loss: 0.5921 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.66434 to 0.66783, saving model to model/fullrun3/CV_4\\model_0.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5542 - accuracy: 0.7013 - val_loss: 0.5847 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.66783 to 0.66975, saving model to model/fullrun3/CV_4\\model_0.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5487 - accuracy: 0.7049 - val_loss: 0.5948 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66975\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5430 - accuracy: 0.7121 - val_loss: 0.5861 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66975\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5367 - accuracy: 0.7177 - val_loss: 0.5850 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66975\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5313 - accuracy: 0.7228 - val_loss: 0.5863 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66975\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5283 - accuracy: 0.7235 - val_loss: 0.5872 - val_accuracy: 0.6649\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66975\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5256 - accuracy: 0.7236 - val_loss: 0.5966 - val_accuracy: 0.6621\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66975\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5213 - accuracy: 0.7277 - val_loss: 0.5878 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66975\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.5171 - accuracy: 0.7342 - val_loss: 0.5879 - val_accuracy: 0.6591\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66975\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5141 - accuracy: 0.7351 - val_loss: 0.5885 - val_accuracy: 0.6616\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66975\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5138 - accuracy: 0.7360 - val_loss: 0.5872 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.66975\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5597 - accuracy: 0.6990 - val_loss: 0.5860 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66626, saving model to model/fullrun3/CV_4\\model_1.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5477 - accuracy: 0.7061 - val_loss: 0.5945 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66626\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5416 - accuracy: 0.7148 - val_loss: 0.5863 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66626 to 0.66992, saving model to model/fullrun3/CV_4\\model_1.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.5324 - accuracy: 0.7237 - val_loss: 0.5847 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66992\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5264 - accuracy: 0.7254 - val_loss: 0.5878 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66992\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5224 - accuracy: 0.7314 - val_loss: 0.5916 - val_accuracy: 0.6617\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66992\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5181 - accuracy: 0.7334 - val_loss: 0.5864 - val_accuracy: 0.6656\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66992\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5178 - accuracy: 0.7348 - val_loss: 0.5882 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66992\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5130 - accuracy: 0.7356 - val_loss: 0.5914 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66992\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5063 - accuracy: 0.7402 - val_loss: 0.5885 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66992\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5044 - accuracy: 0.7454 - val_loss: 0.5888 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.66992 to 0.67428, saving model to model/fullrun3/CV_4\\model_1.h5\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5070 - accuracy: 0.7414 - val_loss: 0.5898 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67428\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4998 - accuracy: 0.7486 - val_loss: 0.5909 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67428\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4980 - accuracy: 0.7486 - val_loss: 0.5917 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67428\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4948 - accuracy: 0.7518 - val_loss: 0.5921 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67428\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4910 - accuracy: 0.7528 - val_loss: 0.5947 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67428\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4917 - accuracy: 0.7520 - val_loss: 0.5933 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67428\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4849 - accuracy: 0.7600 - val_loss: 0.5987 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67428\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4847 - accuracy: 0.7588 - val_loss: 0.5948 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67428\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5035 - accuracy: 0.7451 - val_loss: 0.5934 - val_accuracy: 0.6642\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67428\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4954 - accuracy: 0.7506 - val_loss: 0.5907 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67428\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5482 - accuracy: 0.7096 - val_loss: 0.5885 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66399, saving model to model/fullrun3/CV_4\\model_2.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5366 - accuracy: 0.7188 - val_loss: 0.5939 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66399\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5309 - accuracy: 0.7221 - val_loss: 0.5952 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66399\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5235 - accuracy: 0.7287 - val_loss: 0.5932 - val_accuracy: 0.6626\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66399\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5160 - accuracy: 0.7357 - val_loss: 0.5885 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66399\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5121 - accuracy: 0.7364 - val_loss: 0.5952 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66399\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5101 - accuracy: 0.7395 - val_loss: 0.5894 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66399 to 0.66905, saving model to model/fullrun3/CV_4\\model_2.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5025 - accuracy: 0.7466 - val_loss: 0.5912 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66905\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5048 - accuracy: 0.7444 - val_loss: 0.5954 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66905\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4968 - accuracy: 0.7488 - val_loss: 0.5926 - val_accuracy: 0.6636\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66905\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4956 - accuracy: 0.7521 - val_loss: 0.5905 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.66905 to 0.67201, saving model to model/fullrun3/CV_4\\model_2.h5\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4973 - accuracy: 0.7490 - val_loss: 0.5930 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67201\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4908 - accuracy: 0.7552 - val_loss: 0.5921 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67201\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4875 - accuracy: 0.7581 - val_loss: 0.5944 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67201\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4874 - accuracy: 0.7563 - val_loss: 0.5948 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67201\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4832 - accuracy: 0.7595 - val_loss: 0.5979 - val_accuracy: 0.6642\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67201\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4817 - accuracy: 0.7605 - val_loss: 0.5950 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67201\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4779 - accuracy: 0.7623 - val_loss: 0.5968 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67201\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4784 - accuracy: 0.7623 - val_loss: 0.5984 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67201\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4860 - accuracy: 0.7570 - val_loss: 0.5975 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67201\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4815 - accuracy: 0.7604 - val_loss: 0.5994 - val_accuracy: 0.6595\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67201\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.5406 - accuracy: 0.7155 - val_loss: 0.5922 - val_accuracy: 0.6633\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66330, saving model to model/fullrun3/CV_4\\model_3.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.5324 - accuracy: 0.7234 - val_loss: 0.5956 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66330\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5245 - accuracy: 0.7299 - val_loss: 0.5909 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66330 to 0.66748, saving model to model/fullrun3/CV_4\\model_3.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5179 - accuracy: 0.7365 - val_loss: 0.5933 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66748\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5129 - accuracy: 0.7391 - val_loss: 0.5897 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.66748 to 0.66957, saving model to model/fullrun3/CV_4\\model_3.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5102 - accuracy: 0.7405 - val_loss: 0.5947 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66957\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5053 - accuracy: 0.7434 - val_loss: 0.5903 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66957\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5017 - accuracy: 0.7477 - val_loss: 0.5905 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66957\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5027 - accuracy: 0.7451 - val_loss: 0.5986 - val_accuracy: 0.6589\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66957\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4956 - accuracy: 0.7503 - val_loss: 0.5935 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66957\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4935 - accuracy: 0.7541 - val_loss: 0.5906 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66957\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4914 - accuracy: 0.7550 - val_loss: 0.5932 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66957\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4870 - accuracy: 0.7575 - val_loss: 0.5925 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66957\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4822 - accuracy: 0.7613 - val_loss: 0.5961 - val_accuracy: 0.6626\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66957\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4863 - accuracy: 0.7576 - val_loss: 0.5970 - val_accuracy: 0.6624\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66957\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5240 - accuracy: 0.7318 - val_loss: 0.5904 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66609, saving model to model/fullrun3/CV_4\\model_4.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5159 - accuracy: 0.7361 - val_loss: 0.5942 - val_accuracy: 0.6596\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66609\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5125 - accuracy: 0.7409 - val_loss: 0.5934 - val_accuracy: 0.6616\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66609\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5064 - accuracy: 0.7438 - val_loss: 0.5925 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66609\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5024 - accuracy: 0.7467 - val_loss: 0.5914 - val_accuracy: 0.6642\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66609\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4995 - accuracy: 0.7486 - val_loss: 0.5951 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.66609 to 0.66731, saving model to model/fullrun3/CV_4\\model_4.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4931 - accuracy: 0.7536 - val_loss: 0.5929 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66731\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4901 - accuracy: 0.7560 - val_loss: 0.5923 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.66731 to 0.67044, saving model to model/fullrun3/CV_4\\model_4.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4915 - accuracy: 0.7531 - val_loss: 0.5967 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67044\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4829 - accuracy: 0.7608 - val_loss: 0.5947 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67044\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4820 - accuracy: 0.7612 - val_loss: 0.5961 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67044\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4795 - accuracy: 0.7616 - val_loss: 0.5986 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67044\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4803 - accuracy: 0.7632 - val_loss: 0.5963 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67044\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4742 - accuracy: 0.7680 - val_loss: 0.5960 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67044\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4758 - accuracy: 0.7656 - val_loss: 0.6016 - val_accuracy: 0.6649\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67044\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4881 - accuracy: 0.7561 - val_loss: 0.5930 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67044\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4840 - accuracy: 0.7605 - val_loss: 0.5922 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67044\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4819 - accuracy: 0.7604 - val_loss: 0.5952 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.67044 to 0.67323, saving model to model/fullrun3/CV_4\\model_4.h5\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.4810 - accuracy: 0.7601 - val_loss: 0.5954 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67323\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4847 - accuracy: 0.7569 - val_loss: 0.5992 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67323\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4794 - accuracy: 0.7622 - val_loss: 0.5977 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67323\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4905 - accuracy: 0.7537 - val_loss: 0.5898 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67323\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4905 - accuracy: 0.7533 - val_loss: 0.5951 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67323\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4860 - accuracy: 0.7569 - val_loss: 0.5926 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67323\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4879 - accuracy: 0.7524 - val_loss: 0.5911 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.67323 to 0.67445, saving model to model/fullrun3/CV_4\\model_4.h5\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4853 - accuracy: 0.7575 - val_loss: 0.5925 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67445\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4832 - accuracy: 0.7577 - val_loss: 0.5912 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.67445 to 0.67515, saving model to model/fullrun3/CV_4\\model_4.h5\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4843 - accuracy: 0.7568 - val_loss: 0.5908 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.67515\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4817 - accuracy: 0.7618 - val_loss: 0.5930 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67515\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4797 - accuracy: 0.7629 - val_loss: 0.5929 - val_accuracy: 0.6682\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67515\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4799 - accuracy: 0.7608 - val_loss: 0.5925 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.67515\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4745 - accuracy: 0.7653 - val_loss: 0.5923 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.67515\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4776 - accuracy: 0.7635 - val_loss: 0.5935 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.67515\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4794 - accuracy: 0.7616 - val_loss: 0.5924 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.67515\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4735 - accuracy: 0.7654 - val_loss: 0.5953 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.67515\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4741 - accuracy: 0.7646 - val_loss: 0.5940 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.67515\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4748 - accuracy: 0.7646 - val_loss: 0.5941 - val_accuracy: 0.6682\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.67515\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5327 - accuracy: 0.7237 - val_loss: 0.5938 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66312, saving model to model/fullrun3/CV_4\\model_5.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5264 - accuracy: 0.7285 - val_loss: 0.5975 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66312\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5235 - accuracy: 0.7306 - val_loss: 0.5946 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66312 to 0.66591, saving model to model/fullrun3/CV_4\\model_5.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5165 - accuracy: 0.7331 - val_loss: 0.5948 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66591\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5119 - accuracy: 0.7405 - val_loss: 0.5920 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.66591 to 0.66975, saving model to model/fullrun3/CV_4\\model_5.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5079 - accuracy: 0.7423 - val_loss: 0.5984 - val_accuracy: 0.6586\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66975\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5035 - accuracy: 0.7421 - val_loss: 0.5915 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66975 to 0.66992, saving model to model/fullrun3/CV_4\\model_5.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5022 - accuracy: 0.7454 - val_loss: 0.5918 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.66992 to 0.67114, saving model to model/fullrun3/CV_4\\model_5.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5012 - accuracy: 0.7463 - val_loss: 0.5971 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67114\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4939 - accuracy: 0.7523 - val_loss: 0.5920 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67114\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4902 - accuracy: 0.7566 - val_loss: 0.5946 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67114\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4910 - accuracy: 0.7561 - val_loss: 0.5960 - val_accuracy: 0.6656\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67114\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4856 - accuracy: 0.7587 - val_loss: 0.5948 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.67114 to 0.67149, saving model to model/fullrun3/CV_4\\model_5.h5\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4802 - accuracy: 0.7621 - val_loss: 0.5958 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67149\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4834 - accuracy: 0.7594 - val_loss: 0.6030 - val_accuracy: 0.6589\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67149\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4851 - accuracy: 0.7574 - val_loss: 0.5972 - val_accuracy: 0.6656\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67149\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4820 - accuracy: 0.7604 - val_loss: 0.5942 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67149\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4788 - accuracy: 0.7621 - val_loss: 0.5952 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67149\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4785 - accuracy: 0.7628 - val_loss: 0.5940 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.67149 to 0.67201, saving model to model/fullrun3/CV_4\\model_5.h5\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4799 - accuracy: 0.7617 - val_loss: 0.5999 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67201\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4780 - accuracy: 0.7625 - val_loss: 0.5946 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67201\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4815 - accuracy: 0.7608 - val_loss: 0.5882 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.67201 to 0.67428, saving model to model/fullrun3/CV_4\\model_5.h5\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4795 - accuracy: 0.7625 - val_loss: 0.5945 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67428\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4810 - accuracy: 0.7621 - val_loss: 0.5900 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67428\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4749 - accuracy: 0.7645 - val_loss: 0.5923 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67428\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4747 - accuracy: 0.7656 - val_loss: 0.5919 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67428\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4764 - accuracy: 0.7631 - val_loss: 0.5904 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.67428\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4735 - accuracy: 0.7650 - val_loss: 0.5923 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.67428\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4711 - accuracy: 0.7668 - val_loss: 0.5946 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67428\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4706 - accuracy: 0.7669 - val_loss: 0.5953 - val_accuracy: 0.6642\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67428\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4693 - accuracy: 0.7690 - val_loss: 0.5940 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.67428\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4653 - accuracy: 0.7718 - val_loss: 0.5930 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.67428\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5288 - accuracy: 0.7262 - val_loss: 0.5900 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66521, saving model to model/fullrun3/CV_4\\model_6.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5214 - accuracy: 0.7339 - val_loss: 0.5936 - val_accuracy: 0.6574\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66521\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5185 - accuracy: 0.7359 - val_loss: 0.5938 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66521\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5120 - accuracy: 0.7397 - val_loss: 0.5986 - val_accuracy: 0.6527\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66521\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5087 - accuracy: 0.7416 - val_loss: 0.5921 - val_accuracy: 0.6626\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66521\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5036 - accuracy: 0.7452 - val_loss: 0.5966 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66521\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5010 - accuracy: 0.7462 - val_loss: 0.5922 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66521 to 0.66835, saving model to model/fullrun3/CV_4\\model_6.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4983 - accuracy: 0.7501 - val_loss: 0.5944 - val_accuracy: 0.6643\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66835\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4984 - accuracy: 0.7488 - val_loss: 0.5918 - val_accuracy: 0.6656\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66835\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4902 - accuracy: 0.7549 - val_loss: 0.5931 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.66835 to 0.66922, saving model to model/fullrun3/CV_4\\model_6.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4864 - accuracy: 0.7580 - val_loss: 0.5970 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66922\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4862 - accuracy: 0.7574 - val_loss: 0.6042 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66922\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4830 - accuracy: 0.7604 - val_loss: 0.5980 - val_accuracy: 0.6635\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66922\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4785 - accuracy: 0.7641 - val_loss: 0.5963 - val_accuracy: 0.6642\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66922\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4802 - accuracy: 0.7615 - val_loss: 0.5986 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66922\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4797 - accuracy: 0.7642 - val_loss: 0.5971 - val_accuracy: 0.6626\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66922\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4788 - accuracy: 0.7645 - val_loss: 0.5929 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.66922 to 0.67236, saving model to model/fullrun3/CV_4\\model_6.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4739 - accuracy: 0.7677 - val_loss: 0.5970 - val_accuracy: 0.6649\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67236\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4762 - accuracy: 0.7643 - val_loss: 0.5948 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67236\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4745 - accuracy: 0.7647 - val_loss: 0.6026 - val_accuracy: 0.6633\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67236\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4706 - accuracy: 0.7677 - val_loss: 0.5952 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67236\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4772 - accuracy: 0.7648 - val_loss: 0.5906 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.67236 to 0.67341, saving model to model/fullrun3/CV_4\\model_6.h5\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4747 - accuracy: 0.7641 - val_loss: 0.5956 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67341\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4744 - accuracy: 0.7655 - val_loss: 0.5923 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67341\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4715 - accuracy: 0.7676 - val_loss: 0.5934 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67341\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4677 - accuracy: 0.7688 - val_loss: 0.5966 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67341\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4685 - accuracy: 0.7721 - val_loss: 0.5939 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.67341\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4679 - accuracy: 0.7691 - val_loss: 0.5950 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.67341 to 0.67428, saving model to model/fullrun3/CV_4\\model_6.h5\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4700 - accuracy: 0.7680 - val_loss: 0.5960 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67428\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4645 - accuracy: 0.7740 - val_loss: 0.5993 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67428\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4622 - accuracy: 0.7756 - val_loss: 0.5974 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.67428\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4620 - accuracy: 0.7725 - val_loss: 0.5961 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.67428\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4706 - accuracy: 0.7673 - val_loss: 0.5959 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.67428\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4762 - accuracy: 0.7657 - val_loss: 0.5932 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.67428\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4654 - accuracy: 0.7702 - val_loss: 0.5942 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.67428\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4662 - accuracy: 0.7723 - val_loss: 0.5933 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.67428\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4678 - accuracy: 0.7684 - val_loss: 0.5941 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.67428\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4725 - accuracy: 0.7652 - val_loss: 0.5934 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.67428\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5273 - accuracy: 0.7284 - val_loss: 0.5952 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65667, saving model to model/fullrun3/CV_4\\model_7.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5220 - accuracy: 0.7309 - val_loss: 0.5963 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65667 to 0.65929, saving model to model/fullrun3/CV_4\\model_7.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5195 - accuracy: 0.7335 - val_loss: 0.5930 - val_accuracy: 0.6623\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.65929 to 0.66225, saving model to model/fullrun3/CV_4\\model_7.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5131 - accuracy: 0.7397 - val_loss: 0.5969 - val_accuracy: 0.6595\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66225\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5081 - accuracy: 0.7425 - val_loss: 0.5976 - val_accuracy: 0.6574\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66225\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5046 - accuracy: 0.7449 - val_loss: 0.5985 - val_accuracy: 0.6551\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66225\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5039 - accuracy: 0.7454 - val_loss: 0.5948 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66225 to 0.66452, saving model to model/fullrun3/CV_4\\model_7.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5010 - accuracy: 0.7466 - val_loss: 0.5976 - val_accuracy: 0.6603\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66452\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4988 - accuracy: 0.7488 - val_loss: 0.5963 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66452\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4937 - accuracy: 0.7529 - val_loss: 0.5951 - val_accuracy: 0.6603\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66452\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4900 - accuracy: 0.7579 - val_loss: 0.6003 - val_accuracy: 0.6521\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66452\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4893 - accuracy: 0.7555 - val_loss: 0.6034 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66452\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4885 - accuracy: 0.7567 - val_loss: 0.5995 - val_accuracy: 0.6568\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66452\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4833 - accuracy: 0.7629 - val_loss: 0.5989 - val_accuracy: 0.6572\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66452\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4834 - accuracy: 0.7602 - val_loss: 0.6047 - val_accuracy: 0.6518\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66452\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4796 - accuracy: 0.7632 - val_loss: 0.5988 - val_accuracy: 0.6562\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66452\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4818 - accuracy: 0.7613 - val_loss: 0.5956 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66452\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.5152 - accuracy: 0.7392 - val_loss: 0.5967 - val_accuracy: 0.6494\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64936, saving model to model/fullrun3/CV_4\\model_8.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5104 - accuracy: 0.7402 - val_loss: 0.5969 - val_accuracy: 0.6514\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.64936 to 0.65145, saving model to model/fullrun3/CV_4\\model_8.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5077 - accuracy: 0.7441 - val_loss: 0.6001 - val_accuracy: 0.6506\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.65145\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5034 - accuracy: 0.7489 - val_loss: 0.5998 - val_accuracy: 0.6499\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65145\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4974 - accuracy: 0.7522 - val_loss: 0.5974 - val_accuracy: 0.6530\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.65145 to 0.65302, saving model to model/fullrun3/CV_4\\model_8.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4984 - accuracy: 0.7495 - val_loss: 0.5986 - val_accuracy: 0.6504\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.65302\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4922 - accuracy: 0.7554 - val_loss: 0.5984 - val_accuracy: 0.6558\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.65302 to 0.65580, saving model to model/fullrun3/CV_4\\model_8.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4895 - accuracy: 0.7575 - val_loss: 0.6018 - val_accuracy: 0.6534\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.65580\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4901 - accuracy: 0.7567 - val_loss: 0.5988 - val_accuracy: 0.6556\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.65580\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4800 - accuracy: 0.7631 - val_loss: 0.5993 - val_accuracy: 0.6551\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.65580\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4820 - accuracy: 0.7605 - val_loss: 0.6109 - val_accuracy: 0.6476\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.65580\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4779 - accuracy: 0.7627 - val_loss: 0.6046 - val_accuracy: 0.6516\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.65580\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4777 - accuracy: 0.7654 - val_loss: 0.6025 - val_accuracy: 0.6558\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.65580\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4718 - accuracy: 0.7694 - val_loss: 0.6028 - val_accuracy: 0.6574\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.65580 to 0.65737, saving model to model/fullrun3/CV_4\\model_8.h5\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4747 - accuracy: 0.7659 - val_loss: 0.6137 - val_accuracy: 0.6495\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.65737\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4719 - accuracy: 0.7690 - val_loss: 0.6051 - val_accuracy: 0.6553\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.65737\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4697 - accuracy: 0.7697 - val_loss: 0.6027 - val_accuracy: 0.6556\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.65737\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4822 - accuracy: 0.7622 - val_loss: 0.5972 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.65737 to 0.66051, saving model to model/fullrun3/CV_4\\model_8.h5\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4803 - accuracy: 0.7609 - val_loss: 0.5976 - val_accuracy: 0.6626\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.66051 to 0.66260, saving model to model/fullrun3/CV_4\\model_8.h5\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4801 - accuracy: 0.7614 - val_loss: 0.6036 - val_accuracy: 0.6544\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66260\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4767 - accuracy: 0.7624 - val_loss: 0.6000 - val_accuracy: 0.6588\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66260\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4770 - accuracy: 0.7649 - val_loss: 0.5970 - val_accuracy: 0.6624\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.66260\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4766 - accuracy: 0.7639 - val_loss: 0.5996 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.66260\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4763 - accuracy: 0.7649 - val_loss: 0.5957 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.66260 to 0.66452, saving model to model/fullrun3/CV_4\\model_8.h5\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4743 - accuracy: 0.7657 - val_loss: 0.5983 - val_accuracy: 0.6609\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.66452\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4720 - accuracy: 0.7669 - val_loss: 0.6011 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.66452\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4740 - accuracy: 0.7656 - val_loss: 0.5942 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.66452 to 0.66765, saving model to model/fullrun3/CV_4\\model_8.h5\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4712 - accuracy: 0.7667 - val_loss: 0.5998 - val_accuracy: 0.6624\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.66765\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4709 - accuracy: 0.7695 - val_loss: 0.5973 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.66765\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4696 - accuracy: 0.7669 - val_loss: 0.6020 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.66765\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4678 - accuracy: 0.7687 - val_loss: 0.5988 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.66765\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4661 - accuracy: 0.7737 - val_loss: 0.5989 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.66765 to 0.66853, saving model to model/fullrun3/CV_4\\model_8.h5\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.4711 - accuracy: 0.7675 - val_loss: 0.5993 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.66853\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4713 - accuracy: 0.7685 - val_loss: 0.5995 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.66853\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4687 - accuracy: 0.7701 - val_loss: 0.5999 - val_accuracy: 0.6649\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.66853\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4664 - accuracy: 0.7709 - val_loss: 0.5975 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.66853\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4657 - accuracy: 0.7720 - val_loss: 0.5996 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.66853\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4644 - accuracy: 0.7733 - val_loss: 0.6026 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.66853\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4664 - accuracy: 0.7692 - val_loss: 0.5981 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.66853\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4683 - accuracy: 0.7674 - val_loss: 0.5972 - val_accuracy: 0.6642\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.66853\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4725 - accuracy: 0.7655 - val_loss: 0.5965 - val_accuracy: 0.6657\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.66853\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4682 - accuracy: 0.7711 - val_loss: 0.5997 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.66853\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5387 - accuracy: 0.7165 - val_loss: 0.5950 - val_accuracy: 0.6617\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66173, saving model to model/fullrun3/CV_4\\model_9.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5347 - accuracy: 0.7209 - val_loss: 0.5949 - val_accuracy: 0.6617\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66173\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5297 - accuracy: 0.7255 - val_loss: 0.5953 - val_accuracy: 0.6595\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66173\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5266 - accuracy: 0.7272 - val_loss: 0.5949 - val_accuracy: 0.6591\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66173\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5255 - accuracy: 0.7283 - val_loss: 0.5938 - val_accuracy: 0.6584\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66173\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5197 - accuracy: 0.7329 - val_loss: 0.5916 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66173\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5168 - accuracy: 0.7348 - val_loss: 0.5941 - val_accuracy: 0.6596\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66173\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5144 - accuracy: 0.7362 - val_loss: 0.5940 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66173\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5102 - accuracy: 0.7409 - val_loss: 0.5914 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.66173 to 0.66591, saving model to model/fullrun3/CV_4\\model_9.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5096 - accuracy: 0.7413 - val_loss: 0.5904 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.66591 to 0.66835, saving model to model/fullrun3/CV_4\\model_9.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5061 - accuracy: 0.7432 - val_loss: 0.5907 - val_accuracy: 0.6649\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66835\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5041 - accuracy: 0.7439 - val_loss: 0.5907 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66835\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5021 - accuracy: 0.7469 - val_loss: 0.5952 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66835\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4975 - accuracy: 0.7487 - val_loss: 0.5926 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66835\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4955 - accuracy: 0.7497 - val_loss: 0.5987 - val_accuracy: 0.6609\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66835\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4936 - accuracy: 0.7506 - val_loss: 0.5903 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.66835 to 0.67114, saving model to model/fullrun3/CV_4\\model_9.h5\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4959 - accuracy: 0.7502 - val_loss: 0.5937 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67114\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4893 - accuracy: 0.7568 - val_loss: 0.5945 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67114\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4889 - accuracy: 0.7551 - val_loss: 0.5925 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67114\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4864 - accuracy: 0.7566 - val_loss: 0.5922 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67114\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4864 - accuracy: 0.7587 - val_loss: 0.5923 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67114\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4810 - accuracy: 0.7614 - val_loss: 0.5932 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67114\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4816 - accuracy: 0.7624 - val_loss: 0.5976 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67114\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4797 - accuracy: 0.7635 - val_loss: 0.5918 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.67114 to 0.67375, saving model to model/fullrun3/CV_4\\model_9.h5\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4781 - accuracy: 0.7641 - val_loss: 0.5956 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67375\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4767 - accuracy: 0.7630 - val_loss: 0.5983 - val_accuracy: 0.6624\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67375\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4761 - accuracy: 0.7652 - val_loss: 0.5951 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.67375\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4752 - accuracy: 0.7641 - val_loss: 0.5933 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.67375\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4761 - accuracy: 0.7658 - val_loss: 0.6075 - val_accuracy: 0.6563\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67375\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4737 - accuracy: 0.7656 - val_loss: 0.5927 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67375\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4712 - accuracy: 0.7683 - val_loss: 0.5934 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.67375\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4688 - accuracy: 0.7676 - val_loss: 0.5988 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.67375\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4707 - accuracy: 0.7690 - val_loss: 0.5975 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.67375\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.4671 - accuracy: 0.7714 - val_loss: 0.5980 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.67375\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 10s 84ms/step - loss: 0.6705 - accuracy: 0.5643 - val_loss: 0.6422 - val_accuracy: 0.5730\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57302, saving model to model/fullrun3/CV_5\\model_0.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.6372 - accuracy: 0.5829 - val_loss: 0.6367 - val_accuracy: 0.5833\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.57302 to 0.58330, saving model to model/fullrun3/CV_5\\model_0.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.6258 - accuracy: 0.6119 - val_loss: 0.6288 - val_accuracy: 0.6068\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.58330 to 0.60683, saving model to model/fullrun3/CV_5\\model_0.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.6093 - accuracy: 0.6440 - val_loss: 0.6296 - val_accuracy: 0.6042\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.60683\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5964 - accuracy: 0.6567 - val_loss: 0.6077 - val_accuracy: 0.6441\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.60683 to 0.64413, saving model to model/fullrun3/CV_5\\model_0.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.5858 - accuracy: 0.6690 - val_loss: 0.5972 - val_accuracy: 0.6542\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.64413 to 0.65423, saving model to model/fullrun3/CV_5\\model_0.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5757 - accuracy: 0.6797 - val_loss: 0.5921 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.65423 to 0.65981, saving model to model/fullrun3/CV_5\\model_0.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5666 - accuracy: 0.6897 - val_loss: 0.6038 - val_accuracy: 0.6474\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.65981\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 80ms/step - loss: 0.5624 - accuracy: 0.6932 - val_loss: 0.5874 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.65981 to 0.66643, saving model to model/fullrun3/CV_5\\model_0.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 81ms/step - loss: 0.5535 - accuracy: 0.7018 - val_loss: 0.5928 - val_accuracy: 0.6591\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66643\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 79ms/step - loss: 0.5489 - accuracy: 0.7058 - val_loss: 0.5878 - val_accuracy: 0.6657\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66643\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5408 - accuracy: 0.7150 - val_loss: 0.5851 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.66643 to 0.66713, saving model to model/fullrun3/CV_5\\model_0.h5\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5370 - accuracy: 0.7143 - val_loss: 0.5874 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.66713 to 0.66922, saving model to model/fullrun3/CV_5\\model_0.h5\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.5347 - accuracy: 0.7169 - val_loss: 0.5868 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66922\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.5311 - accuracy: 0.7222 - val_loss: 0.5895 - val_accuracy: 0.6616\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66922\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5271 - accuracy: 0.7240 - val_loss: 0.5859 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66922\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5235 - accuracy: 0.7293 - val_loss: 0.5882 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66922\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5174 - accuracy: 0.7335 - val_loss: 0.5862 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66922\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5159 - accuracy: 0.7343 - val_loss: 0.5867 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.66922\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5156 - accuracy: 0.7336 - val_loss: 0.5876 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66922\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5109 - accuracy: 0.7384 - val_loss: 0.5894 - val_accuracy: 0.6626\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66922\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5097 - accuracy: 0.7381 - val_loss: 0.5944 - val_accuracy: 0.6586\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.66922\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5101 - accuracy: 0.7377 - val_loss: 0.5892 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.66922\n",
      "Epoch 1/100\n",
      "  6/101 [>.............................] - ETA: 7s - loss: 0.5632 - accuracy: 0.6973WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0386s vs `on_train_batch_end` time: 0.0450s). Check your callbacks.\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5635 - accuracy: 0.6953 - val_loss: 0.5844 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66521, saving model to model/fullrun3/CV_5\\model_1.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5504 - accuracy: 0.7071 - val_loss: 0.5890 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66521\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5453 - accuracy: 0.7113 - val_loss: 0.5824 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66521 to 0.66905, saving model to model/fullrun3/CV_5\\model_1.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5364 - accuracy: 0.7178 - val_loss: 0.5806 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66905\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5299 - accuracy: 0.7221 - val_loss: 0.5821 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66905\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5262 - accuracy: 0.7262 - val_loss: 0.5827 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66905\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5212 - accuracy: 0.7320 - val_loss: 0.5799 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66905\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5196 - accuracy: 0.7319 - val_loss: 0.5801 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.66905 to 0.67131, saving model to model/fullrun3/CV_5\\model_1.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5135 - accuracy: 0.7376 - val_loss: 0.5837 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67131\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5107 - accuracy: 0.7388 - val_loss: 0.5809 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67131\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5083 - accuracy: 0.7408 - val_loss: 0.5827 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67131\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5055 - accuracy: 0.7428 - val_loss: 0.5820 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67131\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5011 - accuracy: 0.7458 - val_loss: 0.5834 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67131\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5001 - accuracy: 0.7481 - val_loss: 0.5818 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67131\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4974 - accuracy: 0.7492 - val_loss: 0.5836 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67131\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4947 - accuracy: 0.7510 - val_loss: 0.5841 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67131\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4938 - accuracy: 0.7517 - val_loss: 0.5831 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67131\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4932 - accuracy: 0.7535 - val_loss: 0.5860 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67131\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5426 - accuracy: 0.7154 - val_loss: 0.5836 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66539, saving model to model/fullrun3/CV_5\\model_2.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5373 - accuracy: 0.7211 - val_loss: 0.5857 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66539\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5318 - accuracy: 0.7219 - val_loss: 0.5792 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66539 to 0.67358, saving model to model/fullrun3/CV_5\\model_2.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5226 - accuracy: 0.7301 - val_loss: 0.5786 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67358 to 0.67410, saving model to model/fullrun3/CV_5\\model_2.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5162 - accuracy: 0.7358 - val_loss: 0.5801 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67410 to 0.67741, saving model to model/fullrun3/CV_5\\model_2.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5138 - accuracy: 0.7379 - val_loss: 0.5881 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67741\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5075 - accuracy: 0.7437 - val_loss: 0.5789 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67741\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5056 - accuracy: 0.7438 - val_loss: 0.5788 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67741\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5022 - accuracy: 0.7456 - val_loss: 0.5867 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67741\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4995 - accuracy: 0.7484 - val_loss: 0.5809 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67741\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4971 - accuracy: 0.7500 - val_loss: 0.5823 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67741\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4949 - accuracy: 0.7510 - val_loss: 0.5860 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67741\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4891 - accuracy: 0.7534 - val_loss: 0.5832 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67741\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4895 - accuracy: 0.7549 - val_loss: 0.5871 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67741\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4847 - accuracy: 0.7590 - val_loss: 0.5862 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67741\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5349 - accuracy: 0.7203 - val_loss: 0.5835 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67079, saving model to model/fullrun3/CV_5\\model_3.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5272 - accuracy: 0.7297 - val_loss: 0.5891 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67079\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5203 - accuracy: 0.7338 - val_loss: 0.5848 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67079\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5146 - accuracy: 0.7371 - val_loss: 0.5802 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67079\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5079 - accuracy: 0.7418 - val_loss: 0.5832 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67079 to 0.67149, saving model to model/fullrun3/CV_5\\model_3.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5050 - accuracy: 0.7449 - val_loss: 0.5912 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67149\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4999 - accuracy: 0.7498 - val_loss: 0.5878 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.67149 to 0.67393, saving model to model/fullrun3/CV_5\\model_3.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4989 - accuracy: 0.7502 - val_loss: 0.5854 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67393\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4947 - accuracy: 0.7518 - val_loss: 0.5897 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67393\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4900 - accuracy: 0.7568 - val_loss: 0.5853 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67393\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4895 - accuracy: 0.7580 - val_loss: 0.5858 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67393\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4861 - accuracy: 0.7601 - val_loss: 0.5932 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67393\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4847 - accuracy: 0.7591 - val_loss: 0.5864 - val_accuracy: 0.6657\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67393\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4857 - accuracy: 0.7585 - val_loss: 0.5895 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67393\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4772 - accuracy: 0.7641 - val_loss: 0.5851 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67393\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4922 - accuracy: 0.7511 - val_loss: 0.5844 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67393\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4909 - accuracy: 0.7544 - val_loss: 0.5845 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.67393 to 0.67445, saving model to model/fullrun3/CV_5\\model_3.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4904 - accuracy: 0.7549 - val_loss: 0.5873 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67445\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4950 - accuracy: 0.7514 - val_loss: 0.5862 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67445\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4967 - accuracy: 0.7481 - val_loss: 0.5899 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67445\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4912 - accuracy: 0.7536 - val_loss: 0.5857 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67445\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4944 - accuracy: 0.7505 - val_loss: 0.5849 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67445\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4879 - accuracy: 0.7575 - val_loss: 0.5895 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67445\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4902 - accuracy: 0.7549 - val_loss: 0.5871 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67445\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4918 - accuracy: 0.7525 - val_loss: 0.5858 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67445\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4887 - accuracy: 0.7544 - val_loss: 0.5867 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67445\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4852 - accuracy: 0.7573 - val_loss: 0.5851 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.67445\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5347 - accuracy: 0.7201 - val_loss: 0.5840 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67428, saving model to model/fullrun3/CV_5\\model_4.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5277 - accuracy: 0.7270 - val_loss: 0.5856 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67428\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5227 - accuracy: 0.7317 - val_loss: 0.5864 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67428\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5165 - accuracy: 0.7343 - val_loss: 0.5858 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67428\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5113 - accuracy: 0.7390 - val_loss: 0.5842 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67428\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5080 - accuracy: 0.7427 - val_loss: 0.5895 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67428\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5007 - accuracy: 0.7478 - val_loss: 0.5848 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67428\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5008 - accuracy: 0.7469 - val_loss: 0.5832 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.67428 to 0.67550, saving model to model/fullrun3/CV_5\\model_4.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4981 - accuracy: 0.7511 - val_loss: 0.5882 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67550\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4930 - accuracy: 0.7528 - val_loss: 0.5836 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67550\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4923 - accuracy: 0.7542 - val_loss: 0.5854 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67550\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4898 - accuracy: 0.7570 - val_loss: 0.5914 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67550\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4870 - accuracy: 0.7584 - val_loss: 0.5898 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67550\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4833 - accuracy: 0.7615 - val_loss: 0.5944 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67550\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4781 - accuracy: 0.7642 - val_loss: 0.5887 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67550\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4875 - accuracy: 0.7589 - val_loss: 0.5907 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67550\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4852 - accuracy: 0.7575 - val_loss: 0.5851 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67550\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4825 - accuracy: 0.7599 - val_loss: 0.5893 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67550\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5254 - accuracy: 0.7294 - val_loss: 0.5871 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66800, saving model to model/fullrun3/CV_5\\model_5.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5188 - accuracy: 0.7339 - val_loss: 0.5875 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66800 to 0.66870, saving model to model/fullrun3/CV_5\\model_5.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5159 - accuracy: 0.7361 - val_loss: 0.5875 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66870 to 0.66940, saving model to model/fullrun3/CV_5\\model_5.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5101 - accuracy: 0.7411 - val_loss: 0.5887 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66940\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5036 - accuracy: 0.7449 - val_loss: 0.5852 - val_accuracy: 0.6682\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66940\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5011 - accuracy: 0.7482 - val_loss: 0.5926 - val_accuracy: 0.6643\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66940\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4951 - accuracy: 0.7523 - val_loss: 0.5912 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66940\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4935 - accuracy: 0.7542 - val_loss: 0.5893 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.66940 to 0.67166, saving model to model/fullrun3/CV_5\\model_5.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4880 - accuracy: 0.7573 - val_loss: 0.5933 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67166\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4860 - accuracy: 0.7578 - val_loss: 0.5880 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.67166 to 0.67288, saving model to model/fullrun3/CV_5\\model_5.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4852 - accuracy: 0.7591 - val_loss: 0.5902 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67288\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4803 - accuracy: 0.7615 - val_loss: 0.5958 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67288\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4794 - accuracy: 0.7647 - val_loss: 0.5960 - val_accuracy: 0.6642\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67288\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4770 - accuracy: 0.7643 - val_loss: 0.5937 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67288\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4716 - accuracy: 0.7689 - val_loss: 0.6005 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67288\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4778 - accuracy: 0.7640 - val_loss: 0.5915 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67288\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4774 - accuracy: 0.7672 - val_loss: 0.5924 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67288\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4724 - accuracy: 0.7688 - val_loss: 0.5913 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67288\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4894 - accuracy: 0.7552 - val_loss: 0.5918 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67288\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4875 - accuracy: 0.7574 - val_loss: 0.5938 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67288\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5238 - accuracy: 0.7298 - val_loss: 0.5875 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66661, saving model to model/fullrun3/CV_5\\model_6.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5167 - accuracy: 0.7372 - val_loss: 0.5843 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66661 to 0.67219, saving model to model/fullrun3/CV_5\\model_6.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5134 - accuracy: 0.7390 - val_loss: 0.5898 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67219\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5074 - accuracy: 0.7413 - val_loss: 0.5962 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67219\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5013 - accuracy: 0.7471 - val_loss: 0.5865 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67219\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4972 - accuracy: 0.7506 - val_loss: 0.5917 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67219\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4943 - accuracy: 0.7539 - val_loss: 0.5890 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67219\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4926 - accuracy: 0.7544 - val_loss: 0.5873 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67219\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4888 - accuracy: 0.7572 - val_loss: 0.5923 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67219\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4832 - accuracy: 0.7604 - val_loss: 0.5893 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67219\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4858 - accuracy: 0.7567 - val_loss: 0.5910 - val_accuracy: 0.6642\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67219\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4815 - accuracy: 0.7619 - val_loss: 0.5976 - val_accuracy: 0.6589\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67219\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5130 - accuracy: 0.7408 - val_loss: 0.5904 - val_accuracy: 0.6621\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66208, saving model to model/fullrun3/CV_5\\model_7.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5056 - accuracy: 0.7436 - val_loss: 0.5902 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66208 to 0.66661, saving model to model/fullrun3/CV_5\\model_7.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5050 - accuracy: 0.7478 - val_loss: 0.5886 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66661 to 0.66748, saving model to model/fullrun3/CV_5\\model_7.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4954 - accuracy: 0.7548 - val_loss: 0.5976 - val_accuracy: 0.6586\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66748\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4924 - accuracy: 0.7540 - val_loss: 0.5898 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66748\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4883 - accuracy: 0.7567 - val_loss: 0.6015 - val_accuracy: 0.6558\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66748\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4843 - accuracy: 0.7603 - val_loss: 0.5939 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66748\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4823 - accuracy: 0.7612 - val_loss: 0.5915 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66748\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4782 - accuracy: 0.7648 - val_loss: 0.6001 - val_accuracy: 0.6617\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66748\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4749 - accuracy: 0.7677 - val_loss: 0.5958 - val_accuracy: 0.6643\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66748\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4757 - accuracy: 0.7660 - val_loss: 0.5936 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66748\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4729 - accuracy: 0.7687 - val_loss: 0.6007 - val_accuracy: 0.6577\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66748\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4860 - accuracy: 0.7600 - val_loss: 0.5952 - val_accuracy: 0.6621\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66748\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5079 - accuracy: 0.7424 - val_loss: 0.5914 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66539, saving model to model/fullrun3/CV_5\\model_8.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5040 - accuracy: 0.7460 - val_loss: 0.5938 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66539\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4998 - accuracy: 0.7505 - val_loss: 0.5924 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66539\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4911 - accuracy: 0.7571 - val_loss: 0.5995 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66539\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4888 - accuracy: 0.7582 - val_loss: 0.5958 - val_accuracy: 0.6633\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66539\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4827 - accuracy: 0.7608 - val_loss: 0.6090 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66539\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4778 - accuracy: 0.7633 - val_loss: 0.5938 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66539 to 0.66609, saving model to model/fullrun3/CV_5\\model_8.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4816 - accuracy: 0.7637 - val_loss: 0.5968 - val_accuracy: 0.6624\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66609\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4762 - accuracy: 0.7659 - val_loss: 0.5990 - val_accuracy: 0.6626\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66609\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4714 - accuracy: 0.7701 - val_loss: 0.5932 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.66609 to 0.66975, saving model to model/fullrun3/CV_5\\model_8.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4705 - accuracy: 0.7701 - val_loss: 0.5986 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66975\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4684 - accuracy: 0.7704 - val_loss: 0.6057 - val_accuracy: 0.6582\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66975\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4789 - accuracy: 0.7668 - val_loss: 0.5988 - val_accuracy: 0.6577\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66975\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4902 - accuracy: 0.7538 - val_loss: 0.5937 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66975\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4835 - accuracy: 0.7580 - val_loss: 0.5968 - val_accuracy: 0.6617\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66975\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4845 - accuracy: 0.7579 - val_loss: 0.5920 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66975\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4853 - accuracy: 0.7582 - val_loss: 0.5901 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.66975 to 0.67027, saving model to model/fullrun3/CV_5\\model_8.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4797 - accuracy: 0.7610 - val_loss: 0.5905 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.67027 to 0.67149, saving model to model/fullrun3/CV_5\\model_8.h5\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4858 - accuracy: 0.7580 - val_loss: 0.5909 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67149\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4868 - accuracy: 0.7578 - val_loss: 0.5906 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67149\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4886 - accuracy: 0.7571 - val_loss: 0.5885 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67149\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4876 - accuracy: 0.7567 - val_loss: 0.5876 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67149\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4856 - accuracy: 0.7592 - val_loss: 0.5877 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.67149 to 0.67236, saving model to model/fullrun3/CV_5\\model_8.h5\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4859 - accuracy: 0.7604 - val_loss: 0.5902 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67236\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4870 - accuracy: 0.7582 - val_loss: 0.5859 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.67236 to 0.67375, saving model to model/fullrun3/CV_5\\model_8.h5\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4868 - accuracy: 0.7579 - val_loss: 0.5870 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.67375 to 0.67480, saving model to model/fullrun3/CV_5\\model_8.h5\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4803 - accuracy: 0.7609 - val_loss: 0.5838 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.67480 to 0.67497, saving model to model/fullrun3/CV_5\\model_8.h5\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4816 - accuracy: 0.7630 - val_loss: 0.5855 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.67497\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4802 - accuracy: 0.7625 - val_loss: 0.5874 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67497\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4791 - accuracy: 0.7621 - val_loss: 0.5895 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67497\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4790 - accuracy: 0.7630 - val_loss: 0.5856 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.67497 to 0.67550, saving model to model/fullrun3/CV_5\\model_8.h5\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4764 - accuracy: 0.7641 - val_loss: 0.5862 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.67550\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4742 - accuracy: 0.7652 - val_loss: 0.5870 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.67550\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4738 - accuracy: 0.7685 - val_loss: 0.5891 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.67550\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4782 - accuracy: 0.7624 - val_loss: 0.5885 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.67550\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4728 - accuracy: 0.7675 - val_loss: 0.5885 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.67550\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4709 - accuracy: 0.7686 - val_loss: 0.5901 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.67550\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4700 - accuracy: 0.7687 - val_loss: 0.5919 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.67550\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4688 - accuracy: 0.7692 - val_loss: 0.5898 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.67550\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4698 - accuracy: 0.7689 - val_loss: 0.5910 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.67550\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4692 - accuracy: 0.7705 - val_loss: 0.5893 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.67550\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5471 - accuracy: 0.7121 - val_loss: 0.5879 - val_accuracy: 0.6649\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66487, saving model to model/fullrun3/CV_5\\model_9.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5389 - accuracy: 0.7200 - val_loss: 0.5885 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66487\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5334 - accuracy: 0.7213 - val_loss: 0.5853 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66487 to 0.66713, saving model to model/fullrun3/CV_5\\model_9.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5289 - accuracy: 0.7260 - val_loss: 0.5910 - val_accuracy: 0.6635\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66713\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5259 - accuracy: 0.7266 - val_loss: 0.5876 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66713\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5225 - accuracy: 0.7303 - val_loss: 0.5826 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.66713 to 0.67532, saving model to model/fullrun3/CV_5\\model_9.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5202 - accuracy: 0.7315 - val_loss: 0.5906 - val_accuracy: 0.6633\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67532\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5205 - accuracy: 0.7328 - val_loss: 0.5899 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67532\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5138 - accuracy: 0.7396 - val_loss: 0.5866 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67532\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5115 - accuracy: 0.7372 - val_loss: 0.5912 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67532\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5088 - accuracy: 0.7386 - val_loss: 0.5857 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67532\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5096 - accuracy: 0.7392 - val_loss: 0.5830 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67532\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5083 - accuracy: 0.7407 - val_loss: 0.5879 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67532\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5021 - accuracy: 0.7481 - val_loss: 0.5896 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67532\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5013 - accuracy: 0.7469 - val_loss: 0.5904 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67532\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4995 - accuracy: 0.7477 - val_loss: 0.5863 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67532\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 9s 79ms/step - loss: 0.6749 - accuracy: 0.5678 - val_loss: 0.6440 - val_accuracy: 0.5760\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57598, saving model to model/fullrun3/CV_6\\model_0.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.6336 - accuracy: 0.5986 - val_loss: 0.6650 - val_accuracy: 0.5150\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.57598\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.6183 - accuracy: 0.6255 - val_loss: 0.6120 - val_accuracy: 0.6509\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.57598 to 0.65092, saving model to model/fullrun3/CV_6\\model_0.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5994 - accuracy: 0.6544 - val_loss: 0.6155 - val_accuracy: 0.6218\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65092\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5895 - accuracy: 0.6646 - val_loss: 0.5970 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.65092 to 0.65929, saving model to model/fullrun3/CV_6\\model_0.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5790 - accuracy: 0.6763 - val_loss: 0.5923 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.65929 to 0.66312, saving model to model/fullrun3/CV_6\\model_0.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5692 - accuracy: 0.6869 - val_loss: 0.5931 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66312 to 0.66591, saving model to model/fullrun3/CV_6\\model_0.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5602 - accuracy: 0.6931 - val_loss: 0.6068 - val_accuracy: 0.6446\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66591\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5553 - accuracy: 0.7000 - val_loss: 0.5878 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.66591 to 0.66609, saving model to model/fullrun3/CV_6\\model_0.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5488 - accuracy: 0.7062 - val_loss: 0.5988 - val_accuracy: 0.6591\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66609\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5428 - accuracy: 0.7119 - val_loss: 0.5852 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.66609 to 0.66800, saving model to model/fullrun3/CV_6\\model_0.h5\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5363 - accuracy: 0.7183 - val_loss: 0.5864 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66800\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5345 - accuracy: 0.7171 - val_loss: 0.5881 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.66800 to 0.66940, saving model to model/fullrun3/CV_6\\model_0.h5\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5299 - accuracy: 0.7218 - val_loss: 0.5865 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66940\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5278 - accuracy: 0.7231 - val_loss: 0.5890 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.66940 to 0.66975, saving model to model/fullrun3/CV_6\\model_0.h5\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5232 - accuracy: 0.7301 - val_loss: 0.5869 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66975\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5186 - accuracy: 0.7337 - val_loss: 0.5874 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66975\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5149 - accuracy: 0.7351 - val_loss: 0.5888 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66975\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5138 - accuracy: 0.7356 - val_loss: 0.5902 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.66975\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5108 - accuracy: 0.7374 - val_loss: 0.5887 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66975\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5070 - accuracy: 0.7420 - val_loss: 0.5901 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66975\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5039 - accuracy: 0.7446 - val_loss: 0.5905 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.66975\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5045 - accuracy: 0.7440 - val_loss: 0.5902 - val_accuracy: 0.6682\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.66975\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5039 - accuracy: 0.7438 - val_loss: 0.5902 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.66975\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4991 - accuracy: 0.7507 - val_loss: 0.5909 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.66975\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5634 - accuracy: 0.6937 - val_loss: 0.5859 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66713, saving model to model/fullrun3/CV_6\\model_1.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5497 - accuracy: 0.7063 - val_loss: 0.5905 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66713 to 0.66783, saving model to model/fullrun3/CV_6\\model_1.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5421 - accuracy: 0.7133 - val_loss: 0.5840 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66783 to 0.67288, saving model to model/fullrun3/CV_6\\model_1.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5353 - accuracy: 0.7195 - val_loss: 0.5809 - val_accuracy: 0.6772\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67288 to 0.67724, saving model to model/fullrun3/CV_6\\model_1.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5274 - accuracy: 0.7269 - val_loss: 0.5816 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67724 to 0.67741, saving model to model/fullrun3/CV_6\\model_1.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5243 - accuracy: 0.7273 - val_loss: 0.5852 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67741\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5208 - accuracy: 0.7303 - val_loss: 0.5822 - val_accuracy: 0.6764\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67741\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5156 - accuracy: 0.7359 - val_loss: 0.5822 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67741\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5126 - accuracy: 0.7385 - val_loss: 0.5856 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67741\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5082 - accuracy: 0.7409 - val_loss: 0.5841 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67741\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5051 - accuracy: 0.7433 - val_loss: 0.5842 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67741\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5019 - accuracy: 0.7447 - val_loss: 0.5860 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67741\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4992 - accuracy: 0.7479 - val_loss: 0.5852 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67741\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4982 - accuracy: 0.7483 - val_loss: 0.5872 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67741\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4957 - accuracy: 0.7501 - val_loss: 0.5884 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67741\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5380 - accuracy: 0.7190 - val_loss: 0.5859 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66609, saving model to model/fullrun3/CV_6\\model_2.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5310 - accuracy: 0.7242 - val_loss: 0.5927 - val_accuracy: 0.6621\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66609\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5224 - accuracy: 0.7308 - val_loss: 0.5849 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66609 to 0.67027, saving model to model/fullrun3/CV_6\\model_2.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5168 - accuracy: 0.7355 - val_loss: 0.5819 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67027 to 0.67532, saving model to model/fullrun3/CV_6\\model_2.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5118 - accuracy: 0.7386 - val_loss: 0.5894 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67532\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5083 - accuracy: 0.7426 - val_loss: 0.5916 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67532\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5033 - accuracy: 0.7463 - val_loss: 0.5854 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67532\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4998 - accuracy: 0.7482 - val_loss: 0.5852 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67532\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4947 - accuracy: 0.7539 - val_loss: 0.5918 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67532\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4950 - accuracy: 0.7516 - val_loss: 0.5877 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67532\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4895 - accuracy: 0.7576 - val_loss: 0.5886 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67532\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4879 - accuracy: 0.7558 - val_loss: 0.5904 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67532\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4900 - accuracy: 0.7537 - val_loss: 0.5891 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67532\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4824 - accuracy: 0.7605 - val_loss: 0.5918 - val_accuracy: 0.6649\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67532\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5313 - accuracy: 0.7241 - val_loss: 0.5859 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66835, saving model to model/fullrun3/CV_6\\model_3.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5236 - accuracy: 0.7324 - val_loss: 0.5929 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66835\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5159 - accuracy: 0.7362 - val_loss: 0.5943 - val_accuracy: 0.6588\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66835\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5101 - accuracy: 0.7394 - val_loss: 0.5903 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66835\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5072 - accuracy: 0.7439 - val_loss: 0.5883 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66835\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4998 - accuracy: 0.7496 - val_loss: 0.5980 - val_accuracy: 0.6565\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66835\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4994 - accuracy: 0.7500 - val_loss: 0.5908 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66835\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4943 - accuracy: 0.7518 - val_loss: 0.5876 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66835\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4877 - accuracy: 0.7578 - val_loss: 0.5981 - val_accuracy: 0.6574\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66835\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4887 - accuracy: 0.7556 - val_loss: 0.5885 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66835\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4852 - accuracy: 0.7586 - val_loss: 0.5928 - val_accuracy: 0.6595\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66835\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5188 - accuracy: 0.7343 - val_loss: 0.5880 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66661, saving model to model/fullrun3/CV_6\\model_4.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5135 - accuracy: 0.7378 - val_loss: 0.5917 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66661\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5034 - accuracy: 0.7448 - val_loss: 0.5948 - val_accuracy: 0.6616\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66661\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5005 - accuracy: 0.7475 - val_loss: 0.5915 - val_accuracy: 0.6635\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66661\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4959 - accuracy: 0.7526 - val_loss: 0.5977 - val_accuracy: 0.6572\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66661\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4913 - accuracy: 0.7559 - val_loss: 0.5979 - val_accuracy: 0.6589\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66661\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4878 - accuracy: 0.7585 - val_loss: 0.5865 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66661 to 0.66713, saving model to model/fullrun3/CV_6\\model_4.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4847 - accuracy: 0.7592 - val_loss: 0.5895 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66713\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4811 - accuracy: 0.7646 - val_loss: 0.6032 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66713\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4779 - accuracy: 0.7644 - val_loss: 0.5901 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.66713 to 0.66887, saving model to model/fullrun3/CV_6\\model_4.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4763 - accuracy: 0.7649 - val_loss: 0.5944 - val_accuracy: 0.6656\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66887\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4924 - accuracy: 0.7540 - val_loss: 0.5912 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66887\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4915 - accuracy: 0.7542 - val_loss: 0.5902 - val_accuracy: 0.6682\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66887\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4862 - accuracy: 0.7586 - val_loss: 0.5909 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66887\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4971 - accuracy: 0.7504 - val_loss: 0.5905 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66887\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4990 - accuracy: 0.7469 - val_loss: 0.5872 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66887\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4966 - accuracy: 0.7483 - val_loss: 0.5857 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.66887 to 0.67062, saving model to model/fullrun3/CV_6\\model_4.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4943 - accuracy: 0.7507 - val_loss: 0.5873 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67062\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4930 - accuracy: 0.7512 - val_loss: 0.5881 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67062\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4905 - accuracy: 0.7530 - val_loss: 0.5907 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67062\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4889 - accuracy: 0.7540 - val_loss: 0.5895 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67062\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4856 - accuracy: 0.7575 - val_loss: 0.5870 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67062\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4852 - accuracy: 0.7568 - val_loss: 0.5894 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67062\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4828 - accuracy: 0.7590 - val_loss: 0.5904 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.67062 to 0.67323, saving model to model/fullrun3/CV_6\\model_4.h5\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4820 - accuracy: 0.7585 - val_loss: 0.5883 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67323\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4814 - accuracy: 0.7612 - val_loss: 0.5914 - val_accuracy: 0.6657\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67323\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4817 - accuracy: 0.7579 - val_loss: 0.5878 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.67323\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4812 - accuracy: 0.7594 - val_loss: 0.5920 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.67323\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4798 - accuracy: 0.7610 - val_loss: 0.5931 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67323\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4783 - accuracy: 0.7630 - val_loss: 0.5967 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67323\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4820 - accuracy: 0.7587 - val_loss: 0.5898 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.67323\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4795 - accuracy: 0.7599 - val_loss: 0.5885 - val_accuracy: 0.6657\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.67323\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4758 - accuracy: 0.7657 - val_loss: 0.5899 - val_accuracy: 0.6642\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.67323\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4753 - accuracy: 0.7629 - val_loss: 0.5927 - val_accuracy: 0.6609\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.67323\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5329 - accuracy: 0.7232 - val_loss: 0.5881 - val_accuracy: 0.6635\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66347, saving model to model/fullrun3/CV_6\\model_5.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5294 - accuracy: 0.7248 - val_loss: 0.5907 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66347\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5173 - accuracy: 0.7357 - val_loss: 0.5916 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66347\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5126 - accuracy: 0.7389 - val_loss: 0.5912 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66347\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5076 - accuracy: 0.7411 - val_loss: 0.5898 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.66347 to 0.66626, saving model to model/fullrun3/CV_6\\model_5.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5057 - accuracy: 0.7460 - val_loss: 0.5878 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66626\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4996 - accuracy: 0.7481 - val_loss: 0.5872 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66626 to 0.66748, saving model to model/fullrun3/CV_6\\model_5.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4993 - accuracy: 0.7473 - val_loss: 0.5893 - val_accuracy: 0.6633\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66748\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4945 - accuracy: 0.7538 - val_loss: 0.6012 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66748\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4926 - accuracy: 0.7532 - val_loss: 0.5853 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.66748 to 0.67253, saving model to model/fullrun3/CV_6\\model_5.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4893 - accuracy: 0.7558 - val_loss: 0.5914 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67253\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4919 - accuracy: 0.7531 - val_loss: 0.5945 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67253\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4923 - accuracy: 0.7537 - val_loss: 0.5874 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67253\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4889 - accuracy: 0.7568 - val_loss: 0.5907 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67253\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4936 - accuracy: 0.7522 - val_loss: 0.5895 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67253\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4905 - accuracy: 0.7532 - val_loss: 0.5860 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67253\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4883 - accuracy: 0.7552 - val_loss: 0.5853 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67253\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4881 - accuracy: 0.7562 - val_loss: 0.5859 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67253\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4851 - accuracy: 0.7600 - val_loss: 0.5902 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67253\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4805 - accuracy: 0.7593 - val_loss: 0.5929 - val_accuracy: 0.6633\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67253\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5228 - accuracy: 0.7304 - val_loss: 0.5884 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66312, saving model to model/fullrun3/CV_6\\model_6.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5160 - accuracy: 0.7381 - val_loss: 0.5910 - val_accuracy: 0.6595\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66312\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5077 - accuracy: 0.7425 - val_loss: 0.5915 - val_accuracy: 0.6610\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66312\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5039 - accuracy: 0.7457 - val_loss: 0.5936 - val_accuracy: 0.6636\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.66312 to 0.66365, saving model to model/fullrun3/CV_6\\model_6.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5002 - accuracy: 0.7485 - val_loss: 0.5909 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.66365 to 0.66469, saving model to model/fullrun3/CV_6\\model_6.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4975 - accuracy: 0.7493 - val_loss: 0.5952 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66469\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4955 - accuracy: 0.7515 - val_loss: 0.5905 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66469\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4906 - accuracy: 0.7534 - val_loss: 0.5951 - val_accuracy: 0.6610\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66469\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4869 - accuracy: 0.7582 - val_loss: 0.6033 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66469\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4841 - accuracy: 0.7613 - val_loss: 0.5967 - val_accuracy: 0.6602\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66469\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4801 - accuracy: 0.7633 - val_loss: 0.5940 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66469\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4835 - accuracy: 0.7609 - val_loss: 0.6011 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66469\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4817 - accuracy: 0.7624 - val_loss: 0.5944 - val_accuracy: 0.6624\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66469\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4808 - accuracy: 0.7629 - val_loss: 0.5958 - val_accuracy: 0.6609\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66469\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4799 - accuracy: 0.7623 - val_loss: 0.5953 - val_accuracy: 0.6591\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66469\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5134 - accuracy: 0.7400 - val_loss: 0.5919 - val_accuracy: 0.6584\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65842, saving model to model/fullrun3/CV_6\\model_7.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5119 - accuracy: 0.7428 - val_loss: 0.5925 - val_accuracy: 0.6626\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65842 to 0.66260, saving model to model/fullrun3/CV_6\\model_7.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5027 - accuracy: 0.7471 - val_loss: 0.5952 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66260 to 0.66452, saving model to model/fullrun3/CV_6\\model_7.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4982 - accuracy: 0.7505 - val_loss: 0.5958 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66452\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4939 - accuracy: 0.7516 - val_loss: 0.5946 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66452\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4877 - accuracy: 0.7565 - val_loss: 0.6003 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66452\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4853 - accuracy: 0.7598 - val_loss: 0.5929 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66452 to 0.66591, saving model to model/fullrun3/CV_6\\model_7.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4839 - accuracy: 0.7583 - val_loss: 0.5967 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66591\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4794 - accuracy: 0.7645 - val_loss: 0.6042 - val_accuracy: 0.6565\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66591\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4768 - accuracy: 0.7659 - val_loss: 0.5941 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66591\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4773 - accuracy: 0.7656 - val_loss: 0.5992 - val_accuracy: 0.6616\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66591\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4773 - accuracy: 0.7663 - val_loss: 0.6022 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66591\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4744 - accuracy: 0.7661 - val_loss: 0.5937 - val_accuracy: 0.6657\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66591\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4748 - accuracy: 0.7665 - val_loss: 0.6040 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66591\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4736 - accuracy: 0.7660 - val_loss: 0.6005 - val_accuracy: 0.6602\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66591\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4848 - accuracy: 0.7572 - val_loss: 0.5924 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66591\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4824 - accuracy: 0.7612 - val_loss: 0.5928 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66591\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5120 - accuracy: 0.7409 - val_loss: 0.5954 - val_accuracy: 0.6603\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66033, saving model to model/fullrun3/CV_6\\model_8.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5077 - accuracy: 0.7457 - val_loss: 0.5995 - val_accuracy: 0.6528\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66033\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4966 - accuracy: 0.7528 - val_loss: 0.5971 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66033\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4924 - accuracy: 0.7556 - val_loss: 0.6000 - val_accuracy: 0.6558\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66033\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4909 - accuracy: 0.7549 - val_loss: 0.5980 - val_accuracy: 0.6546\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66033\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4866 - accuracy: 0.7572 - val_loss: 0.6012 - val_accuracy: 0.6534\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66033\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4861 - accuracy: 0.7602 - val_loss: 0.5938 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66033 to 0.66138, saving model to model/fullrun3/CV_6\\model_8.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4852 - accuracy: 0.7581 - val_loss: 0.5994 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66138\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4768 - accuracy: 0.7670 - val_loss: 0.6029 - val_accuracy: 0.6565\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66138\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4769 - accuracy: 0.7647 - val_loss: 0.5950 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66138\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4724 - accuracy: 0.7710 - val_loss: 0.6033 - val_accuracy: 0.6570\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66138\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4748 - accuracy: 0.7671 - val_loss: 0.6021 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66138\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4762 - accuracy: 0.7648 - val_loss: 0.5956 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.66138 to 0.66190, saving model to model/fullrun3/CV_6\\model_8.h5\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4695 - accuracy: 0.7702 - val_loss: 0.5979 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66190\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4701 - accuracy: 0.7702 - val_loss: 0.5998 - val_accuracy: 0.6570\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66190\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4782 - accuracy: 0.7627 - val_loss: 0.5924 - val_accuracy: 0.6623\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.66190 to 0.66225, saving model to model/fullrun3/CV_6\\model_8.h5\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4768 - accuracy: 0.7649 - val_loss: 0.5901 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.66225 to 0.66382, saving model to model/fullrun3/CV_6\\model_8.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4897 - accuracy: 0.7567 - val_loss: 0.5882 - val_accuracy: 0.6621\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66382\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4849 - accuracy: 0.7567 - val_loss: 0.5897 - val_accuracy: 0.6626\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.66382\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4830 - accuracy: 0.7592 - val_loss: 0.5908 - val_accuracy: 0.6574\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66382\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4855 - accuracy: 0.7579 - val_loss: 0.5892 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.66382 to 0.66504, saving model to model/fullrun3/CV_6\\model_8.h5\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4859 - accuracy: 0.7567 - val_loss: 0.5884 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.66504 to 0.66696, saving model to model/fullrun3/CV_6\\model_8.h5\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4813 - accuracy: 0.7607 - val_loss: 0.5916 - val_accuracy: 0.6595\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.66696\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4797 - accuracy: 0.7627 - val_loss: 0.5913 - val_accuracy: 0.6616\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.66696\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4812 - accuracy: 0.7613 - val_loss: 0.5867 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.66696 to 0.66835, saving model to model/fullrun3/CV_6\\model_8.h5\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4781 - accuracy: 0.7625 - val_loss: 0.5907 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.66835\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4784 - accuracy: 0.7629 - val_loss: 0.5886 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.66835\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4762 - accuracy: 0.7648 - val_loss: 0.5918 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.66835\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4766 - accuracy: 0.7642 - val_loss: 0.5879 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.66835\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4772 - accuracy: 0.7616 - val_loss: 0.5930 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.66835\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4766 - accuracy: 0.7648 - val_loss: 0.5876 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.66835\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4731 - accuracy: 0.7672 - val_loss: 0.5866 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.66835 to 0.67009, saving model to model/fullrun3/CV_6\\model_8.h5\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4718 - accuracy: 0.7670 - val_loss: 0.5874 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.67009\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4718 - accuracy: 0.7668 - val_loss: 0.5892 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.67009 to 0.67236, saving model to model/fullrun3/CV_6\\model_8.h5\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4703 - accuracy: 0.7688 - val_loss: 0.5903 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.67236\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4737 - accuracy: 0.7656 - val_loss: 0.5876 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.67236\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4724 - accuracy: 0.7663 - val_loss: 0.5884 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.67236 to 0.67428, saving model to model/fullrun3/CV_6\\model_8.h5\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4688 - accuracy: 0.7704 - val_loss: 0.5925 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.67428\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4686 - accuracy: 0.7700 - val_loss: 0.5906 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.67428 to 0.67480, saving model to model/fullrun3/CV_6\\model_8.h5\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4682 - accuracy: 0.7716 - val_loss: 0.5901 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.67480\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4677 - accuracy: 0.7713 - val_loss: 0.5900 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.67480\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4652 - accuracy: 0.7701 - val_loss: 0.5929 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.67480\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4650 - accuracy: 0.7716 - val_loss: 0.5917 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.67480\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4688 - accuracy: 0.7700 - val_loss: 0.5957 - val_accuracy: 0.6595\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.67480\n",
      "Epoch 45/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4636 - accuracy: 0.7739 - val_loss: 0.5938 - val_accuracy: 0.6610\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.67480\n",
      "Epoch 46/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4672 - accuracy: 0.7673 - val_loss: 0.5911 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.67480\n",
      "Epoch 47/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4629 - accuracy: 0.7728 - val_loss: 0.5927 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.67480\n",
      "Epoch 48/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4619 - accuracy: 0.7745 - val_loss: 0.5943 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.67480\n",
      "Epoch 49/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4612 - accuracy: 0.7742 - val_loss: 0.5935 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.67480\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5501 - accuracy: 0.7080 - val_loss: 0.5909 - val_accuracy: 0.6602\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66016, saving model to model/fullrun3/CV_6\\model_9.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5408 - accuracy: 0.7153 - val_loss: 0.5912 - val_accuracy: 0.6642\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66016 to 0.66417, saving model to model/fullrun3/CV_6\\model_9.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5339 - accuracy: 0.7199 - val_loss: 0.5884 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66417 to 0.66469, saving model to model/fullrun3/CV_6\\model_9.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5307 - accuracy: 0.7249 - val_loss: 0.5899 - val_accuracy: 0.6643\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66469\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5285 - accuracy: 0.7266 - val_loss: 0.5874 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.66469 to 0.66835, saving model to model/fullrun3/CV_6\\model_9.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5259 - accuracy: 0.7288 - val_loss: 0.5877 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66835\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5225 - accuracy: 0.7296 - val_loss: 0.5940 - val_accuracy: 0.6591\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66835\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5174 - accuracy: 0.7365 - val_loss: 0.5904 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66835\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5145 - accuracy: 0.7366 - val_loss: 0.5862 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66835\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5135 - accuracy: 0.7369 - val_loss: 0.5870 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66835\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5107 - accuracy: 0.7403 - val_loss: 0.5843 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.66835 to 0.67253, saving model to model/fullrun3/CV_6\\model_9.h5\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5072 - accuracy: 0.7431 - val_loss: 0.5853 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67253\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5026 - accuracy: 0.7449 - val_loss: 0.5874 - val_accuracy: 0.6682\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67253\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5025 - accuracy: 0.7460 - val_loss: 0.5883 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67253\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5004 - accuracy: 0.7462 - val_loss: 0.5965 - val_accuracy: 0.6586\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67253\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4995 - accuracy: 0.7481 - val_loss: 0.5891 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67253\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4980 - accuracy: 0.7485 - val_loss: 0.5878 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67253\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4925 - accuracy: 0.7534 - val_loss: 0.5919 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67253\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4916 - accuracy: 0.7533 - val_loss: 0.5900 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67253\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4899 - accuracy: 0.7549 - val_loss: 0.5968 - val_accuracy: 0.6609\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67253\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4889 - accuracy: 0.7565 - val_loss: 0.5936 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67253\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 10s 79ms/step - loss: 0.6710 - accuracy: 0.5659 - val_loss: 0.6505 - val_accuracy: 0.5650\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56501, saving model to model/fullrun3/CV_7\\model_0.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.6367 - accuracy: 0.5865 - val_loss: 0.6469 - val_accuracy: 0.5436\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.56501\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.6248 - accuracy: 0.6178 - val_loss: 0.6230 - val_accuracy: 0.6406\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.56501 to 0.64064, saving model to model/fullrun3/CV_7\\model_0.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.6081 - accuracy: 0.6429 - val_loss: 0.6187 - val_accuracy: 0.6218\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64064\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5952 - accuracy: 0.6596 - val_loss: 0.6065 - val_accuracy: 0.6467\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.64064 to 0.64674, saving model to model/fullrun3/CV_7\\model_0.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5839 - accuracy: 0.6707 - val_loss: 0.6014 - val_accuracy: 0.6549\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.64674 to 0.65493, saving model to model/fullrun3/CV_7\\model_0.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5739 - accuracy: 0.6815 - val_loss: 0.6002 - val_accuracy: 0.6572\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.65493 to 0.65720, saving model to model/fullrun3/CV_7\\model_0.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5644 - accuracy: 0.6908 - val_loss: 0.6192 - val_accuracy: 0.6373\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.65720\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5582 - accuracy: 0.6968 - val_loss: 0.5972 - val_accuracy: 0.6527\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.65720\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5506 - accuracy: 0.7046 - val_loss: 0.6076 - val_accuracy: 0.6478\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.65720\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5483 - accuracy: 0.7071 - val_loss: 0.5967 - val_accuracy: 0.6577\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.65720 to 0.65772, saving model to model/fullrun3/CV_7\\model_0.h5\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5411 - accuracy: 0.7128 - val_loss: 0.5969 - val_accuracy: 0.6609\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.65772 to 0.66086, saving model to model/fullrun3/CV_7\\model_0.h5\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5378 - accuracy: 0.7146 - val_loss: 0.5959 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66086\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5311 - accuracy: 0.7227 - val_loss: 0.5959 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66086\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5280 - accuracy: 0.7250 - val_loss: 0.6000 - val_accuracy: 0.6577\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66086\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5237 - accuracy: 0.7273 - val_loss: 0.6006 - val_accuracy: 0.6577\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66086\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5197 - accuracy: 0.7293 - val_loss: 0.6017 - val_accuracy: 0.6596\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66086\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5203 - accuracy: 0.7293 - val_loss: 0.6004 - val_accuracy: 0.6589\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66086\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5138 - accuracy: 0.7358 - val_loss: 0.5996 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.66086\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5129 - accuracy: 0.7368 - val_loss: 0.6002 - val_accuracy: 0.6584\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66086\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5116 - accuracy: 0.7378 - val_loss: 0.6030 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66086\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5078 - accuracy: 0.7401 - val_loss: 0.6046 - val_accuracy: 0.6542\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.66086\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5599 - accuracy: 0.6994 - val_loss: 0.5962 - val_accuracy: 0.6551\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65511, saving model to model/fullrun3/CV_7\\model_1.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5465 - accuracy: 0.7093 - val_loss: 0.6016 - val_accuracy: 0.6544\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.65511\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5409 - accuracy: 0.7144 - val_loss: 0.5965 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.65511 to 0.66190, saving model to model/fullrun3/CV_7\\model_1.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5337 - accuracy: 0.7217 - val_loss: 0.5938 - val_accuracy: 0.6623\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.66190 to 0.66225, saving model to model/fullrun3/CV_7\\model_1.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5299 - accuracy: 0.7229 - val_loss: 0.5940 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66225\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5231 - accuracy: 0.7307 - val_loss: 0.5977 - val_accuracy: 0.6586\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66225\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5193 - accuracy: 0.7308 - val_loss: 0.5965 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66225\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5155 - accuracy: 0.7339 - val_loss: 0.5971 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66225\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5137 - accuracy: 0.7379 - val_loss: 0.5993 - val_accuracy: 0.6544\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66225\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5083 - accuracy: 0.7401 - val_loss: 0.5958 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66225\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5065 - accuracy: 0.7419 - val_loss: 0.5968 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66225\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5034 - accuracy: 0.7444 - val_loss: 0.5977 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66225\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5003 - accuracy: 0.7472 - val_loss: 0.5993 - val_accuracy: 0.6577\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66225\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4960 - accuracy: 0.7497 - val_loss: 0.6027 - val_accuracy: 0.6572\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66225\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5400 - accuracy: 0.7152 - val_loss: 0.5943 - val_accuracy: 0.6560\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65598, saving model to model/fullrun3/CV_7\\model_2.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5305 - accuracy: 0.7237 - val_loss: 0.6055 - val_accuracy: 0.6528\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.65598\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5238 - accuracy: 0.7316 - val_loss: 0.5971 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.65598 to 0.65981, saving model to model/fullrun3/CV_7\\model_2.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5178 - accuracy: 0.7348 - val_loss: 0.5960 - val_accuracy: 0.6617\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.65981 to 0.66173, saving model to model/fullrun3/CV_7\\model_2.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5109 - accuracy: 0.7399 - val_loss: 0.6002 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66173\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5070 - accuracy: 0.7432 - val_loss: 0.6001 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66173\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5053 - accuracy: 0.7440 - val_loss: 0.5973 - val_accuracy: 0.6574\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66173\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4999 - accuracy: 0.7476 - val_loss: 0.5983 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66173\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4964 - accuracy: 0.7500 - val_loss: 0.6111 - val_accuracy: 0.6528\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66173\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4943 - accuracy: 0.7502 - val_loss: 0.5988 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66173\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4927 - accuracy: 0.7545 - val_loss: 0.5999 - val_accuracy: 0.6548\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66173\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4913 - accuracy: 0.7557 - val_loss: 0.6013 - val_accuracy: 0.6577\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66173\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4845 - accuracy: 0.7595 - val_loss: 0.6031 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66173\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4865 - accuracy: 0.7582 - val_loss: 0.6058 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66173\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5348 - accuracy: 0.7216 - val_loss: 0.5999 - val_accuracy: 0.6520\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65197, saving model to model/fullrun3/CV_7\\model_3.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5239 - accuracy: 0.7303 - val_loss: 0.6124 - val_accuracy: 0.6433\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.65197\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5194 - accuracy: 0.7323 - val_loss: 0.6022 - val_accuracy: 0.6541\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.65197 to 0.65406, saving model to model/fullrun3/CV_7\\model_3.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5110 - accuracy: 0.7417 - val_loss: 0.5987 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.65406 to 0.65755, saving model to model/fullrun3/CV_7\\model_3.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5074 - accuracy: 0.7437 - val_loss: 0.6009 - val_accuracy: 0.6551\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.65755\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5023 - accuracy: 0.7485 - val_loss: 0.6039 - val_accuracy: 0.6535\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.65755\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4955 - accuracy: 0.7519 - val_loss: 0.5998 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.65755 to 0.66138, saving model to model/fullrun3/CV_7\\model_3.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4942 - accuracy: 0.7523 - val_loss: 0.6012 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66138\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4892 - accuracy: 0.7579 - val_loss: 0.6087 - val_accuracy: 0.6502\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66138\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4885 - accuracy: 0.7563 - val_loss: 0.5989 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66138\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4872 - accuracy: 0.7589 - val_loss: 0.6020 - val_accuracy: 0.6582\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66138\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4859 - accuracy: 0.7580 - val_loss: 0.6033 - val_accuracy: 0.6562\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66138\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4797 - accuracy: 0.7630 - val_loss: 0.6037 - val_accuracy: 0.6560\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66138\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4796 - accuracy: 0.7642 - val_loss: 0.6071 - val_accuracy: 0.6542\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66138\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5045 - accuracy: 0.7455 - val_loss: 0.5998 - val_accuracy: 0.6537\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66138\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5011 - accuracy: 0.7475 - val_loss: 0.5998 - val_accuracy: 0.6520\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66138\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4970 - accuracy: 0.7505 - val_loss: 0.6008 - val_accuracy: 0.6497\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66138\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5257 - accuracy: 0.7313 - val_loss: 0.5985 - val_accuracy: 0.6507\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65075, saving model to model/fullrun3/CV_7\\model_4.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5206 - accuracy: 0.7326 - val_loss: 0.6086 - val_accuracy: 0.6434\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.65075\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.5130 - accuracy: 0.7373 - val_loss: 0.6025 - val_accuracy: 0.6487\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.65075\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5071 - accuracy: 0.7446 - val_loss: 0.6050 - val_accuracy: 0.6488\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65075\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5017 - accuracy: 0.7465 - val_loss: 0.6018 - val_accuracy: 0.6534\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.65075 to 0.65336, saving model to model/fullrun3/CV_7\\model_4.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4985 - accuracy: 0.7485 - val_loss: 0.6031 - val_accuracy: 0.6542\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.65336 to 0.65423, saving model to model/fullrun3/CV_7\\model_4.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4921 - accuracy: 0.7543 - val_loss: 0.6007 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.65423 to 0.65667, saving model to model/fullrun3/CV_7\\model_4.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4933 - accuracy: 0.7547 - val_loss: 0.6023 - val_accuracy: 0.6589\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.65667 to 0.65894, saving model to model/fullrun3/CV_7\\model_4.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4857 - accuracy: 0.7592 - val_loss: 0.6079 - val_accuracy: 0.6530\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.65894\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4848 - accuracy: 0.7601 - val_loss: 0.6037 - val_accuracy: 0.6556\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.65894\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4830 - accuracy: 0.7596 - val_loss: 0.6052 - val_accuracy: 0.6563\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.65894\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4811 - accuracy: 0.7606 - val_loss: 0.6070 - val_accuracy: 0.6544\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.65894\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4770 - accuracy: 0.7644 - val_loss: 0.6038 - val_accuracy: 0.6596\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.65894 to 0.65964, saving model to model/fullrun3/CV_7\\model_4.h5\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4767 - accuracy: 0.7648 - val_loss: 0.6115 - val_accuracy: 0.6562\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.65964\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4914 - accuracy: 0.7539 - val_loss: 0.6055 - val_accuracy: 0.6572\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.65964\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4886 - accuracy: 0.7533 - val_loss: 0.6045 - val_accuracy: 0.6558\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.65964\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4852 - accuracy: 0.7556 - val_loss: 0.6003 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.65964\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4999 - accuracy: 0.7491 - val_loss: 0.5985 - val_accuracy: 0.6582\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.65964\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4947 - accuracy: 0.7503 - val_loss: 0.5998 - val_accuracy: 0.6610\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.65964 to 0.66103, saving model to model/fullrun3/CV_7\\model_4.h5\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4947 - accuracy: 0.7522 - val_loss: 0.6022 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66103\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4942 - accuracy: 0.7520 - val_loss: 0.6043 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66103\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4906 - accuracy: 0.7550 - val_loss: 0.6013 - val_accuracy: 0.6546\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.66103\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4939 - accuracy: 0.7527 - val_loss: 0.6041 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.66103\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4924 - accuracy: 0.7523 - val_loss: 0.6016 - val_accuracy: 0.6584\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.66103\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4896 - accuracy: 0.7552 - val_loss: 0.6018 - val_accuracy: 0.6546\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.66103\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4880 - accuracy: 0.7574 - val_loss: 0.6039 - val_accuracy: 0.6542\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.66103\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4919 - accuracy: 0.7534 - val_loss: 0.6030 - val_accuracy: 0.6542\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.66103\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4881 - accuracy: 0.7555 - val_loss: 0.6030 - val_accuracy: 0.6534\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.66103\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4850 - accuracy: 0.7588 - val_loss: 0.6049 - val_accuracy: 0.6582\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.66103\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5314 - accuracy: 0.7229 - val_loss: 0.6008 - val_accuracy: 0.6539\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65389, saving model to model/fullrun3/CV_7\\model_5.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5206 - accuracy: 0.7330 - val_loss: 0.6037 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65389 to 0.65789, saving model to model/fullrun3/CV_7\\model_5.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5183 - accuracy: 0.7321 - val_loss: 0.6030 - val_accuracy: 0.6562\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.65789\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5118 - accuracy: 0.7378 - val_loss: 0.6019 - val_accuracy: 0.6562\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65789\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5070 - accuracy: 0.7440 - val_loss: 0.6036 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.65789 to 0.65807, saving model to model/fullrun3/CV_7\\model_5.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5054 - accuracy: 0.7438 - val_loss: 0.6058 - val_accuracy: 0.6534\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.65807\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4996 - accuracy: 0.7506 - val_loss: 0.5998 - val_accuracy: 0.6560\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.65807\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4964 - accuracy: 0.7515 - val_loss: 0.6020 - val_accuracy: 0.6584\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.65807 to 0.65842, saving model to model/fullrun3/CV_7\\model_5.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4920 - accuracy: 0.7553 - val_loss: 0.6084 - val_accuracy: 0.6534\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.65842\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4866 - accuracy: 0.7580 - val_loss: 0.6025 - val_accuracy: 0.6574\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.65842\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4861 - accuracy: 0.7589 - val_loss: 0.6037 - val_accuracy: 0.6577\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.65842\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4849 - accuracy: 0.7585 - val_loss: 0.6081 - val_accuracy: 0.6556\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.65842\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4808 - accuracy: 0.7617 - val_loss: 0.6074 - val_accuracy: 0.6544\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.65842\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4834 - accuracy: 0.7618 - val_loss: 0.6075 - val_accuracy: 0.6568\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.65842\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4867 - accuracy: 0.7590 - val_loss: 0.6094 - val_accuracy: 0.6532\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.65842\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4839 - accuracy: 0.7598 - val_loss: 0.6033 - val_accuracy: 0.6588\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.65842 to 0.65877, saving model to model/fullrun3/CV_7\\model_5.h5\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4819 - accuracy: 0.7609 - val_loss: 0.6011 - val_accuracy: 0.6595\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.65877 to 0.65946, saving model to model/fullrun3/CV_7\\model_5.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4853 - accuracy: 0.7586 - val_loss: 0.6018 - val_accuracy: 0.6572\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.65946\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4855 - accuracy: 0.7593 - val_loss: 0.6055 - val_accuracy: 0.6556\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.65946\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4840 - accuracy: 0.7603 - val_loss: 0.6065 - val_accuracy: 0.6534\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.65946\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4830 - accuracy: 0.7604 - val_loss: 0.6055 - val_accuracy: 0.6549\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.65946\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4803 - accuracy: 0.7613 - val_loss: 0.6038 - val_accuracy: 0.6509\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.65946\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4815 - accuracy: 0.7611 - val_loss: 0.6052 - val_accuracy: 0.6521\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.65946\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4777 - accuracy: 0.7642 - val_loss: 0.6053 - val_accuracy: 0.6541\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.65946\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4810 - accuracy: 0.7599 - val_loss: 0.6041 - val_accuracy: 0.6546\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.65946\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4750 - accuracy: 0.7659 - val_loss: 0.6071 - val_accuracy: 0.6516\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.65946\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4795 - accuracy: 0.7622 - val_loss: 0.6042 - val_accuracy: 0.6555\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.65946\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5276 - accuracy: 0.7279 - val_loss: 0.6027 - val_accuracy: 0.6520\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65197, saving model to model/fullrun3/CV_7\\model_6.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5209 - accuracy: 0.7326 - val_loss: 0.6059 - val_accuracy: 0.6518\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.65197\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5153 - accuracy: 0.7372 - val_loss: 0.6063 - val_accuracy: 0.6549\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.65197 to 0.65493, saving model to model/fullrun3/CV_7\\model_6.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5093 - accuracy: 0.7410 - val_loss: 0.6072 - val_accuracy: 0.6516\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65493\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5065 - accuracy: 0.7427 - val_loss: 0.6061 - val_accuracy: 0.6542\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.65493\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5002 - accuracy: 0.7472 - val_loss: 0.6048 - val_accuracy: 0.6568\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.65493 to 0.65685, saving model to model/fullrun3/CV_7\\model_6.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4980 - accuracy: 0.7493 - val_loss: 0.5998 - val_accuracy: 0.6568\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.65685\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4936 - accuracy: 0.7529 - val_loss: 0.6001 - val_accuracy: 0.6556\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.65685\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4894 - accuracy: 0.7561 - val_loss: 0.6059 - val_accuracy: 0.6572\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.65685 to 0.65720, saving model to model/fullrun3/CV_7\\model_6.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4877 - accuracy: 0.7554 - val_loss: 0.6007 - val_accuracy: 0.6596\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.65720 to 0.65964, saving model to model/fullrun3/CV_7\\model_6.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4857 - accuracy: 0.7595 - val_loss: 0.6026 - val_accuracy: 0.6560\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.65964\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4826 - accuracy: 0.7609 - val_loss: 0.6075 - val_accuracy: 0.6542\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.65964\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4790 - accuracy: 0.7633 - val_loss: 0.6090 - val_accuracy: 0.6544\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.65964\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4812 - accuracy: 0.7598 - val_loss: 0.6102 - val_accuracy: 0.6558\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.65964\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4823 - accuracy: 0.7618 - val_loss: 0.6089 - val_accuracy: 0.6563\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.65964\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4793 - accuracy: 0.7632 - val_loss: 0.6057 - val_accuracy: 0.6565\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.65964\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4776 - accuracy: 0.7636 - val_loss: 0.6039 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.65964\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4809 - accuracy: 0.7624 - val_loss: 0.6026 - val_accuracy: 0.6589\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.65964\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4765 - accuracy: 0.7648 - val_loss: 0.6076 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.65964\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4783 - accuracy: 0.7646 - val_loss: 0.6078 - val_accuracy: 0.6560\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.65964\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5173 - accuracy: 0.7335 - val_loss: 0.6034 - val_accuracy: 0.6556\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65563, saving model to model/fullrun3/CV_7\\model_7.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5125 - accuracy: 0.7386 - val_loss: 0.6026 - val_accuracy: 0.6572\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65563 to 0.65720, saving model to model/fullrun3/CV_7\\model_7.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5090 - accuracy: 0.7421 - val_loss: 0.6108 - val_accuracy: 0.6537\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.65720\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5011 - accuracy: 0.7487 - val_loss: 0.6045 - val_accuracy: 0.6565\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65720\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4981 - accuracy: 0.7514 - val_loss: 0.6026 - val_accuracy: 0.6602\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.65720 to 0.66016, saving model to model/fullrun3/CV_7\\model_7.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4934 - accuracy: 0.7540 - val_loss: 0.6074 - val_accuracy: 0.6572\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66016\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4913 - accuracy: 0.7556 - val_loss: 0.6025 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66016 to 0.66138, saving model to model/fullrun3/CV_7\\model_7.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4898 - accuracy: 0.7582 - val_loss: 0.6033 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66138\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4805 - accuracy: 0.7622 - val_loss: 0.6069 - val_accuracy: 0.6591\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66138\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4815 - accuracy: 0.7633 - val_loss: 0.6040 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66138\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4810 - accuracy: 0.7624 - val_loss: 0.6040 - val_accuracy: 0.6616\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.66138 to 0.66155, saving model to model/fullrun3/CV_7\\model_7.h5\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4767 - accuracy: 0.7652 - val_loss: 0.6102 - val_accuracy: 0.6582\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66155\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4747 - accuracy: 0.7658 - val_loss: 0.6120 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66155\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4746 - accuracy: 0.7652 - val_loss: 0.6103 - val_accuracy: 0.6577\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66155\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4750 - accuracy: 0.7662 - val_loss: 0.6108 - val_accuracy: 0.6563\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66155\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4767 - accuracy: 0.7641 - val_loss: 0.6082 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66155\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4728 - accuracy: 0.7670 - val_loss: 0.6067 - val_accuracy: 0.6582\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66155\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4717 - accuracy: 0.7690 - val_loss: 0.6058 - val_accuracy: 0.6535\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66155\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4735 - accuracy: 0.7684 - val_loss: 0.6072 - val_accuracy: 0.6541\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.66155\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4699 - accuracy: 0.7702 - val_loss: 0.6125 - val_accuracy: 0.6541\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66155\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4824 - accuracy: 0.7598 - val_loss: 0.6057 - val_accuracy: 0.6563\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66155\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5163 - accuracy: 0.7382 - val_loss: 0.6056 - val_accuracy: 0.6528\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65284, saving model to model/fullrun3/CV_7\\model_8.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5125 - accuracy: 0.7392 - val_loss: 0.6099 - val_accuracy: 0.6535\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65284 to 0.65354, saving model to model/fullrun3/CV_7\\model_8.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5115 - accuracy: 0.7418 - val_loss: 0.6089 - val_accuracy: 0.6555\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.65354 to 0.65545, saving model to model/fullrun3/CV_7\\model_8.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5042 - accuracy: 0.7463 - val_loss: 0.6102 - val_accuracy: 0.6527\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65545\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4957 - accuracy: 0.7524 - val_loss: 0.6099 - val_accuracy: 0.6562\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.65545 to 0.65615, saving model to model/fullrun3/CV_7\\model_8.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4942 - accuracy: 0.7537 - val_loss: 0.6150 - val_accuracy: 0.6521\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.65615\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4901 - accuracy: 0.7550 - val_loss: 0.6055 - val_accuracy: 0.6523\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.65615\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4906 - accuracy: 0.7553 - val_loss: 0.6104 - val_accuracy: 0.6570\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.65615 to 0.65702, saving model to model/fullrun3/CV_7\\model_8.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4832 - accuracy: 0.7622 - val_loss: 0.6121 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.65702\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4808 - accuracy: 0.7646 - val_loss: 0.6043 - val_accuracy: 0.6560\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.65702\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4808 - accuracy: 0.7637 - val_loss: 0.6123 - val_accuracy: 0.6535\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.65702\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4778 - accuracy: 0.7639 - val_loss: 0.6143 - val_accuracy: 0.6518\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.65702\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4755 - accuracy: 0.7658 - val_loss: 0.6101 - val_accuracy: 0.6562\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.65702\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4743 - accuracy: 0.7676 - val_loss: 0.6165 - val_accuracy: 0.6502\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.65702\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4749 - accuracy: 0.7672 - val_loss: 0.6134 - val_accuracy: 0.6534\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.65702\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4746 - accuracy: 0.7654 - val_loss: 0.6098 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.65702\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4684 - accuracy: 0.7727 - val_loss: 0.6096 - val_accuracy: 0.6549\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.65702\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4681 - accuracy: 0.7715 - val_loss: 0.6116 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.65702 to 0.65755, saving model to model/fullrun3/CV_7\\model_8.h5\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4711 - accuracy: 0.7698 - val_loss: 0.6107 - val_accuracy: 0.6558\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.65755\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4684 - accuracy: 0.7742 - val_loss: 0.6178 - val_accuracy: 0.6460\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.65755\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4774 - accuracy: 0.7650 - val_loss: 0.6092 - val_accuracy: 0.6537\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.65755\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4857 - accuracy: 0.7557 - val_loss: 0.6046 - val_accuracy: 0.6565\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.65755\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4841 - accuracy: 0.7578 - val_loss: 0.6079 - val_accuracy: 0.6542\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.65755\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4839 - accuracy: 0.7592 - val_loss: 0.6113 - val_accuracy: 0.6551\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.65755\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4836 - accuracy: 0.7582 - val_loss: 0.6051 - val_accuracy: 0.6565\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.65755\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4751 - accuracy: 0.7666 - val_loss: 0.6092 - val_accuracy: 0.6535\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.65755\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4818 - accuracy: 0.7610 - val_loss: 0.6039 - val_accuracy: 0.6535\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.65755\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4818 - accuracy: 0.7590 - val_loss: 0.6086 - val_accuracy: 0.6516\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.65755\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5404 - accuracy: 0.7161 - val_loss: 0.5999 - val_accuracy: 0.6568\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65685, saving model to model/fullrun3/CV_7\\model_9.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5366 - accuracy: 0.7188 - val_loss: 0.6021 - val_accuracy: 0.6527\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.65685\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5304 - accuracy: 0.7252 - val_loss: 0.6015 - val_accuracy: 0.6586\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.65685 to 0.65859, saving model to model/fullrun3/CV_7\\model_9.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5294 - accuracy: 0.7250 - val_loss: 0.6063 - val_accuracy: 0.6534\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65859\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5233 - accuracy: 0.7311 - val_loss: 0.6008 - val_accuracy: 0.6542\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.65859\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5210 - accuracy: 0.7328 - val_loss: 0.6011 - val_accuracy: 0.6577\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.65859\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5161 - accuracy: 0.7348 - val_loss: 0.6047 - val_accuracy: 0.6565\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.65859\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5161 - accuracy: 0.7349 - val_loss: 0.6071 - val_accuracy: 0.6551\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.65859\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5131 - accuracy: 0.7387 - val_loss: 0.5989 - val_accuracy: 0.6563\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.65859\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5094 - accuracy: 0.7371 - val_loss: 0.6010 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.65859 to 0.65929, saving model to model/fullrun3/CV_7\\model_9.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5078 - accuracy: 0.7423 - val_loss: 0.5998 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.65929\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5030 - accuracy: 0.7458 - val_loss: 0.6011 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.65929\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5018 - accuracy: 0.7455 - val_loss: 0.6042 - val_accuracy: 0.6577\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.65929\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5011 - accuracy: 0.7472 - val_loss: 0.6021 - val_accuracy: 0.6586\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.65929\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4978 - accuracy: 0.7482 - val_loss: 0.6078 - val_accuracy: 0.6568\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.65929\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4944 - accuracy: 0.7547 - val_loss: 0.6008 - val_accuracy: 0.6553\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.65929\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4940 - accuracy: 0.7521 - val_loss: 0.6017 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.65929\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4934 - accuracy: 0.7533 - val_loss: 0.6038 - val_accuracy: 0.6553\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.65929\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4907 - accuracy: 0.7553 - val_loss: 0.6003 - val_accuracy: 0.6542\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.65929\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4878 - accuracy: 0.7560 - val_loss: 0.6063 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.65929\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 9s 78ms/step - loss: 0.6705 - accuracy: 0.5629 - val_loss: 0.6447 - val_accuracy: 0.5701\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57006, saving model to model/fullrun3/CV_8\\model_0.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.6358 - accuracy: 0.5870 - val_loss: 0.6482 - val_accuracy: 0.5411\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.57006\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.6229 - accuracy: 0.6191 - val_loss: 0.6194 - val_accuracy: 0.6335\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.57006 to 0.63350, saving model to model/fullrun3/CV_8\\model_0.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.6049 - accuracy: 0.6477 - val_loss: 0.6138 - val_accuracy: 0.6335\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.63350\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5939 - accuracy: 0.6613 - val_loss: 0.6020 - val_accuracy: 0.6539\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.63350 to 0.65389, saving model to model/fullrun3/CV_8\\model_0.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5839 - accuracy: 0.6714 - val_loss: 0.5950 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.65389 to 0.66121, saving model to model/fullrun3/CV_8\\model_0.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5738 - accuracy: 0.6840 - val_loss: 0.5911 - val_accuracy: 0.6635\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66121 to 0.66347, saving model to model/fullrun3/CV_8\\model_0.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5619 - accuracy: 0.6938 - val_loss: 0.6139 - val_accuracy: 0.6410\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66347\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5600 - accuracy: 0.6983 - val_loss: 0.5887 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.66347 to 0.67062, saving model to model/fullrun3/CV_8\\model_0.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5497 - accuracy: 0.7082 - val_loss: 0.5935 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67062\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5452 - accuracy: 0.7072 - val_loss: 0.5857 - val_accuracy: 0.6765\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.67062 to 0.67654, saving model to model/fullrun3/CV_8\\model_0.h5\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5401 - accuracy: 0.7143 - val_loss: 0.5864 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67654\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5345 - accuracy: 0.7191 - val_loss: 0.5862 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67654\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5302 - accuracy: 0.7244 - val_loss: 0.5859 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67654\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5263 - accuracy: 0.7247 - val_loss: 0.5874 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67654\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5245 - accuracy: 0.7250 - val_loss: 0.5880 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67654\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5196 - accuracy: 0.7316 - val_loss: 0.5932 - val_accuracy: 0.6623\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67654\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5172 - accuracy: 0.7342 - val_loss: 0.5916 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67654\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5161 - accuracy: 0.7350 - val_loss: 0.5925 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67654\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5113 - accuracy: 0.7385 - val_loss: 0.5924 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67654\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5124 - accuracy: 0.7373 - val_loss: 0.5911 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67654\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5611 - accuracy: 0.6952 - val_loss: 0.5871 - val_accuracy: 0.6649\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66487, saving model to model/fullrun3/CV_8\\model_1.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5474 - accuracy: 0.7100 - val_loss: 0.5903 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66487 to 0.67166, saving model to model/fullrun3/CV_8\\model_1.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5429 - accuracy: 0.7112 - val_loss: 0.5866 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67166 to 0.67689, saving model to model/fullrun3/CV_8\\model_1.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5356 - accuracy: 0.7197 - val_loss: 0.5833 - val_accuracy: 0.6765\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67689\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5296 - accuracy: 0.7244 - val_loss: 0.5868 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67689\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5229 - accuracy: 0.7305 - val_loss: 0.5885 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67689\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5219 - accuracy: 0.7291 - val_loss: 0.5841 - val_accuracy: 0.6778\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.67689 to 0.67776, saving model to model/fullrun3/CV_8\\model_1.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5150 - accuracy: 0.7347 - val_loss: 0.5838 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67776\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5137 - accuracy: 0.7358 - val_loss: 0.5853 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67776\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5069 - accuracy: 0.7429 - val_loss: 0.5845 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67776\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5040 - accuracy: 0.7442 - val_loss: 0.5850 - val_accuracy: 0.6765\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67776\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5054 - accuracy: 0.7431 - val_loss: 0.5861 - val_accuracy: 0.6788\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.67776 to 0.67881, saving model to model/fullrun3/CV_8\\model_1.h5\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5001 - accuracy: 0.7472 - val_loss: 0.5855 - val_accuracy: 0.6765\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67881\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4960 - accuracy: 0.7481 - val_loss: 0.5893 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67881\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5003 - accuracy: 0.7464 - val_loss: 0.5865 - val_accuracy: 0.6804\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.67881 to 0.68038, saving model to model/fullrun3/CV_8\\model_1.h5\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4940 - accuracy: 0.7512 - val_loss: 0.5883 - val_accuracy: 0.6753\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.68038\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4939 - accuracy: 0.7510 - val_loss: 0.5885 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68038\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4910 - accuracy: 0.7570 - val_loss: 0.5892 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68038\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4897 - accuracy: 0.7559 - val_loss: 0.5897 - val_accuracy: 0.6771\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68038\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4864 - accuracy: 0.7569 - val_loss: 0.5942 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.68038\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4830 - accuracy: 0.7594 - val_loss: 0.5919 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.68038\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4974 - accuracy: 0.7486 - val_loss: 0.5906 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.68038\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4948 - accuracy: 0.7484 - val_loss: 0.5904 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.68038\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4936 - accuracy: 0.7520 - val_loss: 0.5919 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.68038\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4913 - accuracy: 0.7526 - val_loss: 0.5902 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.68038\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5470 - accuracy: 0.7104 - val_loss: 0.5867 - val_accuracy: 0.6764\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67637, saving model to model/fullrun3/CV_8\\model_2.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5355 - accuracy: 0.7214 - val_loss: 0.5904 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67637\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5341 - accuracy: 0.7212 - val_loss: 0.5881 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67637\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5250 - accuracy: 0.7288 - val_loss: 0.5859 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67637\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5222 - accuracy: 0.7317 - val_loss: 0.5883 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67637\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5142 - accuracy: 0.7373 - val_loss: 0.5871 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67637\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5147 - accuracy: 0.7364 - val_loss: 0.5846 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67637\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5058 - accuracy: 0.7452 - val_loss: 0.5836 - val_accuracy: 0.6795\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.67637 to 0.67951, saving model to model/fullrun3/CV_8\\model_2.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5049 - accuracy: 0.7446 - val_loss: 0.5881 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67951\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4989 - accuracy: 0.7476 - val_loss: 0.5837 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67951\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5003 - accuracy: 0.7474 - val_loss: 0.5835 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67951\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4974 - accuracy: 0.7504 - val_loss: 0.5853 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67951\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4929 - accuracy: 0.7525 - val_loss: 0.5862 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67951\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4908 - accuracy: 0.7546 - val_loss: 0.5848 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67951\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4893 - accuracy: 0.7574 - val_loss: 0.5881 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67951\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4906 - accuracy: 0.7557 - val_loss: 0.5845 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67951\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4852 - accuracy: 0.7598 - val_loss: 0.5889 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67951\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4841 - accuracy: 0.7592 - val_loss: 0.5882 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67951\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5356 - accuracy: 0.7227 - val_loss: 0.5854 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67445, saving model to model/fullrun3/CV_8\\model_3.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5261 - accuracy: 0.7288 - val_loss: 0.5885 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67445\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5232 - accuracy: 0.7320 - val_loss: 0.5870 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67445\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5158 - accuracy: 0.7368 - val_loss: 0.5846 - val_accuracy: 0.6788\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67445 to 0.67881, saving model to model/fullrun3/CV_8\\model_3.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5105 - accuracy: 0.7411 - val_loss: 0.5864 - val_accuracy: 0.6772\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67881\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5063 - accuracy: 0.7429 - val_loss: 0.5931 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67881\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5043 - accuracy: 0.7469 - val_loss: 0.5875 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67881\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4997 - accuracy: 0.7482 - val_loss: 0.5843 - val_accuracy: 0.6765\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67881\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4984 - accuracy: 0.7500 - val_loss: 0.5857 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67881\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4919 - accuracy: 0.7529 - val_loss: 0.5841 - val_accuracy: 0.6778\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67881\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4934 - accuracy: 0.7518 - val_loss: 0.5857 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67881\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4886 - accuracy: 0.7548 - val_loss: 0.5906 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67881\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4833 - accuracy: 0.7592 - val_loss: 0.5905 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67881\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4820 - accuracy: 0.7625 - val_loss: 0.5885 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67881\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5215 - accuracy: 0.7329 - val_loss: 0.5845 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67393, saving model to model/fullrun3/CV_8\\model_4.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5129 - accuracy: 0.7367 - val_loss: 0.5921 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67393\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5133 - accuracy: 0.7385 - val_loss: 0.5912 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67393\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5041 - accuracy: 0.7437 - val_loss: 0.5881 - val_accuracy: 0.6760\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67393 to 0.67602, saving model to model/fullrun3/CV_8\\model_4.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4975 - accuracy: 0.7487 - val_loss: 0.5928 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67602\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4951 - accuracy: 0.7505 - val_loss: 0.5975 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67602\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4936 - accuracy: 0.7543 - val_loss: 0.5902 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67602\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4883 - accuracy: 0.7574 - val_loss: 0.5916 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67602\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4853 - accuracy: 0.7576 - val_loss: 0.5912 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67602\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4834 - accuracy: 0.7604 - val_loss: 0.5890 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67602\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4825 - accuracy: 0.7601 - val_loss: 0.5908 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67602\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4788 - accuracy: 0.7642 - val_loss: 0.5950 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67602\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4721 - accuracy: 0.7659 - val_loss: 0.5964 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67602\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4727 - accuracy: 0.7692 - val_loss: 0.6007 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67602\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.5176 - accuracy: 0.7383 - val_loss: 0.5877 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67131, saving model to model/fullrun3/CV_8\\model_5.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5125 - accuracy: 0.7406 - val_loss: 0.5947 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67131\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5101 - accuracy: 0.7423 - val_loss: 0.5903 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67131\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5009 - accuracy: 0.7477 - val_loss: 0.5893 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67131 to 0.67375, saving model to model/fullrun3/CV_8\\model_5.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4942 - accuracy: 0.7525 - val_loss: 0.5962 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67375\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4897 - accuracy: 0.7567 - val_loss: 0.5987 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67375\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4911 - accuracy: 0.7554 - val_loss: 0.5942 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67375\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4845 - accuracy: 0.7609 - val_loss: 0.5946 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67375\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4841 - accuracy: 0.7611 - val_loss: 0.5967 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67375\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4766 - accuracy: 0.7667 - val_loss: 0.5930 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67375\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4783 - accuracy: 0.7629 - val_loss: 0.5979 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67375\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4754 - accuracy: 0.7650 - val_loss: 0.5984 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67375\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4698 - accuracy: 0.7689 - val_loss: 0.6021 - val_accuracy: 0.6657\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67375\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4687 - accuracy: 0.7699 - val_loss: 0.6019 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67375\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5125 - accuracy: 0.7401 - val_loss: 0.5895 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66870, saving model to model/fullrun3/CV_8\\model_6.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5055 - accuracy: 0.7462 - val_loss: 0.5935 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66870\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5052 - accuracy: 0.7432 - val_loss: 0.5950 - val_accuracy: 0.6621\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66870\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4976 - accuracy: 0.7515 - val_loss: 0.5922 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66870\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4924 - accuracy: 0.7542 - val_loss: 0.5987 - val_accuracy: 0.6635\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66870\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4871 - accuracy: 0.7594 - val_loss: 0.6025 - val_accuracy: 0.6570\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66870\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4884 - accuracy: 0.7570 - val_loss: 0.5973 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66870\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4821 - accuracy: 0.7612 - val_loss: 0.5950 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66870\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4795 - accuracy: 0.7633 - val_loss: 0.6002 - val_accuracy: 0.6626\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66870\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4759 - accuracy: 0.7665 - val_loss: 0.5922 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66870\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4735 - accuracy: 0.7663 - val_loss: 0.5962 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66870\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5032 - accuracy: 0.7473 - val_loss: 0.5940 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66399, saving model to model/fullrun3/CV_8\\model_7.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5005 - accuracy: 0.7498 - val_loss: 0.5990 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66399\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4972 - accuracy: 0.7524 - val_loss: 0.5950 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66399\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4903 - accuracy: 0.7575 - val_loss: 0.5977 - val_accuracy: 0.6609\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66399\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4842 - accuracy: 0.7612 - val_loss: 0.6015 - val_accuracy: 0.6603\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66399\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4803 - accuracy: 0.7639 - val_loss: 0.6084 - val_accuracy: 0.6562\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66399\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4818 - accuracy: 0.7625 - val_loss: 0.5985 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66399 to 0.66748, saving model to model/fullrun3/CV_8\\model_7.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4757 - accuracy: 0.7669 - val_loss: 0.6041 - val_accuracy: 0.6635\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66748\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4737 - accuracy: 0.7675 - val_loss: 0.6018 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66748\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4721 - accuracy: 0.7713 - val_loss: 0.5953 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66748\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4681 - accuracy: 0.7710 - val_loss: 0.5973 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66748\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4848 - accuracy: 0.7585 - val_loss: 0.5980 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66748\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4781 - accuracy: 0.7657 - val_loss: 0.5975 - val_accuracy: 0.6626\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66748\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4773 - accuracy: 0.7647 - val_loss: 0.5946 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66748\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5003 - accuracy: 0.7456 - val_loss: 0.5878 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.66748 to 0.67027, saving model to model/fullrun3/CV_8\\model_7.h5\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4963 - accuracy: 0.7511 - val_loss: 0.5853 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.67027 to 0.67306, saving model to model/fullrun3/CV_8\\model_7.h5\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4934 - accuracy: 0.7514 - val_loss: 0.5863 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67306\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4915 - accuracy: 0.7529 - val_loss: 0.5866 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67306\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4903 - accuracy: 0.7542 - val_loss: 0.5869 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67306\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4907 - accuracy: 0.7550 - val_loss: 0.5881 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67306\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4877 - accuracy: 0.7564 - val_loss: 0.5865 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67306\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4886 - accuracy: 0.7548 - val_loss: 0.5850 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67306\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4885 - accuracy: 0.7546 - val_loss: 0.5886 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67306\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4886 - accuracy: 0.7566 - val_loss: 0.5897 - val_accuracy: 0.6656\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67306\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4838 - accuracy: 0.7579 - val_loss: 0.5869 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67306\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4882 - accuracy: 0.7562 - val_loss: 0.5886 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67306\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5137 - accuracy: 0.7393 - val_loss: 0.5907 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66521, saving model to model/fullrun3/CV_8\\model_8.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5063 - accuracy: 0.7437 - val_loss: 0.5933 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66521\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5064 - accuracy: 0.7434 - val_loss: 0.5911 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66521 to 0.66713, saving model to model/fullrun3/CV_8\\model_8.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4954 - accuracy: 0.7531 - val_loss: 0.5957 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66713\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4921 - accuracy: 0.7542 - val_loss: 0.5986 - val_accuracy: 0.6642\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66713\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4915 - accuracy: 0.7546 - val_loss: 0.6035 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66713\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4932 - accuracy: 0.7530 - val_loss: 0.5927 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66713 to 0.67323, saving model to model/fullrun3/CV_8\\model_8.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4814 - accuracy: 0.7624 - val_loss: 0.6037 - val_accuracy: 0.6623\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67323\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4840 - accuracy: 0.7600 - val_loss: 0.5978 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67323\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4781 - accuracy: 0.7650 - val_loss: 0.5908 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67323\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4759 - accuracy: 0.7663 - val_loss: 0.5948 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67323\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4810 - accuracy: 0.7615 - val_loss: 0.5980 - val_accuracy: 0.6609\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67323\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4798 - accuracy: 0.7618 - val_loss: 0.6008 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67323\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4750 - accuracy: 0.7678 - val_loss: 0.5987 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67323\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4904 - accuracy: 0.7526 - val_loss: 0.5937 - val_accuracy: 0.6671\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67323\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4893 - accuracy: 0.7557 - val_loss: 0.5884 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.67323 to 0.67428, saving model to model/fullrun3/CV_8\\model_8.h5\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4856 - accuracy: 0.7594 - val_loss: 0.5879 - val_accuracy: 0.6758\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.67428 to 0.67585, saving model to model/fullrun3/CV_8\\model_8.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.4842 - accuracy: 0.7581 - val_loss: 0.5880 - val_accuracy: 0.6797\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.67585 to 0.67968, saving model to model/fullrun3/CV_8\\model_8.h5\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4809 - accuracy: 0.7608 - val_loss: 0.5904 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67968\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4814 - accuracy: 0.7604 - val_loss: 0.5940 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67968\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4798 - accuracy: 0.7628 - val_loss: 0.5925 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67968\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4770 - accuracy: 0.7647 - val_loss: 0.5856 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67968\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4801 - accuracy: 0.7626 - val_loss: 0.5881 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67968\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4774 - accuracy: 0.7652 - val_loss: 0.5960 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67968\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4752 - accuracy: 0.7668 - val_loss: 0.5877 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.67968 to 0.68003, saving model to model/fullrun3/CV_8\\model_8.h5\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4739 - accuracy: 0.7666 - val_loss: 0.5911 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.68003\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4835 - accuracy: 0.7601 - val_loss: 0.5891 - val_accuracy: 0.6779\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.68003\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4825 - accuracy: 0.7596 - val_loss: 0.5884 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.68003\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4788 - accuracy: 0.7628 - val_loss: 0.5864 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.68003\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4789 - accuracy: 0.7633 - val_loss: 0.5912 - val_accuracy: 0.6781\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.68003\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4768 - accuracy: 0.7617 - val_loss: 0.5887 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.68003\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4766 - accuracy: 0.7649 - val_loss: 0.5911 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.68003\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4775 - accuracy: 0.7628 - val_loss: 0.5903 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.68003\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4751 - accuracy: 0.7641 - val_loss: 0.5914 - val_accuracy: 0.6765\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.68003\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4752 - accuracy: 0.7651 - val_loss: 0.5946 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.68003\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5481 - accuracy: 0.7096 - val_loss: 0.5902 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66783, saving model to model/fullrun3/CV_8\\model_9.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5381 - accuracy: 0.7178 - val_loss: 0.5890 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66783 to 0.66940, saving model to model/fullrun3/CV_8\\model_9.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5337 - accuracy: 0.7225 - val_loss: 0.5908 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66940\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.5304 - accuracy: 0.7248 - val_loss: 0.5924 - val_accuracy: 0.6642\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66940\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5248 - accuracy: 0.7284 - val_loss: 0.5903 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66940\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5242 - accuracy: 0.7285 - val_loss: 0.5863 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.66940 to 0.67166, saving model to model/fullrun3/CV_8\\model_9.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.5188 - accuracy: 0.7324 - val_loss: 0.5903 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67166\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.5179 - accuracy: 0.7344 - val_loss: 0.5919 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67166\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5129 - accuracy: 0.7410 - val_loss: 0.5879 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67166\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5121 - accuracy: 0.7411 - val_loss: 0.5910 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67166\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5101 - accuracy: 0.7422 - val_loss: 0.5851 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.67166 to 0.67288, saving model to model/fullrun3/CV_8\\model_9.h5\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5068 - accuracy: 0.7413 - val_loss: 0.5859 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67288\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5035 - accuracy: 0.7430 - val_loss: 0.5885 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67288\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5017 - accuracy: 0.7483 - val_loss: 0.5900 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67288\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4993 - accuracy: 0.7483 - val_loss: 0.5919 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67288\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5008 - accuracy: 0.7492 - val_loss: 0.5863 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67288\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4928 - accuracy: 0.7540 - val_loss: 0.5887 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.67288 to 0.67445, saving model to model/fullrun3/CV_8\\model_9.h5\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4928 - accuracy: 0.7548 - val_loss: 0.5900 - val_accuracy: 0.6692\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67445\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4918 - accuracy: 0.7537 - val_loss: 0.5896 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67445\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4920 - accuracy: 0.7554 - val_loss: 0.5920 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67445\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4884 - accuracy: 0.7531 - val_loss: 0.5885 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67445\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4892 - accuracy: 0.7562 - val_loss: 0.5876 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67445\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4880 - accuracy: 0.7564 - val_loss: 0.5920 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67445\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4843 - accuracy: 0.7601 - val_loss: 0.5905 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67445\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4834 - accuracy: 0.7588 - val_loss: 0.5937 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67445\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4798 - accuracy: 0.7606 - val_loss: 0.6012 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67445\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4827 - accuracy: 0.7603 - val_loss: 0.5931 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.67445 to 0.67480, saving model to model/fullrun3/CV_8\\model_9.h5\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4760 - accuracy: 0.7624 - val_loss: 0.5938 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.67480\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4743 - accuracy: 0.7677 - val_loss: 0.5978 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67480\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4788 - accuracy: 0.7648 - val_loss: 0.5914 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67480\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4754 - accuracy: 0.7651 - val_loss: 0.5941 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.67480\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4728 - accuracy: 0.7661 - val_loss: 0.5949 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.67480\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4763 - accuracy: 0.7665 - val_loss: 0.5975 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.67480\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4734 - accuracy: 0.7666 - val_loss: 0.5938 - val_accuracy: 0.6765\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.67480 to 0.67654, saving model to model/fullrun3/CV_8\\model_9.h5\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4696 - accuracy: 0.7679 - val_loss: 0.5940 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.67654\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4694 - accuracy: 0.7686 - val_loss: 0.5938 - val_accuracy: 0.6764\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.67654\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4672 - accuracy: 0.7715 - val_loss: 0.5979 - val_accuracy: 0.6711\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.67654\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4691 - accuracy: 0.7699 - val_loss: 0.5941 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.67654\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4695 - accuracy: 0.7710 - val_loss: 0.5919 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.67654\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4684 - accuracy: 0.7701 - val_loss: 0.5917 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.67654\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4638 - accuracy: 0.7730 - val_loss: 0.5934 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.67654\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4681 - accuracy: 0.7699 - val_loss: 0.5975 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.67654\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4654 - accuracy: 0.7729 - val_loss: 0.5976 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.67654\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4640 - accuracy: 0.7715 - val_loss: 0.5944 - val_accuracy: 0.6764\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.67654\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 9s 79ms/step - loss: 0.6717 - accuracy: 0.5652 - val_loss: 0.6482 - val_accuracy: 0.5720\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57198, saving model to model/fullrun3/CV_9\\model_0.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.6357 - accuracy: 0.5880 - val_loss: 0.6543 - val_accuracy: 0.5284\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.57198\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.6227 - accuracy: 0.6198 - val_loss: 0.6153 - val_accuracy: 0.6323\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.57198 to 0.63228, saving model to model/fullrun3/CV_9\\model_0.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.6035 - accuracy: 0.6526 - val_loss: 0.6196 - val_accuracy: 0.6162\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.63228\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5923 - accuracy: 0.6615 - val_loss: 0.6041 - val_accuracy: 0.6436\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.63228 to 0.64360, saving model to model/fullrun3/CV_9\\model_0.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5812 - accuracy: 0.6752 - val_loss: 0.5898 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.64360 to 0.66643, saving model to model/fullrun3/CV_9\\model_0.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5746 - accuracy: 0.6833 - val_loss: 0.5844 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66643 to 0.67166, saving model to model/fullrun3/CV_9\\model_0.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5634 - accuracy: 0.6924 - val_loss: 0.5811 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.67166 to 0.67236, saving model to model/fullrun3/CV_9\\model_0.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5565 - accuracy: 0.7020 - val_loss: 0.5819 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.67236 to 0.67497, saving model to model/fullrun3/CV_9\\model_0.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5506 - accuracy: 0.7022 - val_loss: 0.5837 - val_accuracy: 0.6657\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67497\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5459 - accuracy: 0.7099 - val_loss: 0.5846 - val_accuracy: 0.6664\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67497\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5384 - accuracy: 0.7149 - val_loss: 0.5811 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67497\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5351 - accuracy: 0.7188 - val_loss: 0.5815 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67497\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5302 - accuracy: 0.7242 - val_loss: 0.5818 - val_accuracy: 0.6748\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67497\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5285 - accuracy: 0.7243 - val_loss: 0.5837 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67497\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5243 - accuracy: 0.7263 - val_loss: 0.5814 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67497\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5211 - accuracy: 0.7308 - val_loss: 0.5863 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67497\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5158 - accuracy: 0.7322 - val_loss: 0.5862 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67497\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5145 - accuracy: 0.7360 - val_loss: 0.5843 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67497\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5638 - accuracy: 0.6934 - val_loss: 0.5821 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66835, saving model to model/fullrun3/CV_9\\model_1.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5495 - accuracy: 0.7075 - val_loss: 0.5852 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66835 to 0.67079, saving model to model/fullrun3/CV_9\\model_1.h5\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5444 - accuracy: 0.7102 - val_loss: 0.5806 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67079 to 0.67097, saving model to model/fullrun3/CV_9\\model_1.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5352 - accuracy: 0.7182 - val_loss: 0.5776 - val_accuracy: 0.6743\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67097 to 0.67428, saving model to model/fullrun3/CV_9\\model_1.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5300 - accuracy: 0.7239 - val_loss: 0.5803 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67428 to 0.67497, saving model to model/fullrun3/CV_9\\model_1.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5256 - accuracy: 0.7265 - val_loss: 0.5828 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.67497 to 0.67619, saving model to model/fullrun3/CV_9\\model_1.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5220 - accuracy: 0.7311 - val_loss: 0.5792 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67619\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5155 - accuracy: 0.7355 - val_loss: 0.5802 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67619\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5132 - accuracy: 0.7363 - val_loss: 0.5813 - val_accuracy: 0.6772\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.67619 to 0.67724, saving model to model/fullrun3/CV_9\\model_1.h5\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5098 - accuracy: 0.7409 - val_loss: 0.5809 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.67724 to 0.67863, saving model to model/fullrun3/CV_9\\model_1.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5070 - accuracy: 0.7425 - val_loss: 0.5816 - val_accuracy: 0.6785\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67863\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5039 - accuracy: 0.7437 - val_loss: 0.5826 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67863\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5025 - accuracy: 0.7458 - val_loss: 0.5837 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67863\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5012 - accuracy: 0.7483 - val_loss: 0.5863 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67863\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4973 - accuracy: 0.7512 - val_loss: 0.5835 - val_accuracy: 0.6720\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67863\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4959 - accuracy: 0.7529 - val_loss: 0.5869 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67863\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4942 - accuracy: 0.7494 - val_loss: 0.5851 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67863\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4910 - accuracy: 0.7545 - val_loss: 0.5892 - val_accuracy: 0.6727\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67863\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4893 - accuracy: 0.7568 - val_loss: 0.5868 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67863\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5025 - accuracy: 0.7440 - val_loss: 0.5889 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67863\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5470 - accuracy: 0.7108 - val_loss: 0.5829 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67149, saving model to model/fullrun3/CV_9\\model_2.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5364 - accuracy: 0.7188 - val_loss: 0.5901 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67149\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5300 - accuracy: 0.7251 - val_loss: 0.5851 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67149 to 0.67393, saving model to model/fullrun3/CV_9\\model_2.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5240 - accuracy: 0.7291 - val_loss: 0.5802 - val_accuracy: 0.6745\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67393 to 0.67445, saving model to model/fullrun3/CV_9\\model_2.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5161 - accuracy: 0.7337 - val_loss: 0.5821 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67445 to 0.67463, saving model to model/fullrun3/CV_9\\model_2.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5133 - accuracy: 0.7367 - val_loss: 0.5858 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67463\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5111 - accuracy: 0.7379 - val_loss: 0.5837 - val_accuracy: 0.6724\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67463\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5045 - accuracy: 0.7421 - val_loss: 0.5801 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.67463 to 0.67567, saving model to model/fullrun3/CV_9\\model_2.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5040 - accuracy: 0.7455 - val_loss: 0.5861 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67567\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4969 - accuracy: 0.7507 - val_loss: 0.5822 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67567\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4992 - accuracy: 0.7469 - val_loss: 0.5810 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67567\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4940 - accuracy: 0.7541 - val_loss: 0.5856 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67567\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4912 - accuracy: 0.7540 - val_loss: 0.5822 - val_accuracy: 0.6767\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.67567 to 0.67672, saving model to model/fullrun3/CV_9\\model_2.h5\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4899 - accuracy: 0.7551 - val_loss: 0.5842 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67672\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4890 - accuracy: 0.7553 - val_loss: 0.5842 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67672\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4847 - accuracy: 0.7597 - val_loss: 0.5916 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67672\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4856 - accuracy: 0.7559 - val_loss: 0.5838 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67672\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4810 - accuracy: 0.7604 - val_loss: 0.5870 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67672\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4809 - accuracy: 0.7628 - val_loss: 0.5872 - val_accuracy: 0.6729\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67672\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4862 - accuracy: 0.7585 - val_loss: 0.5923 - val_accuracy: 0.6649\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67672\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4978 - accuracy: 0.7478 - val_loss: 0.5892 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67672\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4951 - accuracy: 0.7492 - val_loss: 0.5836 - val_accuracy: 0.6757\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67672\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4933 - accuracy: 0.7511 - val_loss: 0.5883 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67672\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5396 - accuracy: 0.7176 - val_loss: 0.5839 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67410, saving model to model/fullrun3/CV_9\\model_3.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5306 - accuracy: 0.7248 - val_loss: 0.5871 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67410\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5236 - accuracy: 0.7300 - val_loss: 0.5905 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67410\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5183 - accuracy: 0.7362 - val_loss: 0.5832 - val_accuracy: 0.6746\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67410 to 0.67463, saving model to model/fullrun3/CV_9\\model_3.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5118 - accuracy: 0.7385 - val_loss: 0.5889 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67463\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5072 - accuracy: 0.7415 - val_loss: 0.5915 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67463\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5041 - accuracy: 0.7434 - val_loss: 0.5893 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67463\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5031 - accuracy: 0.7463 - val_loss: 0.5854 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67463\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5010 - accuracy: 0.7467 - val_loss: 0.5904 - val_accuracy: 0.6685\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67463\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4955 - accuracy: 0.7497 - val_loss: 0.5886 - val_accuracy: 0.6708\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67463\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4949 - accuracy: 0.7523 - val_loss: 0.5860 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67463\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4904 - accuracy: 0.7540 - val_loss: 0.5917 - val_accuracy: 0.6682\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67463\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4874 - accuracy: 0.7579 - val_loss: 0.5888 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67463\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4866 - accuracy: 0.7582 - val_loss: 0.5899 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67463\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5272 - accuracy: 0.7271 - val_loss: 0.5861 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66800, saving model to model/fullrun3/CV_9\\model_4.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5185 - accuracy: 0.7347 - val_loss: 0.5915 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66800\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5119 - accuracy: 0.7421 - val_loss: 0.5905 - val_accuracy: 0.6652\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66800\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5049 - accuracy: 0.7465 - val_loss: 0.5876 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.66800 to 0.67009, saving model to model/fullrun3/CV_9\\model_4.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5013 - accuracy: 0.7478 - val_loss: 0.5889 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67009\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4991 - accuracy: 0.7492 - val_loss: 0.5911 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67009\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4946 - accuracy: 0.7539 - val_loss: 0.5884 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67009\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4932 - accuracy: 0.7525 - val_loss: 0.5874 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.67009 to 0.67131, saving model to model/fullrun3/CV_9\\model_4.h5\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4892 - accuracy: 0.7548 - val_loss: 0.5933 - val_accuracy: 0.6636\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67131\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4853 - accuracy: 0.7588 - val_loss: 0.5887 - val_accuracy: 0.6717\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.67131 to 0.67166, saving model to model/fullrun3/CV_9\\model_4.h5\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4851 - accuracy: 0.7586 - val_loss: 0.5898 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67166\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4788 - accuracy: 0.7623 - val_loss: 0.5967 - val_accuracy: 0.6643\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67166\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4796 - accuracy: 0.7609 - val_loss: 0.5922 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67166\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4772 - accuracy: 0.7651 - val_loss: 0.5947 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67166\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4901 - accuracy: 0.7553 - val_loss: 0.5911 - val_accuracy: 0.6687\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67166\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4885 - accuracy: 0.7549 - val_loss: 0.5897 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67166\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4860 - accuracy: 0.7579 - val_loss: 0.5888 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67166\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4828 - accuracy: 0.7608 - val_loss: 0.5921 - val_accuracy: 0.6636\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67166\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4830 - accuracy: 0.7593 - val_loss: 0.5909 - val_accuracy: 0.6649\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67166\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4837 - accuracy: 0.7597 - val_loss: 0.5956 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67166\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5241 - accuracy: 0.7292 - val_loss: 0.5904 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66190, saving model to model/fullrun3/CV_9\\model_5.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5178 - accuracy: 0.7348 - val_loss: 0.5929 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66190\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5134 - accuracy: 0.7405 - val_loss: 0.5947 - val_accuracy: 0.6584\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66190\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5044 - accuracy: 0.7449 - val_loss: 0.5915 - val_accuracy: 0.6624\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.66190 to 0.66243, saving model to model/fullrun3/CV_9\\model_5.h5\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.5020 - accuracy: 0.7476 - val_loss: 0.5965 - val_accuracy: 0.6610\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66243\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4984 - accuracy: 0.7509 - val_loss: 0.5945 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66243\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4935 - accuracy: 0.7545 - val_loss: 0.5952 - val_accuracy: 0.6603\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66243\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4907 - accuracy: 0.7563 - val_loss: 0.5944 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66243\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4874 - accuracy: 0.7576 - val_loss: 0.5982 - val_accuracy: 0.6542\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66243\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4858 - accuracy: 0.7602 - val_loss: 0.5950 - val_accuracy: 0.6584\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66243\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4831 - accuracy: 0.7595 - val_loss: 0.5966 - val_accuracy: 0.6610\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66243\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4772 - accuracy: 0.7648 - val_loss: 0.6075 - val_accuracy: 0.6513\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66243\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4777 - accuracy: 0.7628 - val_loss: 0.5978 - val_accuracy: 0.6603\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66243\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4768 - accuracy: 0.7670 - val_loss: 0.6011 - val_accuracy: 0.6584\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66243\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.5186 - accuracy: 0.7350 - val_loss: 0.5912 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66051, saving model to model/fullrun3/CV_9\\model_6.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5122 - accuracy: 0.7406 - val_loss: 0.5936 - val_accuracy: 0.6596\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66051\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5062 - accuracy: 0.7462 - val_loss: 0.5924 - val_accuracy: 0.6616\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66051 to 0.66155, saving model to model/fullrun3/CV_9\\model_6.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5021 - accuracy: 0.7485 - val_loss: 0.5929 - val_accuracy: 0.6596\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66155\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4957 - accuracy: 0.7521 - val_loss: 0.5928 - val_accuracy: 0.6621\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.66155 to 0.66208, saving model to model/fullrun3/CV_9\\model_6.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4913 - accuracy: 0.7549 - val_loss: 0.5977 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66208\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4872 - accuracy: 0.7588 - val_loss: 0.5966 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66208 to 0.66765, saving model to model/fullrun3/CV_9\\model_6.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4815 - accuracy: 0.7614 - val_loss: 0.5926 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66765\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4822 - accuracy: 0.7610 - val_loss: 0.6002 - val_accuracy: 0.6582\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66765\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4804 - accuracy: 0.7619 - val_loss: 0.5913 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66765\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4772 - accuracy: 0.7659 - val_loss: 0.5932 - val_accuracy: 0.6624\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66765\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4710 - accuracy: 0.7706 - val_loss: 0.6062 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66765\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4723 - accuracy: 0.7696 - val_loss: 0.5970 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66765\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4686 - accuracy: 0.7701 - val_loss: 0.5961 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66765\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4911 - accuracy: 0.7553 - val_loss: 0.5919 - val_accuracy: 0.6621\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66765\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4880 - accuracy: 0.7563 - val_loss: 0.5929 - val_accuracy: 0.6624\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66765\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4836 - accuracy: 0.7585 - val_loss: 0.5897 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66765\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 78ms/step - loss: 0.5138 - accuracy: 0.7381 - val_loss: 0.5924 - val_accuracy: 0.6656\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66556, saving model to model/fullrun3/CV_9\\model_7.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5101 - accuracy: 0.7418 - val_loss: 0.5935 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66556\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5009 - accuracy: 0.7506 - val_loss: 0.5954 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66556\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4972 - accuracy: 0.7503 - val_loss: 0.5927 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66556\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4936 - accuracy: 0.7535 - val_loss: 0.5951 - val_accuracy: 0.6656\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66556\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4901 - accuracy: 0.7572 - val_loss: 0.5982 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66556\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4870 - accuracy: 0.7597 - val_loss: 0.5951 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66556 to 0.66765, saving model to model/fullrun3/CV_9\\model_7.h5\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4818 - accuracy: 0.7630 - val_loss: 0.5939 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66765\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4817 - accuracy: 0.7611 - val_loss: 0.6015 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66765\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4773 - accuracy: 0.7643 - val_loss: 0.5967 - val_accuracy: 0.6612\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66765\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4763 - accuracy: 0.7650 - val_loss: 0.5985 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66765\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4707 - accuracy: 0.7710 - val_loss: 0.6022 - val_accuracy: 0.6633\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66765\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4713 - accuracy: 0.7683 - val_loss: 0.6005 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66765\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4683 - accuracy: 0.7722 - val_loss: 0.6027 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66765\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4809 - accuracy: 0.7626 - val_loss: 0.5988 - val_accuracy: 0.6595\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66765\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4775 - accuracy: 0.7631 - val_loss: 0.5933 - val_accuracy: 0.6643\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66765\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4752 - accuracy: 0.7672 - val_loss: 0.5920 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66765\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5103 - accuracy: 0.7419 - val_loss: 0.5920 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66504, saving model to model/fullrun3/CV_9\\model_8.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5061 - accuracy: 0.7441 - val_loss: 0.5968 - val_accuracy: 0.6619\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66504\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5021 - accuracy: 0.7486 - val_loss: 0.5973 - val_accuracy: 0.6636\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66504\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4978 - accuracy: 0.7520 - val_loss: 0.5996 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66504\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4897 - accuracy: 0.7571 - val_loss: 0.6027 - val_accuracy: 0.6586\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66504\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4876 - accuracy: 0.7587 - val_loss: 0.6028 - val_accuracy: 0.6596\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66504\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4859 - accuracy: 0.7607 - val_loss: 0.6063 - val_accuracy: 0.6602\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66504\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.4785 - accuracy: 0.7637 - val_loss: 0.6017 - val_accuracy: 0.6621\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66504\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4802 - accuracy: 0.7626 - val_loss: 0.6038 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66504\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4790 - accuracy: 0.7655 - val_loss: 0.5986 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66504\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.4760 - accuracy: 0.7670 - val_loss: 0.6046 - val_accuracy: 0.6579\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.66504\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5405 - accuracy: 0.7144 - val_loss: 0.5891 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66731, saving model to model/fullrun3/CV_9\\model_9.h5\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5350 - accuracy: 0.7208 - val_loss: 0.5905 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66731\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5349 - accuracy: 0.7182 - val_loss: 0.5871 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66731 to 0.66748, saving model to model/fullrun3/CV_9\\model_9.h5\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5263 - accuracy: 0.7277 - val_loss: 0.5881 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66748\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5240 - accuracy: 0.7279 - val_loss: 0.5860 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.66748 to 0.66957, saving model to model/fullrun3/CV_9\\model_9.h5\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5194 - accuracy: 0.7330 - val_loss: 0.5832 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.66957 to 0.67375, saving model to model/fullrun3/CV_9\\model_9.h5\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5185 - accuracy: 0.7349 - val_loss: 0.5901 - val_accuracy: 0.6643\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67375\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5140 - accuracy: 0.7385 - val_loss: 0.5865 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67375\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5136 - accuracy: 0.7360 - val_loss: 0.5854 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67375\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5109 - accuracy: 0.7389 - val_loss: 0.5896 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67375\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5057 - accuracy: 0.7438 - val_loss: 0.5853 - val_accuracy: 0.6703\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67375\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5079 - accuracy: 0.7412 - val_loss: 0.5834 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67375\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 8s 77ms/step - loss: 0.5032 - accuracy: 0.7455 - val_loss: 0.5914 - val_accuracy: 0.6610\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67375\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 8s 76ms/step - loss: 0.5013 - accuracy: 0.7460 - val_loss: 0.5828 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67375\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4971 - accuracy: 0.7505 - val_loss: 0.5904 - val_accuracy: 0.6624\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67375\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 8s 75ms/step - loss: 0.4946 - accuracy: 0.7521 - val_loss: 0.5849 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67375\n",
      "CPU times: total: 5h 22min 51s\n",
      "Wall time: 5h 8min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "\ttrain_model(trainx, trainy, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d0cb864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 1s 3ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 1s 3ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 1s 3ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "auroc =  0.7568850858341855\n",
      "aupr =  0.7365158329326047\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 1s 3ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "auroc =  0.7444576773556003\n",
      "aupr =  0.7177677888243916\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 1s 3ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "auroc =  0.7641450580300881\n",
      "aupr =  0.737560776342218\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 1s 3ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "auroc =  0.7564063562843686\n",
      "aupr =  0.7393486158089969\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 1s 3ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "auroc =  0.757711822184015\n",
      "aupr =  0.7384266465870019\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 1s 3ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "auroc =  0.7516725161857484\n",
      "aupr =  0.7284025632115836\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "auroc =  0.748110746466993\n",
      "aupr =  0.7369498867520178\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 1s 3ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "auroc =  0.7506238791830216\n",
      "aupr =  0.7243365000107407\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 1s 3ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "auroc =  0.7481702763437625\n",
      "aupr =  0.731079218494488\n",
      "CPU times: total: 1min 45s\n",
      "Wall time: 1min 47s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 620x620 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 620x620 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "\tgenerate_curves(trainx, trainy, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d0cb864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 330, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 330, 256)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 586)          66049       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            84481       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "200/200 [==============================] - 4s 3ms/step\n",
      "CPU times: total: 3.66 s\n",
      "Wall time: 5.82 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 620x620 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 620x620 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "\ttest_model(valx, valy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267d6781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deephtlv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3395fde9124d4e43fe1ba25af65432035387285b638bc47c56e288c9c5de6369"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

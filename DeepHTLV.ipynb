{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac1e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import random\n",
    "import sys,os\n",
    "import itertools\n",
    "import numbers\n",
    "from collections import Counter\n",
    "from warnings import warn\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a5a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cf7fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(1337)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "#python_random.seed(1337)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.random.set_seed(1337)\n",
    "#older version of tensorflow\n",
    "#tf.set_random_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8784dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf00f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2,3,4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9a06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 4\n",
    "# Maximum number of threads to use for OpenMP parallel regions.\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "# Without setting below 2 environment variables, it didn't work for me. Thanks to @cjw85 \n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"4\"\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"4\"\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(\n",
    "    num_threads\n",
    ")\n",
    "tf.config.threading.set_intra_op_parallelism_threads(\n",
    "    num_threads\n",
    ")\n",
    "tf.config.set_soft_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acc5c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.regularizers import (\n",
    "    l2, \n",
    "    l1, \n",
    "    l1_l2\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import (\n",
    "    activations, \n",
    "    initializers, \n",
    "    regularizers, \n",
    "    constraints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98af4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53ba35c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, \n",
    "    EarlyStopping\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20d6afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest,\n",
    "    chi2\n",
    ")\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84eec855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention_layer import Attention, attention_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b27604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\tprint('building model')\n",
    "\n",
    "\tseq_input_shape = (1000,4)\n",
    "\tnb_filter = 256\n",
    "\tfilter_length = 9\n",
    "\tattentionhidden = 256\n",
    "\n",
    "\tseq_input = Input(shape = seq_input_shape, name = 'seq_input')\n",
    "\tconvul1   = Convolution1D(filters = nb_filter,\n",
    "                        \t  kernel_size = filter_length,\n",
    "                        \t  padding = 'valid',\n",
    "                        \t  activation = 'relu',\n",
    "                        \t  kernel_constraint = MaxNorm(3),\n",
    "                        \t  )\n",
    "\n",
    "\tpool_ma1 = MaxPooling1D(pool_size = 3)\n",
    "\tdropout1 = Dropout(0.5977908689086315)\n",
    "\tdropout2 = Dropout(0.50131233477637737)\n",
    "\tdecoder  = Attention(hidden = attentionhidden, activation = 'linear')\n",
    "\tdense1   = Dense(1)\n",
    "\tdense2   = Dense(1)\n",
    "\n",
    "\toutput_1 = pool_ma1(convul1(seq_input))\n",
    "\toutput_2 = dropout1(output_1)\n",
    "\tatt_decoder  = decoder(output_2)\n",
    "\toutput_3 = attention_flatten(output_2.shape[2])(att_decoder)\n",
    "\n",
    "\toutput_4 =  dense1(dropout2(Flatten()(output_2)))\n",
    "\tall_outp =  concatenate([output_3, output_4])\n",
    "\toutput_5 =  dense2(all_outp)\n",
    "\toutput_f =  Activation('sigmoid')(output_5)\n",
    "\n",
    "\tmodel = Model(inputs = seq_input, outputs = output_f)\n",
    "\tmodel.compile(loss = 'binary_crossentropy', optimizer = 'nadam', metrics = ['accuracy'])\n",
    "\n",
    "\tprint (model.summary())\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "246210bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing():\n",
    "    x_visdb = np.load('data/x_VISDB_fulldata.npy')\n",
    "    y_visdb = np.load('data/y_VISDB_fulldata.npy')\n",
    "\n",
    "    ###split 9:1\n",
    "    trainx, valx, trainy, valy = train_test_split(x_visdb, y_visdb, test_size = 0.1, stratify=y_visdb, random_state=42)\n",
    "\n",
    "    ###test 1:1\n",
    "    neg_val = np.where(valy == 0)\n",
    "    pos_val = np.where(valy == 1)\n",
    "    xval_positive = valx[pos_val]\n",
    "    yval_positive = valy[pos_val]\n",
    "    xval_negative = valx[neg_val]\n",
    "    yval_negative = valy[neg_val]\n",
    "\n",
    "    np.random.seed(42) \n",
    "    permutation = np.random.permutation(xval_negative.shape[0])\n",
    "    xval_negative_1 = xval_negative[permutation[:xval_positive.shape[0]], :, :]\n",
    "    yval_negative_1 = yval_negative[permutation[:xval_positive.shape[0]]]\n",
    "\n",
    "    valx = np.concatenate((xval_positive, xval_negative_1), axis=0)\n",
    "    valy = np.concatenate((yval_positive, yval_negative_1), axis=0)\n",
    "\n",
    "    valx2, valy2 = shuffle(valx, valy, random_state=42)\n",
    "    \n",
    "    return trainx, trainy, valx2, valy2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fff25ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model():\n",
    "    trainx, trainy, valx, valy = data_processing()\n",
    "\n",
    "    model = build_model()\n",
    "    model.load_weights('model/Final_model.h5')\n",
    "\n",
    "    print('testing')\n",
    "\n",
    "    y_pred = model.predict(valx, verbose = 1)\n",
    "\n",
    "    auroc = roc_auc_score(valy, y_pred)\n",
    "    aupr = average_precision_score(valy, y_pred)\n",
    "\n",
    "    np.save('data/y_pred.npy', y_pred)\n",
    "    np.save('data/valy.npy', valy)\n",
    "\n",
    "    print('auroc = ', auroc)\n",
    "    print('aupr = ', aupr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d0cb864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 330, 256)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 330, 256)     0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 84480)        0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 586)          66049       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 84480)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 256)          0           attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            84481       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257)          0           attention_flatten[0][0]          \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            258         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "building model\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq_input (InputLayer)          [(None, 1000, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 992, 256)     9472        seq_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 330, 256)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 330, 256)     0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 84480)        0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 586)          66049       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 84480)        0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_1 (attention_ (None, 256)          0           attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            84481       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 257)          0           attention_flatten_1[0][0]        \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            258         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 160,260\n",
      "Trainable params: 160,260\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "testing\n",
      "200/200 [==============================] - 4s 3ms/step\n",
      "auroc =  0.7515721203572368\n",
      "aupr =  0.7322076120636053\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\tbuild_model()\n",
    "\trun_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a93d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deephtlv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3395fde9124d4e43fe1ba25af65432035387285b638bc47c56e288c9c5de6369"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
